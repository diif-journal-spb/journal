dx
dt
6
 
-
?
ДИФФЕРЕНЦИАЛЬНЫЕ УРАВНЕНИЯ
И
ПРОЦЕССЫ УПРАВЛЕНИЯ
N 2, 2005
Электронный журнал,
рег. N П23275 от 07.03.97

e-mail: diff@osipenko.stu.neva.ru
Общая теория управления
ОРТОРЕГРЕССИОННЫЕ МЕТОДЫ ОЦЕНИВАНИЯ
ПАРАМЕТРОВ И ЗАДАЧИ ОТДЕЛЕНИЯ ТРЕНДОВ
В ЛИНЕЙНЫХ СИСТЕМАХ
А.А. Ломов
Институт математики им. С. Л. Соболева СО РАН,
пр. ак. Коптюга, 4, 630090 г. Новосибирск, Россия.
e-mail: lomov@math.nsc.ru
Аннотация.
Рассматриваетсязадачаоцениванияпараметровлинейныхдинамических
систем по коротким участкам переходных процессов с аддитивными измери-
тельнымивозмущениями.Дляполученияоценокиспользуютсямногомерные
статистическиеметодытипаортогональнойрегрессии.Приводятсярезульта-
ты сравнительного исследования методов с точки зрения использования ин-
формацииолинейныхсвязяхвнаблюдениях.Исследованысвойстваоценокв
предельных случаях выборки большого объема и малых возмущений. Пред-
ложена схема сравнения методов по линейным приближениям. Обсуждает-
ся применение орторегрессионных методов для идентификации систем без
свойства управляемости. Рассмотрен новый класс задач отделения трендов в
линейных системах. Показано, что определение параметров уравнения трен-
да связано с идентификацией некоторой расширенной системы без свойства
управляемости.Дифференциальные уравнения и процессы управления, N. 2, 2005
Введение
Встатьерассматриваетсязадачаоцениванияпараметровлинейныхдина-
мических систем по коротким выборкам измерений переходных процессов с
аддитивнымиизмерительнымивозмущениями.Объемстатистическойвыбор-
ки здесь определяется числом измеренных отрезков траекторий. Начальные
условия траекторий подлежат оцениванию совместно с параметрами систе-
мы. Общая постановка задач такого рода обсуждалась в [1].
Известные в литературе исследования в области оценивания параметров
по измерениям коротких участков траекторий преимущественно связаны с
расширенным фильтром Калмана для систем в форме 1-го порядка [1, 2].
Отмечается, что для эффективных вычислений в реальном времени методы
такого рода имеют недостаточный радиус сходимости [2].
Альтернативный подход, рассматриваемый в статье, основан на записи
системы в равносильной форме высокого порядка без переменных состояния
и оценивании параметров вариационными методами [3]. К семейству вари-
ационных методов принадлежит известный метод ортогональной регрессии
(ОР) и его разновидности [4, 5, 6, 7, 8]. Для вариационных методов к настоя-
щему времени разработаны устойчивые вычислительные алгоритмы получе-
нияоценоксбольшимрадиусомсходимости,решенызадачиоценкисигналов
системы совместно с параметрами уравнения [3], исследованы условия иден-
тифицируемости параметров и состоятельности оценок [9, 10, 11, 12].
Вариационные орторегрессионные методы отличаются друг от друга вы-
числительнойсложностьюиасимптотическимисвойствамиоценок.В[6]срав-
нивались два метода этого типа на примере систем со скалярными сигнала-
ми входа, выхода. Сравнение проводилось методом теории возмущений для
собственныхчиселисобственныхвекторовположительноопределенноймат-
рицы функции потерь в предположении малости измерительного шума.
Встатьеприводятсярезультатысравнительногоисследованияоценоква-
риационныхметодоввдвухразныхпредельныхслучаях:малыхвозмущений
и большого объема выборки. Первые результаты в этом направлении были
опубликованыв[10,13,14].Вподолжениеэтихработ,здесьпроводитсясрав-
нениеметодовсточкизренияиспользованияаприорнойинформацииолиней-
ных связях в траекториях оцениваемого объекта. Показано, что от степени
использования информации о линейных связях зависит дисперсия оценок.
Поясним сказанное примером.

Пусть объект описывается системой линейных уравнений
(
ˇy =Kw
∗ +Lθ
∗ +η ∗ ,
Mw
∗ = 0.
Здесь K, L, M
T
  заданные числовые матрицы с линейно независимыми
столбцами, w
∗ , θ ∗   векторы оцениваемых параметров, η ∗ ∈ N(0,σ 2
I)  
стохастические возмущения, ˇy   наблюдаемый сигнал. Сравниваются две
модели объекта:
(а) полная
(
y =Kw+Lθ,
Mw = 0;
(б) упрощенная модель y =Kw+Lθ.
Для параметров объекта (w
∗ ;θ ∗ ) строятся две состоятельные оценки:
(w
0
;θ 0
)
.
= arg min
w,θ :Mw=0
kˇy− yk
2
, (w
1
;θ 1
)
.
= argmin
w,θ
kˇy− yk
2
.
Здесь и далее применяются обозначения(A,B)
.
= (AB), (A;B)
.
=
 
A
B
!
.
Оценкаθ 0
,полученнаяпополноймодели(а),вобщемслучаеимеетмень-
шую дисперсию, чем оценка θ 1
по модели (б) (приложение, раздел 8.8).
Данная схема сравнения линейных методов применяется к нелинейным
орторегрессионным методам. Для этого рассматривается случай малых воз-
мущений с заменой оценок линейными приближениями (раздел 3.2).
Показано, что в орторегрессионном методе ВИ [3, 10, 11] полностью ис-
пользуетсяинформациявидаMw = 0освязяхмеждуотсчетамитраекторий
линейного динамического объекта. Это позволяет на коротких участках пе-
реходных процессов за счет более интенсивных вычислений получать состо-
ятельные оценки параметров с лучшими асимптотическими свойствами.
Существеннойособенностьюрассматриваемыхметодовявляетсявозмож-
ность получать состоятельные оценки параметров по измерениям отрезков
траекторий конечной длины. Это позволяет включить в рассмотрение но-
вый класс систем без условий устойчивости и управляемости. Системы без
условия управляемости привлекли внимание исследователей сравнительно
недавно [15]. Здесь мы показываем, что неуправляемые системы возникают
в задачах отделения динамических трендов от полезных сигналов системы
(раздел 6).

1 Класс систем
Исследуемые системы описываются уравнениями вида
α p
y
k+p
+...+α 0
y
k
=β p
u
k+p
+...+β 0
u
k
, k∈ 1,N− p. (1)
Здесь p> 0   порядок системы, N > p+1   длина траектории, α i
= α i,θ
∈
R
r× r
, β i
= β i,θ ∈R
r× m
  матрицы, зависящие от фиксированного параметра
θ , подлежащего оцениванию.
Системе (1) сопоставим многочленную матрицу
γ θ (s)
.
=γ 0,θ
+γ 1,θ
s+...+γ p,θ
s
p
∈R
r× (r+m)
[s], (2)
γ i,θ .
=γ i
= (α i
,− β i
)∈R
r× (r+m)
.
Запись R
r× (r+m)
[s] обозначает кольцо многочленов с действительными мат-
ричными коэффициентами изR
r× (r+m)
.
Введем также числовую матрицу
γ θ .
= (γ 0,θ
γ 1,θ
...γ p,θ
)∈R
r× (r+m)(p+1)
. (3)
Обозначим γ i
.
=
 
γ i
0
γ i
1
...γ i
p
 
i-ю строку γ θ , и определим вектор
γ =γ (θ )
.
=
 
γ 1
;...;γ r
 
.
= vecγ θ (4)
как последовательно составленный из строк матрицы γ θ .
На систему (1) налагаются условия:
(i) γ (θ ) = d +Dθ .
=D(1;θ )
.
=Dϑ, гдеD
.
= (d,D), ϑ
.
= (1;θ ); матрицаD
задана;
θ ∈ Ω ⊂ R
v
.
(ii) Для каждого значения параметра θ ∈ Ω в матрице γ θ (s) (2)
а) строки линейно независимы;
б) сумма степеней строк p
1
+...+p
r
.
=n постоянна;
в) γ θ (s) имеет наименьшую сумму степеней строк среди всех левоэквива-
лентных γ θ (s) матриц, т.е. γ θ (s) приведена по строкам;
г) числовая матрица γ θ (0) =γ 0,θ
имеет линейно независимые строки.

(iii) Параметрысистемыразличимы втомсмысле,чтолюбымдвумразлич-
ным значениям параметра θ соответствуют разные множества решений си-
стемы (1). Для различимости необходимо и достаточно, чтобы из равенства
ρ (s)γ θ (s) =γ ξ (s),ξ ∈ Ω ,следовалоρ (s) =I
r× r
,ξ =θ ;болеепростыеалгорит-
мически проверяемые критерии различимости в виде ограничений на ранги
специальных матриц, построенных из элементов γ θ , приведены в [12, 16].
Отметим, что условия (i)–(iii) не накладывают ограничений на устойчи-
вость и управляемость системы. Это позволяет включить в рассмотрение но-
вые задачи оценки параметров и сигналов для систем без свойства управля-
емости (раздел 6).
1.1 Обозначения
Отсчетывекторныхсигналовобъектаy
k
,u
k
объединимввектор-траекторию
z
.
= (z
1
;...;z
N
), z
i
.
= (y
i
;u
i
).
Систему (1) запишем в матричном виде:
Gz = 0,
G =






γ 0
γ 1
... γ p
0
γ 0
γ 1
... γ p
.
.
.
.
.
.
.
.
.
0 γ 0
γ 1
... γ p






. (5)
Матрица G имеет клеточно-теплицев вид, что прямо связано со стационар-
ностью системы.
Система уравнений (5) допускает равносильную форму записи
G(γ )z =V(z)γ, (6)
в которой используется вектор γ (4) и матрица
V(z)
.
=






I
r
⊗  
z
T
1
...z
T
p+1
 
I
r
⊗  
z
T
2
...z
T
p+2
 
.
.
.
I
r
⊗  
z
T
N− p
...z
T
N
 






.

Перестановкой строк (6) приводится к виду



G
1
.
.
.
G
r



z =



V 0
.
.
.
0 V



γ, (7)
G
i
.
=






γ i
0
γ i
1
... γ i
p
0
γ i
0
γ i
1
... γ i
p
.
.
.
.
.
.
.
.
.
0 γ i
0
γ i
1
... γ i
p






,
V
.
=






z
T
1
... z
T
p+1
z
T
2
... z
T
p+2
.
.
.
.
.
.
z
T
N− p
... z
T
N






.
Будем использовать также следующую форму записи системы (1), (5).
Переупорядочим компоненты траектории. Примем
υ k
.
= (y
k
;u
k
)
.
=
 
υ [1]
k
;...;υ [r+m]
k
 
∈R
r+m
.
Вместо z = (y
1
;u
1
;...;y
N
;u
N
) = (υ 1
;...;υ N
) запишем
z =
 
υ [1]
1
;...;υ [1]
N
;...;υ [r+m]
1
;...;υ [r+m]
N
 
. (8)
Тогда уравнение (5) можно записать через многочленную матрицу γ θ (s) в
следующем виде:
(γ θ (s)⊗ E)z = 0, (9)
где⊗   символ Кронекерова произведения, s   оператор сдвига:
s
k
E
.
=E
k
.
=



0 ... 0
.
.
.
.
.
.
0 ... 0
1 0
.
.
.
0 1
0 ... 0
.
.
.
.
.
.
0 ... 0



| {z }
k
| {z }
p
n
− k
∈R
(N− p
n
)× N
.
Если позволяют обстоятельства изложения, в обозначениях многочленов
(многочленных матриц)φ (s)∈R
n× m
[s] иногда будем опускать знак аргумен-
та: φ (s)
.
=φ .

Введем обозначениеN
γ для многообразия решений системы (9) (правого
нуль-пространства матрицы γ (s)⊗ E):
N
γ .
= kerγ (s)⊗ E.
Для любой траектории z системы (5) справедливо представление
z =H(θ )w,
так чтоN
γ = imH(θ ), где H(θ )   матрица из марковских параметров (при-
ложение, раздел 8.6), и w = (x
0
;u)   вектор, составленный из начальных
условий x
0
и входного сигнала u = (u
1
;...;u
N
).
ПустьN  линейноемногообразиевR
n
.ИпустьPx = 0,P ∈R
m× n
 си-
стемауравнений,множестворешенийкоторойсовпадаетсN: kerP =N.То-
гда систему Px = 0 (или матрицу P) будем называть описанием дляN. Без
ограничения общности можно считать, что строки P линейно независимы. В
этом смысле любая базисная система строк в ортогональном дополненииN
является описанием дляN.
Линейную оболочку строк матрицы P будем обозначать spanrP, тогда
spanrP = kerP. (10)
Если P   описание дляN, то spanrP =N.
Пусть A∈R
n× m
. Будем обозначать A∈R
n× k
матрицу, столбцы которой
образуют базис дополнения imA доR
n
. Согласно этому определению, всегда
imA = kerA
T
. (11)
Крометого,будемобозначатьA
⊥
∈R
m× t
матрицу,столбцыкоторойобразуют
базис подпространства kerA:
kerA = imA
⊥
, AA
⊥
= 0. (12)
Столбцы составной матрицы (A
T
,A
⊥
) всегда содержат базис пространства
R
m
:
im(A
T
,A
⊥
) =R
m
.
Если строки A линейно независимы, то матрица (A
T
,A
⊥
) неособенная.
Предложение 1. Имеют место следующие соотношения:
1) если столбцы матрицы A линейно независимы, то
 
A
 
.
=A =A;
2) всегда (A
⊥
)
⊥
.
=A
⊥⊥
= 0;
3) всегда
 
A
 
⊥
= 0;
4) если строки матрицы A линейно независимы, то (A
⊥
)
.
=A
⊥
=A
T
.

Доказательство. Первое соотношение сразу следует из определения
матрицы A. Второе и третье соотношения следуют из того, что матрицы A и
A
⊥
поопределениюимеютлинейнонезависимыестолбцы,тоесть kerA = 0и
kerA
⊥
= 0. Четвертое соотношение получается так: по условию строкиA ли-
нейно независимы, следовательно, матрица (A
T
,A
⊥
) неособенная; последнее
равносильно тому, что A
⊥
=A
T
или (ввиду соотношения 1) A
⊥
=A
T
.
Предложение доказано.
Пусть A(s)   многочленная матрица. Каноническую форму A(s), состо-
ящую из нулей и инвариантных многочленов на диагонали (форму Смита)
[17, с. 135], обозначаем SmA(s).
1.2 Однородные траектории
В частном случае однородной системы (1) (β i
= 0, m = 0) многообразие
N
γ образовано векторами вида
z
.
= (y
1
;...;y
N
),
y
t
=y
01
P
1
s
t
1
+...+y
0n
P
n
s
t
n
, (13)
n =p
1
+...+p
r
= degdetα (s),
где для i∈ 1,n числа y
0i
∈C есть начальные условия, s
i
∈C   корни урав-
нения detα (s) = 0, векторы P
i
∈R
r
вычисляются из уравнений α (s
i
)P
i
= 0
и нормируются каким-либо способом, например, kP
i
k = 1. В случае, ес-
ли корень s
i
имеет кратность k > 2, будем считать, что совпадают корни
s
i
= s
i+1
= ... = s
i+k− 1
, и тогда у соответствующих слагаемых суммы (13)
появляются сомножители   многочлены от t степени от нуля до k− 1:
 
y
0,i
P
i
+y
0,i+1
P
i+1
t+...+y
0,i+k− 1
P
i+k− 1
t
k− 1
 
s
t
i
. (14)
В качестве векторовP
i
,...,P
i+k− 1
в этом случае выбирается нормированный
базис подпространства kerα (s
i
).
В силу того, что уравнение (1) имеет действительные коэффициенты,
комплексные корни появляются в парах сопряженных корней s
j
.
= a + ib,
s
j+1
.
= a− ib. Поскольку мы ограничиваемся только действительными ре-
шениями, начальные условия y
0,i
в линейных комбинациях (13) и (14) при
действительныхкорняхs
i
должныбытьдействительные,априкомплексных
сопряженных корнях s
j
и s
j+1
  сопряженные: y
0,j
=y
0,j+1
[18]. В последнем
случае два парных слагаемых j и j +1 в сумме (13) дают траекторию
A%
t
cos(ωt+ϕ),

%
.
=
p
a
2
+b
2
, ω
.
= arccos
a
√
a
2
+b
2
.
Эта траектория определена с точностью до чисел A = A(y
0,j
,y
0,j+1
), ϕ =
ϕ(y
0,j
,y
0,j+1
).
Соответствующая парам сопряженных корней часть многочлена имеет
вид
(s− s
j
)(s− s
j+1
) =
 
s
2
− 2ρ cosω· s+ρ 2
 
.
Траектории вида
z
.
= (y
1
;...;y
N
), y
t
=Ps
t
=Pe
tlns
, P ∈R
r
,
являются показательными функциями времени t с основанием s или экспо-
нентами с показателем tlns. Ввиду этого линейные комбинации (13) можно
называть экспоненциальными траекториями.
Однородные системы с “вертикальными” матрицами
Рассмотрим системы
α p
y
k+p
+...+α 0
y
k
= 0, k∈ 1,N− p,
с матрицами α i
∈ R
q× r
, q > r. Пусть α (s) имеет полный нормальный ранг,
то есть инвариантные многочлены α (s) ненулевые. В этом случае многооб-
разие решенийN
γ определяется формулами (13) с заменой detα (s) на π (s),
гдеπ (s) произведениеинвариантныхмногочленовα (s),или(равносильно)
наибольший общий делитель миноров порядка r в α (s).
1.3 Постановка задачи идентификации
Пусть ˇz
(i)
  наблюдения траекторий:
ˇz
(i)
=z
∗ (i)
+η ∗ (i)
, i> 1, (15)
где z
∗ (i)
=H(θ ∗ )w
∗ (i)
  траектории, соответствующие “истинному” значению
параметров θ ∗ , и
η ∗ (i)
∈N(0,σ 2
I), M[η ∗ (i)
η T
∗ (j)
] =σ 2
I· δ ij
  стохастические погрешности измерений (M   символ математического
ожидания), w
∗ (i)
  независимые одинаково распределенные случайные вели-
чины.

Определение. Пусть θ =θ ∗ . При условии (iii) множество решений системы
(1)
N
∗ L
.
={z
∗ (1)
,...,z
∗ (L)
}
называется полным, если параметр θ по множеству N
∗ L
вычисляется одно-
значно. Можно показать [11], что полнотаN
∗ L
равносильна условию
L
− 1
L
X
i=1
D
T
V(z
∗ (i)
)
T
V(z
∗ (i)
)D > 0. (16)
Последовательность наблюдений
 
ˇz
(i)
, i> 1
	
(15) называется полной, если
она соответствует множеству решенийN
∗ L
, полному в пределе L→∞:
lim
L→∞
L
− 1
L
X
i=1
D
T
V(z
∗ (i)
)
T
V(z
∗ (i)
)D > 0.
Задача.Исходяизполнойпоследовательностинаблюдений
 
ˇz
(i)
, i> 1
	
,
получить оценку θ L
= θ L
 
ˇz
(1)
,...,ˇz
(L)
 
, сходящуюся с вероятностью 1 к ис-
тинному значению: lim
L→∞
θ L
=θ ∗ .
2 Орторегрессионные оценки параметров
Орторегрессионныеоценкиθ L
строятсякакрезультатминимизацииквад-
ратичной функции потерь с линейными ограничениями [3, 5, 6, 10, 11]:
θ L
= argmin
θ J
L
(θ ), J
L
=
1
L
L
X
i=1
J
(i)
, J
(i)
= min
Gz
(i)
=0


Φˇ z
(i)
− z
(i)


2
, (17)
kerΦ = 0 .
Отметим, что возможна запись функции потерь J
(i)
в более симметричном
виде по отношению к переменным ˇz
(i)
, z
(i)
:
J
(i)
= min
Gz
(i)
=0


Φˇ z
(i)
− Υ z
(i)


2
, (18)
kerΦ = 0 , kerΥ = 0 .
Запись (18) сводится к (17) заменой Υ z
(i)
наz
(i)
при добавлении новых строк
к матрице ограничений: [G;g]z
(i)
= 0, где g есть наибольшая линейно неза-
висимая система строк, отвечающая условию gΥ = 0 .

Условиясильнойсостоятельности(сходимостисвероятностью1)дляоце-
нок θ L
(17) при Φ = I исследовались в [9, 10, 11]. Переход к случаю Φ 6= I
несоставляетпринципиальныхзатруднений.Крометого,допустимоналичие
не зависящей от параметра θ неособенной весовой матрицы в норме k·k . В
[19] доказана сильная состоятельность оценок θ L
при Φ = I, p = 0, α 0,θ
≡ I,
vecβ 0,θ
≡ θ .Обобщениемрезультата[19]наслучайp> 0являетсяследующая
теорема.
Теорема 1. При ограничениях (i)–(iii) и полном множестве наблюдений
 
ˇz
(i)
, i> 1
	
орторегрессионная оценка θ L
(17) сильно состоятельна по L→
∞.
Доказательство несложно провести по схеме [11] (опущено).
Далее без потери общности будем полагать L = 1, опустив соответствую-
щие индексы у величин.
2.1 Оценки методов вариационной идентификации и ортогональ-
ной регрессии
Частными случаями оценок (17) являются оценки методов ВИ θ V
и ОР
θ OR
, определяемые соотношениями:
θ V
= argmin
θ J(θ ), J(θ ) = min
Gz=0
kˇz− zk
2
, (19)
G =






γ 0,θ
γ 1,θ
... γ p,θ
0
γ 0,θ
γ 1,θ
... γ p,θ
.
.
.
.
.
.
.
.
.
0 γ 0,θ
γ 1,θ
... γ p,θ






,
θ OR
= argmin
θ J
OR
(θ ), J
OR
(θ ) = min
G
OR
z=0
kˇz− zk
2
, (20)
G
OR
=






γ 0,θ
γ 1,θ
... γ p,θ
0
γ 0,θ
γ 1,θ
... γ p,θ
.
.
.
0 γ 0,θ
γ 1,θ
... γ p,θ






.
Отметим, что оценки (19) и (20) отличаются только матрицами ограни-
чений: G
OR
получается из G вычеркиванием части строк.

Для функции потерь J (19) получим явное выражение зависимости от θ (см. также [3, 10, 11]). Наименьшее по z значение квадрата нормы kˇz− zk
2
при условии Gz = 0 равно ˇz
T
Π G
ˇz, где Π G
= G
T
(GG
T
)
− 1
G есть матрица
проекторанаортогональноедополнениекподпространству kerGтраекторий
системы. Заменяя Gˇz на V(ˇz)γ =V(ˇz)Dϑ, получим
J(θ ) =ϑ
T
D
T
ˇ V
T
C
ˇ VDϑ, (21)
ˇ V
.
=V(ˇz), C = (GG
T
)
− 1
.
Таким же образом получается выражение для J
OR
(θ ) (20):
J
OR
(θ ) =ϑ
T
D
T
ˇ V
T
OR
C
OR
ˇ V
OR
Dϑ,
ˇ V
OR
.
=V
OR
(ˇz), V
OR
(z) =






I
r
⊗  
z
T
1
...z
T
p+1
 
I
r
⊗  
z
T
p+2
...z
T
2p+2
 
.
.
.
I
r
⊗  
z
T
M− p
...z
T
M
 






,
∃k M =k(p+1)∈N− p,N,
C
OR
= (G
OR
G
T
OR
)
− 1
=



(γ θ γ T
θ )
− 1
0
.
.
.
0 (γ θ γ T
θ )
− 1



.
2.2 Модифицированные оценки ортогональной регрессии
Введем еще один частный случай орторегрессионных оценок, так назы-
ваемые модифицированные (М):
θ M
= argmin
θ J
M
(θ ), J
M
(θ ) =ϑ
T
D
T
ˇ V
T
C
OR
ˇ VDϑ. (22)
Какпоказанов[6],М-оценкиприr = 1обладаютбольшейустойчивостью
к возмущениям в исходных данных, чем оценки ОР.
3 Сравнение оценок
С точки зрения общего определения (17), оценка ВИ (19) при L > 1
может быть представлена как оценка ОР (20) с “большой” матрицей G
L
=
diag(G...G) вместо G = diag(γ...γ ).

По виду функции потерь, М-оценки занимают промежуточное положе-
ние между оценками ОР и ВИ. Они получаются из оценок ВИ (21) заменой
матрицы C на матрицу C
OR
более простой структуры. С другой стороны,
модифицированная оценка θ M
(22) является оценкой ОР (20) с особым обра-
зом сформированным вектором наблюдений ˇz. Действительно, имеют место
соотношения:
J
M
= min
G
M
z
M
=0
kΦˇ z− z
M
k
2
, (23)
Φ =













I
0
I
0
.
.
.













⊗ 
I
r
0
0 I
m
!
.
= Φ ⊗ 
I
r
0
0 I
m
!
, Φ ∈R
(N− p)(p+1)× N
,
G
M
=






γ θ 0 ... 0
0 γ θ .
.
.
.
.
.
.
.
. 0
0 ... 0 γ θ 





, G
M
Φ = G.
Здесь символ ⊗ обозначает Кронекерово произведение матриц. Как можно
увидеть из определений (23), матрица ограничений G
M
в модифицированном
методе имеет ту же клеточно-диагональную структуру, что и матрица G
OR
в методе ОР, отличаясь только увеличенным размером. Соответственно уве-
личен размер вектора z
M
вспомогательной (модельной) траектории. Но это
связано не с увеличением объема выборки за счет добавления новых незави-
симых измерений, а с дублированием компонент в векторе измерений Φˇ z:
ˇz = (ˇz
1
;...;ˇz
N
), Φ z = (ˇz
1
;...;ˇz
p+1
ˇz
2
;...;ˇz
p+2
;......;ˇz
N
).
Заметим,
V(z) =V
OR
(Φ z).
С точки зрения вычислительных ресурсов, поиск минимума функции
потерь метода ВИ требует существенно большего числа операций, чем ОР.
Оценки ОР и М по вычислительным затратам практически не отличаются.
Подробное рассмотрение оценок с вычислительной стороны выходит за рам-
ки статьи.

Далее сравниваются оценки θ V
(19, 21) и θ M
(22).
3.1 Оценки метода вариационной идентификации как модифици-
рованные оценки ортогональной регрессии с дополнительны-
ми линейными ограничениями на оцениваемые переменные
Вфункцияхпотерь(19),(22)явновыразимтраекториюzчерезначальное
состояние системы x
0
и входной сигнал u = (u
1
;...;u
N
):
J(θ ) = min
w
J(θ,w ), J(θ,w )
.
=kΦˇ z− Φ H(θ )wk
2
, w
.
= (x
0
;u), (24)
J
M
(θ ) = min
w
M
J
M
(θ,w
M
), J
M
(θ,w
M
)
.
=kΦˇ z− H
M
(θ )w
M
k
2
, w
M
.
= (x
M,0
;u
M
). (25)
МатрицыH(θ ),H
M
(θ ),ивекторыw,w
M
выписанывприложении(раздел8.6).
СомножительΦ добавленкобоимслагаемым(24)дляприведения(24)квиду
(25) по первому слагаемому Φˇ z.
Утверждение 1. Существует линейное ограничение Mw
M
= 0, при нало-
жении которого функция потерь J
M
(θ ) (25) совпадает с функцией потерь
J(θ ) (24):
J(θ ) = min
w
J(θ,w ) = min
w
M
:Mw
M
=0
J
M
(θ,w
M
). (26)
Доказательство см. в приложении, раздел 8.6.
3.2 Сравнение оценок по линейному приближению
В орторегрессионных методах параметрыw,w
M
оцениваются совместно с
θ .Оценкидляпар(w;θ ),(w
M
;θ )можнозаменитьлинейнымиприближениями,
рассмотрев предельный случай малых возмущений.
Предположим, что случайные величины η (i)
∈R
N(r+m)
имеют распреде-
лениеP с выпуклым ограниченным носителем: suppP3 0, diamsuppP<σ .
ПустьMη (i)
= 0. Будем полагать величину σ достаточно малой, чтобы зна-
чения χ V
.
= (w
V
;θ V
) и χ M
.
= (w
M
;θ M
), получаемые минимизацией (24), (25),
с вероятностью 1 уклонялись от истинных значений χ ∗ .
= (w
∗ ;θ ∗ ) не более
чем на заранее заданную малую величину ε. Возможность такого выбора
σ обусловлена однозначностью и непрерывностью зависимости оптимальных
значенийпараметровχ .
= (w;θ )отисходныхданных ˇz.Этазависимостьзада-
ется как неявная функция системой равенств ∂J(ˇz,χ )/∂χ = 0. Существова-
ние и непрерывность неявной функции χ (ˇz) для орторегрессионных методов
следует непосредственно из результатов [10] (приложение, раздел 8.10.2).

Пусть (w
 
;θ  
)   некоторая оценка для (w
∗ ;θ ∗ ) с уклонением не более ε.
3.2.1 Линейные приближения
Запишемфункциюпотерь(24)ввидеJ = minkFk
2
иразложимфункцию
F относительноточки (z
 
;w
 
;θ  
),z
 
=H(θ  
)w
 
,врядТейлорасостаточным
членом R:
J(w,θ ) =kF
0
+Δ F(w,θ )+R(w,θ )k
2
, (27)
F
0
.
=z
 
− H(θ  
)w
 
= 0,
Δ F
.
= Δˇ z− Δ H(θ  
,Δ θ )w
 
− H(θ  
)Δ w,
Δˇ z
.
= ˇz− z
 
, Δ w
.
=w− w
 
, Δ θ .
=θ − θ  
.
Взаписи(27)выделимслагаемые,зависящиеотпеременных(Δ w;Δ θ )
.
= Δ χ :
J(Δ χ ) =kΔˇ z− Δ f(χ  
,Δ χ )+R(χ  
,Δ χ )k
2
=
=kΔˇ z− Δ f(χ  
,Δ χ )k
2
+O
 
kΔ χ k
3
 
. (28)
ОценкаВИχ V
,соответствующаяизмерениямΔˇ z
.
= ˇz− z
 
,вычисляетсяпутем
минимизации функции потерь (28):
χ V
=χ  
+Δ χ V
, (29)
Δ χ V
= argmin
Δ χ J(Δ χ ).
Зададимся приближенной функцией потерь
e
J(Δ χ ) =kΔˇ z− Δ f(χ  
,Δ χ )k
2
. (30)
Минимизируя приближенную функцию
e
J(Δ χ ), получим некоторую оценку
e χ V
:
e χ V
=χ  
+Δ e χ V
, (31)
Δ e χ V
= argmin
Δ χ e
J(Δ χ ).
Покажем,чтооценкаe χ V
являетсяприближениемдляχ V
вследующемсмысле.
Утверждение 2.ke χ V
− χ V
k =o(kχ V
− χ  
k), т. е. приkχ V
− χ  
k→ 0 имеет
место сходимость
ke χ V
− χ V
k
kχ V
− χ  
k
→ 0.

Другими словами, если рассматривать оценку χ V
как один шаг итера-
ционной процедуры уточнения оценки χ  
, то по мере уменьшения величины
шага,разницамеждуχ V
иe χ V
будетуменьшатьсябыстрее,чемвеличинашага
kχ V
− χ  
k. В этом смысле e χ V
является приближением для χ V
.
Замечание. В рассуждениях всюду полагаем χ V
− χ  
.
= Δ χ V
6= 0.
Доказательство. 1) Установим лемму:
Лемма 1. Пусть некоторая функция J(x) : R
n
→R
1
представима в виде
суммы J(x) = J
1
(x) + R(x), J
1
(x) = J
0
+ (x− x
0
)
T
Q(x− x
0
), x, x
0
∈ B,
где Q > 0   положительно определенная матрица, B   замкнутое вы-
пуклое подмножество R
n
, и функция R(x) в B непрерывна и ограничена:
∀x ∈ B kR(x)k < C. Обозначим x
1
точку минимума J(x) в B. Тогда рас-
стояние между точками минимума функций J(x) и J
1
(x) ограничено свер-
ху величиной:kx
1
− x
0
k<
q
2C
λ min
(Q)
, где λ min
(Q)   наименьшее собственное
число матрицы Q.
Доказательство леммы дано в приложении, раздел 8.7.
2) Введем обозначения:
x
.
= Δ χ, J
1
(x)
.
=
e
J(Δ χ ),
x
0
.
= Δ e χ V
, J
0
.
=
e
J(Δ e χ V
),
Q
.
=
1
2
∂
2
e
J(x)
∂x
2
(x
0
).
Запишем функцию потерь
e
J(Δ χ ) (30):
e
J(Δ χ )
.
=J
1
(x) =J
0
+(x− x
0
)
T
Q(x− x
0
). (32)
Применим лемму 1 к функциям
e
J(Δ χ ) (32) и J(Δ χ ) =
e
J(Δ χ )+O
 
kΔ χ k
3
 
(28), учитывая оценку
R(x) =O
 
kΔ χ k
3
 
<C
1
kΔ χ V
k
3
для некоторой константы C
1
. Эта оценка обеспечивается надлежащим выбо-
ромобластиB значенийΔ χ .Согласнолемме,имеетместоследующаяоценка
сверху для расстояния между корнями функций
e
J(Δ χ ) и J(Δ χ ):
kΔ e χ V
− Δ χ V
k =ke χ V
− χ V
k<
s
2C
1
kΔ χ V
k
3
λ min
(Q)
.
=C
2
kΔ χ V
k
3/2
=C
2
kχ V
− χ  
k
3/2
.

Отсюда следуетke χ V
− χ V
k =o(kχ V
− χ  
k).
Утверждение доказано.
Построим линейное приближение для модифицированных оценок (25).
Для этого повторим изложенные выше рассуждения, заменив обозначения.
Запишем функцию потерь (25) в виде J
M
= minkF
M
k
2
и разложим функ-
цию F
M
относительно точки (z
 
;w
 
;θ  
) в ряд Тейлора с остаточным членом
R
M
:
J
M
(w
M
,θ ) =kF
M,0
+Δ F
M
(w
M
,θ )+R
M
(w
M
,θ )k
2
, (33)
F
M,0
.
= Φ z
 
− H
M
(θ  
)w
 
M
= 0,
Δ F
M
.
= ΦΔˇ z− Δ H
M
(θ  
,Δ θ )w
 
M
− H
M
(θ  
)Δ w
M
,
Δˇ z
.
= ˇz− z
 
, Δ w
M
.
=w
M
− w
 
M
, Δ θ .
=θ − θ  
.
В записи (33) выделим слагаемые, зависящие от переменных (Δ w
M
;Δ θ )
.
=
Δ χ :
J
M
(Δ χ ) =kΦΔˇ z− Δ f
M
(χ  
,Δ χ )+R
M
(χ  
,Δ χ )k
2
=
=kΦΔˇ z− Δ f
M
(χ  
,Δ χ )k
2
+O
 
kΔ χ k
3
 
. (34)
Модифицированная оценка χ M
, соответствующая измерениям Δˇ z
.
= ˇz− z
 
,
вычисляется путем минимизации функции потерь (34):
χ M
=χ  
+Δ χ M
, (35)
Δ χ M
= argmin
Δ χ J
M
(Δ χ ).
Зададимся приближенной функцией потерь
e
J
M
(Δ χ ) =kΦΔˇ z− Δ f
M
(χ  
,Δ χ )k
2
. (36)
Минимизируяприближеннуюфункцию
e
J
M
(Δ χ ),мыполучимнекоторуюоцен-
ку e χ M
:
e χ M
=χ  
+Δ e χ M
, (37)
Δ e χ M
= argmin
Δ χ e
J
M
(Δ χ ).
Оценка e χ M
является приближением для χ M
согласно следующему утвержде-
нию.
Утверждение 3.ke χ M
− χ M
k =o(kχ M
− χ  
k), т. е. приkχ M
− χ  
k→ 0 имеет
место сходимость
ke χ M
− χ M
k
kχ M
− χ  
k
→ 0.
Доказательствополностьюаналогичнодоказательствуутверждения2.

3.2.2 Сравнение по линейным приближениям
Визложенномвышесмыслеможозаменитьоценкиχ V
,χ M
(исоответствен-
но θ V
, θ M
) (29, 35) линейными приближениями e χ V
, e χ M
(
e
θ V
,
e
θ M
) (31, 37). После
заменыиспользуетсяизложеннаявовведениииприложении(раздел8.8)схе-
ма сравнения линейных оценок.
Сформулируем основной результат.
Теорема 2. Пусть D
V
и D
M
  дисперсии оценок
e
θ V
и
e
θ M
соответственно.
Тогда D
V
6D
M
, и равенство достигается тогда и только тогда, когда
∀Δ θ H
M
(θ ∗ )
T
Δ H
M
(θ ∗ ,Δ θ ) = 0.
Доказательство. Учтем соответствие обозначений в теореме 7 (при-
ложение, раздел 8.8) и в формулах (33, 36), с заменой θ  
на θ ∗ при малых ε
(согласно определению θ  
, данному в начале раздела 3.2):
θ .
= Δ θ, w
.
= Δ w
M
, Y
.
= ΦΔˇ z,
K
.
=H
M
(θ ∗ ), Lθ .
= Δ H
M
(θ ∗ ,Δ θ )w
M∗ .
Тогда утверждение теоремы является непосредственным следствием теоре-
мы 7. Теорема доказана.
Укажем класссистем(1),длякотороговсегдавыполняетсястрогое нера-
венство D
V
<D
M
.
Определение. Пусть α (s)
.
= α 0
+α 1
s +... +α p
s
p
и многочлен detα (s) не
имеет нулевых корней. Тогда в системе (82) многочлен det(sI− A) не имеет
нулевых корней и матрица A неособенная. Кроме того, пусть в разложении
α (s) = (diag
i
s
p
i
)·  
α [0]
+s
− 1
α [− 1]
+...+s
− p
r
α [− p
r
]
 
,
diag
i
s
p
i
.
= diag(s
p
1
,s
p
2
,...,s
p
r
),
с числовыми матрицами α [i]
матрица α [0]
не зависит от параметра θ . Тогда в
равносильной системе (82) в форме восстанавливаемости матрицаC не зави-
сит от параметра θ (приложение, раздел 8.4). В этом случае будем говорить,
что система (1) принадлежит классу простых.
В [13, 14] было приведено без доказательства следующее утверждение.
Теорема 3. Для систем из класса простых всегда
∃Δ θ H
M
(θ )
T
Δ H
M
(θ, Δ θ )6= 0,
т. е. всегда D
V
<D
M
.

Доказательство дано в приложении, раздел 8.9.
Теоремы 2 и 3 утверждают, что метод ВИ в предельном случае малых
возмущений обеспечивает оценки параметров с меньшей дисперсией, чем ме-
тодОР,покрайнеймередлясистемизклассапростых,засчетболееполного
использования информации о линейных связях в наблюдениях.
4 Асимптотическоераспределениеоценок(предельный
случай L→∞)
Состоятельностьоценкиθ L
(17)утверждаетсявтеореме1.Вэтомразделе
исследуется асимптотическое распределение при L→∞.
Сначала сформулируем результат для оценок ВИ. Для оценок ОР соот-
ветствующие утверждения получаются заменой G на G
OR
и V на V
OR
.
Пусть γ ij
  ij-й элемент γ θ (3), тогда строка γ i
имеет вид
γ i
.
=
 
γ i
0
,γ i
1
,...,γ i
p
 
.
=
 
γ i1
,γ i2
,...,γ it
 
, t
.
= (p+1)(r+m).
Будем располагать строки в G согласно (7). Обозначим
Π .
=I− G
T
CG,
E
ij
.
=∂G/∂γ ij
,
b z
.
= Πˇ z.
(38)
Матрицу V (7) разобьем на клеточные столбцы:
V =



V 0
.
.
.
0 V



=I
r
⊗ V
.
=
 
V
1
...V
r
 
, (39)
V
1
.
=






V
0
.
.
.
0






, ..., V
r
.
=






0
.
.
.
0
V






.
Обозначим V
ij
j-й столбец матрицы V
i
. Отметим, что V
ij
есть столбец мат-
рицы V, порядковый номер l которого вычисляется по двойному индексу ij
согласно правилу l =j +(i− 1)(p+1)(r+m).

Теорема 4. В условиях теоремы 1 орторегрессионная оценка θ L
(1), (19)
асимптотически по L→∞ нормальна с дисперсией
(1) covL
1/2
(θ L
− θ ∗ )
L→∞
−→ (MJ
00
1
)
− 1
(MJ
0
1
J
0T
1
)(MJ
00
1
)
− 1
,
(2) MJ
0
1
J
0T
1
=σ 2
MJ
00
1
+σ 2
D
T
X
T
XD,
(3) MJ
00
1
=MD
T
V
T
∗ CV
∗ D,
X
T
X
.
=kx
ij,kl
k
i∈1,r,j∈1,t
k∈1,r,l∈1,t
, x
ij,kl
.
=M(
b
V − V
∗ )
T
ij
C(
b
V − V
∗ )
kl
,
(4) x
ij,kl
=σ 2
SpΠ E
T
ij
CE
kl
Π ,
b
V
.
=V(b z), V
∗ .
=V(z
∗ ).
Доказательство теоремы дано в статье [10] и для удобства читателя
приведено с незначительными изменениями в приложении (раздел 8.10).
Замечание 1. Втеореме4изформулы(4)следует,чтовтороеслагаемоев(2)
имеет величину порядка σ 4
.
Рассмотрим модифицированные оценки (22). Они отличаются от оценок
ОР и ВИ тем, что выражение G
T
(G
OR
G
T
OR
)
− 1
G в функции потерь (22):
J
M
(θ ) =ϑ
T
D
T
ˇ V
T
C
OR
ˇ VDϑ =
= ˇz
T
G
T
(G
OR
G
T
OR
)
− 1
Gˇz
  уже не является проективной матрицей со свойством Π 2
= Π . Это су-
щественно усложняет отдельные моменты доказательства. Учитывая заме-
чание 1, для М-оценок заменим некоторые из точных выражений оценками
сверху.
Теорема 5. В условиях теоремы 1 модифицированная орторегрессионная
оценка θ L
(1), (22) асимптотически по L→∞ нормальна с дисперсией
(1) covL
1/2
(θ L
− θ ∗ )
L→∞
−→ (MJ
00
1
)
− 1
(MJ
0
1
J
0T
1
)(MJ
00
1
)
− 1
,
(2) MJ
0
1
J
0T
1
=σ 2
MD
T
V
T
∗ C
OR
V
∗ D+σ 4
D
T
WD,
0<W <c
1
I,
c
1
=N
4
(p+1)
3
r(r+m+1)
3
Sp(γ T
θ γ θ )
− 1
.
(3) MJ
00
1
=MD
T
V
T
∗ C
OR
V
∗ D+σ 2
Sp
 
C
OR
C
− 1
 
00
θθ ,
Sp
 
C
OR
C
− 1
 
00
θθ 6 4(p+1)
1/2
N
3
(r+m)
2
kDD
T
kSp(γ T
θ γ θ )
− 1
.
V
∗ .
=V(z
∗ ).

Доказательство дано в приложении, раздел 8.11.
Следствие. В случае σ → 0 предельные значения асимптотических дис-
персий оценок ВИ, ОР, М определяются первыми слагаемым в формулах
(2) утверждений теорем 4, 5:
covL
1/2
(θ L
− θ ∗ )
L→∞
−→ σ 2
(MJ
00
1
)
− 1
, σ → 0,
где для оценок ВИ
MJ
00
1
σ →0
−→ MD
T
V
T
∗ CV
∗ D, (40)
для оценок ОР
MJ
00
1
σ →0
−→ MD
T
V
T
OR∗ C
OR
V
OR∗ D, (41)
и для оценок М
MJ
00
1
σ →0
−→ MD
T
V
T
∗ C
OR
V
∗ D. (42)
5 Распределение оценок при возмущениях малой ам-
плитуды (предельный случай σ → 0)
Получим предельные значения дисперсий оценок (40), (41), (42) другим
способом, применяя теорему о неявной функции.
Пусть ˇz   наблюдение траектории. Оценка параметров θ .
=θ 1
(17) опре-
деляется из уравнения
J
0
θ (ˇz,θ ) = 0, (43)
где J
0
θ обозначает частную производную J по θ . С учетом того, что все необ-
ходимые производные существуют (см. раздел 8.10.2), уравнение (43) задает
неявную функцию
θ (ˇz) =θ 0
+Δ θ (Δ z)+Δ 2
θ (Δ z)+...
Δ z
.
= ˇz− z
0
, J
0
θ (z
0
,θ 0
) = 0. (44)
При малых уклонениях наблюдений ˇz от опорной точки z
0
оценка θ будет
мало уклоняться от значения θ 0
.
=θ (z
0
). Если уклонения Δ z носят стохасти-
ческий характер, можно описать распределение оценки θ , отталкиваясь от
известного распределения наблюдений ˇz.

Разложимлевуючастьуравнения(43)врядТейлораотносительноточки
(z
0
,θ 0
):
J
0
θ (ˇz,θ ) =J
0
θ (z
0
,θ 0
)+J
00
θz
(z
0
,θ 0
)Δ z +J
00
θθ (z
0
,θ 0
)Δ θ +O
z,θ, 2
,
где обозначено
O
z,θ, 2
.
=O(kΔ zk
2
)+O(kΔ θ k
2
).
Учитывая (43), (44), получаем
J
00
θz
(z
0
,θ 0
)Δ z +J
00
θθ (z
0
,θ 0
)Δ θ +O
z,θ, 2
= 0,
откуда
Δ θ =− (J
00
θθ )
− 1
J
00
θz
Δ z +O
z,θ, 2
. (45)
Будем считать Δ z случайной величиной, распределенной в окрестности
нуля с нулевым мат. ожиданием и дисперсией σ 2
I. Пусть носитель распреде-
ления ˇz имеетконечныйдиаметрнебольшеc· σ ,гдеc некотораяконстанта.
Проведем сравнение Δ θ с нормированным уклонением из условия теоре-
мы 4:
Δ θ L
.
=L
1/2
(θ L
− θ ∗ ). (46)
Утверждение4. ДляоценокВИ,М,ОРуклонение Δ θ (45)впределеσ → 0
и уклонение Δ θ L
(46) в пределе L→∞ имеют одинаковую дисперсию
D
Δ θ .
=σ 2
Q
− 1
∗ ,
где для оценок ВИ
Q
∗ =D
T
V
T
∗ CV
∗ D,
для модифицированных оценок (М)
Q
∗ =D
T
V
T
∗ C
OR
V
∗ D,
и для оценок ОР
Q
∗ =D
T
V
T
OR∗ C
OR
V
OR∗ D.
Доказательство. 1) В случае оценок ВИ используем выражения для
производных J
0
θ , J
00
θθ (лемма 3, приложение, раздел 8.10.2):
J = ˇz
T
G
T
CGˇz,
J
0
θ = (θ T
D
T
+d
T
)
ˇ V
T
C
b
VD =z
T
G
T
C
b
VD

⇒ J
00
θz
=
∂J
0T
θ ∂z
=D
T
b
V
T
CG, (47)
J
00
θθ =D
T
b
V
T
C
b
VD+O
z,1
, O
z,k
.
=O(kΔ zk
k
). (48)
Производныеберутсявточкахz
0
,θ 0
,исглаженноезначениетраекторииb z по-
нимается как проекция ˇz на пространство траекторий модели с параметрами
θ 0
.
Подставляя (47), (48) в (45), получим зависимость Δ θ (Δ z):
Δ θ =−  
D
T
b
V
T
C
b
VD+O
z,1
 
− 1
D
T
b
V
T
CGΔ z +O
z,2
=
=−  
D
T
b
V
T
C
b
VD
 
− 1
D
T
b
V
T
CGΔ z +O
z,2
.
Вычислим дисперсию Δ θ :
D
Δ θ =MΔ θ Δ θ T
=
=M
 
 
D
T
b
V
T
C
b
VD
 
− 1
D
T
b
V
T
CG(Δ zΔ z
T
)× × G
T
C
b
VD
 
D
T
b
V
T
C
b
VD
 
− 1
 
+O
z,3
=
=σ 2
b
Q
− 1
+O
z,3
, (49)
b
Q
.
=D
T
b
V
T
C
b
VD.
2)АсимптотическоепоL→∞выражениедлядисперсииуклонения Δ θ L
(46) согласно теореме 4 имеет вид:
D
Δ θ L
.
= covL
1/2
(θ L
− θ ∗ ) →
→ (Q
∗ )
− 1
 
σ 2
Q
∗ +σ 2
D
T
X
T
XD
 
(Q
∗ )
− 1
=
=σ 2
Q
− 1
∗ +O
z,4
, (50)
Q
∗ .
=D
T
V
T
∗ CV
∗ D.
Сравним выражения (49) и (50).
Рассмотрим предельный случай возмущений малой амплитуды σ → 0
(kΔ zk → 0) при условии z
0
= z
∗ , θ 0
= θ ∗ . Интуитивно понятно, что при
kΔ zk → 0 оценка траектории ˆ z сходится к значению z
∗ , и соответственно,
b
Q→ Q
∗ . Здесь важно убедиться, что разность между σ 2
b
Q
− 1
и σ 2
Q
− 1
∗ имеет

порядок величины не больше остаткаO
z,3
в формуле (49). Действительно, из
разложенияkˇz− z
∗ k
2
=kˆ z− z
∗ k
2
+kˇz− ˆ zk
2
следуетkˆ z− z
∗ k<kˇz− z
∗ k =kΔ zk.
Значит,k
b
V − V
∗ k =O
z,1
, и в силу равенства
b
Q− Q
∗ =
= (
b
V − V
∗ )
T
C(
b
V − V
∗ )+
+V
T
∗ C(
b
V − V
∗ )+(
b
V − V
∗ )
T
CV
∗ получаем
b
Q− Q
∗ =O
z,1
.
Далее,
b
Q
− 1
− Q
− 1
∗ =− Q
− 1
∗  
b
Q− Q
∗  
Q
− 1
∗ +O
 
k
b
Q− Q
∗ k
2
 
=O
 
k
b
Q− Q
∗ k
 
=O
z,1
.
Следовательно,
σ 2
b
Q
− 1
− σ 2
Q
− 1
∗ =O
z,3
.
Значит, уклонение Δ θ (45) в пределе σ → 0 и уклонение Δ θ L
(46) в пределе
L→∞ имеют одну и ту же дисперсию
D
Δ θ .
=σ 2
Q
− 1
∗ , Q
∗ =D
T
V
T
∗ CV
∗ D.
3) Для оценок ОР все выражения остаются в силе с заменой G на G
OR
, C
на C
OR
и V на V
OR
:
Q
∗ =D
T
V
T
OR∗ C
OR
V
OR∗ D.
4) Для модифицированных оценок вместо леммы 3 следует использовать
лемму 6 (приложение, раздел 8.11).
Утверждение доказано.
6 Системы без свойства управляемости в задачах отде-
ления трендов
Особенностьюсистембезсвойствауправляемостиявляетсяналичиенеуправ-
ляемых свободных движений. Оценка параметров и траекторий неуправляе-
мыхдвиженийможетбытьосуществленаметодамиорторегрессионноготипа.

Здесь будет показано, что неуправляемые системы возникают, в частно-
сти,взадачахотделениятрендовотсигналовлинейныхдинамическихобъек-
тов. Трендами называем аддитивные составляющие, описываемые линейны-
ми разностными уравнениями, отличающимися от уравнений объекта. Трен-
ды представляют собой детерминированные сигналы и играют роль возму-
щений нестохастического характера. Отделить тренд значит вычислить на-
чальные условия и параметры уравнения тренда исходя из предъявленных
измерений суммы тренда и полезного сигнала. Начальные значения полез-
ного сигнала также подлежат вычислению. Если не все параметры системы
известны, можно говорить о совместной оценке неизвестных параметров и
начальных условий тренда и полезного сигнала, объединяя их в одну новую
систему. Будет показано, что такие объединенные системы неуправляемы.
6.1 Разделение тренда и сигналов системы
Рассмотримобъектстраекториямиz,описываемымисистемойуравнений
Gz = 0, (51)
и сигнал тренда ε:
Fε = 0. (52)
Пусть наблюдаемой величиной является сумма ˇz сигналов объекта и тренда:
ˇz =z +ε.
Запишем уравнения для сигналов объекта и тренда в виде системы















ˇz = (I,I)
"
z
ε
#
,
 
G 0
0 F
!"
z
ε
#
= 0,
(53)
или, введя обозначения
P
.
=
 
G 0
0 F
!
, N
.
= (I,I), x
.
=
"
z
ε
#
,
получим систему

(
ˇz =Nx,
Px = 0.
(54)
Задача. По наблюдению ˇz при известных матрицах N, P восстановить
x.
Если задача вычисления x по предъявленному ˇz имеет единственное ре-
шение, будем говорить, что сигналы тренда ε и объекта z разделяемы.
6.2 Условия разделяемости
Получим условия разделяемости в виде условий на матрицы N, P.
Пусть наблюдение ˇz не содержит ошибок и точно удовлетворяет системе
(54) при некотором x (противоположный случай рассмотрен ниже в разде-
ле 6.4). Условие Px = 0 равносильно выполнению равенства x = P
⊥
χ при
некотором χ , и вычисление x сводится к вычислению χ . Из первого уравне-
ния системы (54) получаем
ˇz =NP
⊥
χ,
откуда следует искомое условие на матрицы N, P
⊥
:
Предложение 2. Задача вычисления сигналов x по наблюдениям ˇz имеет
единственноерешениетогдаитолькотогда,когдастолбцыматрицыNP
⊥
линейно независимы:
kerNP
⊥
= 0.
Утверждение 5. Следующие условия единственности равносильны:
kerNP
⊥
= 0, (55)
ker(G
⊥
,F
⊥
) = 0, (56)
ker
 
G
F
!
= 0, (57)
kerF ∩kerG = 0. (58)
Доказательство. 1) Равносильность (55) и (56) вытекает из определе-
ний:
P
⊥
.
=
 
G
⊥
0
0 F
⊥
!
, NP
⊥
= (G
⊥
,F
⊥
).

2)Длядоказательстваравносильности(55)и(58),установимравносильность
противоположных утверждений:
kerNP
⊥
6= 0 ⇔ kerF ∩kerG6= 0.
Переформулируемпоследнееутверждение,используяопределение(12)ирав-
носильность (55) и (56):
ker(G
⊥
,F
⊥
)6= 0 ⇔ imG
⊥
∩imF
⊥
6= 0.
Для доказательства этого соотношения заметим, что ker(G
⊥
,F
⊥
)6= 0 значит
G
⊥
x = F
⊥
y
.
= z для некоторых x, y, то есть imG
⊥
и imF
⊥
имеют общий
элемент z. Обратно, если z ∈ imG
⊥
∩ imF
⊥
6= 0, то z = G
⊥
x = F
⊥
y для
некоторыхx,y, следовательно, ker(G
⊥
,F
⊥
)6= 0. Тем самым, равносильность
(55) и (58) доказана.
3) Установим равносильность (57) и (56). От противного,
ker
 
P
N
!
6= 0 ⇔ ∃x6= 0
(
Px = 0,
Nx = 0,
⇔
⇔
(
x∈P
⊥
,
x∈N
⊥
,
⇔ x =P
⊥
χ =N
⊥
ω ⇔ ker(P
⊥
,N
⊥
)6= 0.
Утверждение доказано.
Отметим, что разделяемость сигналов тренда и системыравносильна ну-
левому пересечению многообразий трендов и траекторий системы (kerF ∩
kerG = 0).
6.2.1 Условие нулевого пересечения многообразий динамических траекторий
Рассмотрим случай, когда системы (51), (52) описывают многообразия
динамических траекторий. Это значит, что матрицы F и G имеют теплицев
вид (5) и соответствуют разностным уравнениям вида (1).
Пусть, в согласии с формой записи (9),
G =γ (s)⊗ E, F =φ (s)⊗ E. (59)
Утверждение 6. Условие kerF∩kerG = 0 равносильно тому, что канони-
ческаяформа Sm
 
γ (s)
φ (s)
!
длявсехsимеетлинейнонезависимыестолбцы:
∀s∈R kerSm
 
γ (s)
φ (s)
!
= 0. (60)

Последнее равносильно тому, что Sm
 
γ (s)
φ (s)
!
состоит только из нулей и
единиц и является “вертикальной” (число строк> числа столбцов).
Доказательство. Как несложно увидеть,
kerF ∩kerG = 0 ⇔ ker
 
G
F
!
= 0.
Далее,
 
G
F
!
=
 
γ (s)⊗ E
φ (s)⊗ E
!
=
 
γ (s)
φ (s)
!
⊗ E.
Следовательно, ker
 
G
F
!
= 0 означает, что система (1), соответствующая
составной матрице γ θ (s)
.
=
 
γ (s)
φ (s)
!
, имеет только нулевые траектории. По-
следнее равносильно тому, что каноническая форма Sm
 
γ (s)
φ (s)
!
для всех s
имеет линейно независимые столбцы, или (равносильно) состоит только из
нулей и единиц и является “вертикальной” (число строк> числа столбцов)
(см. раздел 1.2).
Утверждение доказано.
6.3 Восстановлениесигналов(фильтрациятренда)приизвестных
параметрах системы и точно известном суммарном сигнале
Запишем систему (53) в равносильном виде















ˇz =z +ε,
z =G
⊥
w,
ε =F
⊥
e.
(61)
При известном суммарном сигнале ˇz и известных матрицах G
⊥
, F
⊥
нужно
восстановить значения слагаемых z, ε (или w, e). Это задача косого проеци-
рования ˇz на направления imG
⊥
, imF
⊥
, или разложения ˇz в сумму
ˇz =G
⊥
w+F
⊥
e. (62)

Решение дается формулой (75):
F
⊥
e =F
⊥
 
F
T
⊥
G
⊥
G
⊥
T
F
⊥
 
− 1
F
T
⊥
G
⊥
G
⊥
T
ˇz,
G
⊥
w = ˇz− F
⊥
e
(см. приложение, раздел 8.2).
В силу соотношения 4 в предложении 1, предыдущее выражение можно
переписать в виде
F
⊥
e =F
⊥
(F
T
⊥
G
T
GF
⊥
)
− 1
F
T
⊥
G
T
Gˇz. (63)
Операция обращения выполнима при условии kerGF
⊥
= 0.
Предложение. (56), (57) ⇒ kerGF
⊥
= 0.
Доказательство. Согласно определению символа ker, имеем
kerA = 0, kerB = 0 ⇒ kerAB = 0. (64)
Далее положим A =
 
G
F
!
, B = (G
⊥
,F
⊥
). Тогда
AB =
 
G
F
!
(G
⊥
,F
⊥
) =
 
0 GF
⊥
FG
⊥
0
!
.
Ввиду (56), (57) и (64),
ker
 
0 GF
⊥
FG
⊥
0
!
= 0,
тогда kerGF
⊥
= 0.
Предложение доказано.
Несложноувидеть,чтовсематрицыипроизведения,входящиевформулу
(63),имеютпростуюструктуру,ивычислениялегковыполнимыпрактически
для любых размерностей вектора ˇz (см. пример в разделе 6.6).
6.4 Восстановление сигналов, если суммарный сигнал известен
неточно
Пусть наблюдение ˇz содержит аддитивные ошибки и не удовлетворяет
системе (54). Рассмотрим задачу восстановления x по неточным измерениям

ˇz посредством условной минимизации квадратичной функции потерь
(
J(x) =kˇz− Nxk
2
,
Px = 0.
(65)
Введем строку множителей Лагранжа λ и запишем необходимое условие ми-
нимума в виде равенства нулю производных по x и по λ расширенной функ-
ции потерь
J
∗ =kˇz− Nxk
2
+λPx,
(
J
∗ x
= 2(ˇz− Nx)
T
N +λP = 0,
J
∗ λ =Px = 0.
(66)
Умножая обе части первого уравнения системы (66) справа на P
⊥
, получим
равенство
(ˇz− Nx)
T
NP
⊥
= 0,
откуда следует
P
T
⊥
N
T
Nx =P
T
⊥
N
T
ˇz.
Записав второе уравнение системы (66) в виде x =P
⊥
χ , получим
P
T
⊥
N
T
NP
⊥
χ =P
T
⊥
N
T
ˇz. (67)
Однозначное вычисление величин χ и x из последнего уравнения возможно
тогда и только тогда, когда матрица P
T
⊥
N
T
NP
⊥
обратима, что равносильно
линейной независимости столбцов NP
⊥
.
Таким образом, предложение 2 и утверждение 5 остаются в силе и в слу-
чае восстановления x по неточным измерениям ˇz посредством условной ми-
нимизации квадратичной функции потерь (65).
Обозначим ˆ z отфильтрованное значение (оценку) суммарного сигнала ˇz,
полученную по формулам (65), (67):
ˆ z =Nx =NP
⊥
χ =NP
⊥
(P
T
⊥
N
T
NP
⊥
)
− 1
P
T
⊥
N
T
ˇz.
Заметим, что столбцы матрицы NP
⊥
.
= Σ ⊥
являются базисом многообра-
зия решений суммарной системы (сигнал плюс тренд). Как показано в сле-
дующем разделе 6.5, для суммарной системы всегда существует матрица Σ описания с клеточно-теплицевой структурой:
kerΣ = imΣ ⊥
= imNP
⊥
.

Тогда
ˆ z =
 
I− Σ T
(ΣΣ T
)
− 1
Σ  
ˇz,
где
Π .
=I− Σ T
(ΣΣ T
)
− 1
Σ есть матрица проектора на подпространство imΣ ⊥
. Устойчивые алгоритмы
вычисления проекции ˆ z для клеточно-теплицевых матриц Σ описаны в [3].
Сложность программной реализации обсуждалась в [11].
Проекция ˆ z по построению точно удовлетворяет системе уравнений (54).
Поэтомудляотфильтрованногозначения ˆ z суммарногосигнала ˇz верныфор-
мулы восстановления тренда (62), (63) с заменой ˇz на ˆ z.
6.5 Описания суммарных систем
Пусть G, F   матрицы системы (53).
1. Множество решенийN
Σ .
={ˇz =z +ε} представимо в виде суммы
N
Σ = kerF +kerG.
Описанием для N
Σ по определению является матрица Σ , строки которой
образуют базис подпространства kerF +kerG (см. раздел 1.1):
spanrΣ = kerF +kerG = kerF ∩kerG = spanrF ∩spanrG. (68)
2. Пусть G, F   клеточно-теплицевые матрицы. Покажем, что в этом
случаесуммарноемножествоN
Σ = kerF +kerGвсегдаможноописатьнеко-
торой системой уравнений с клеточно-теплицевой матрицей.
Утверждение 7. Суммарное многообразие N
Σ = kerF + kerG является
множеством решений некоторой стационарной динамической системы с
клеточно-теплицевой матрицейΣ :
kerΣ =N
Σ .
Доказательство. Нужно показать, что подпространство
spanrF ∩ spanrG имеет базис с клеточно-теплицевой структурой. Пусть G
i
иF
i
 клеточныестрокиматрицGиF,ипустьh группастрок(клеточная
строка) из пересечения spanrF ∩spanrG:
h =
X
λ i
G
i
=
X
μ j
F
j
. (69)

Клеточно-теплицевость G и F означает, что ˆ sG
i
= G
i+1
, ˆ sF
i
= F
i+1
, где ˆ s  
оператор сдвига. Следовательно, клеточная строка
ˆ sh =
X
λ i
G
i+1
=
X
μ i
F
i+1
(70)
принадлежит пересечению вместе с h. В силу произвольности h заключаем,
что пересечение spanrF∩spanrG имеет базис с клеточно-теплицевой струк-
турой.
Есливразложениях(69)номерiпринимаетнаибольшеезначение,равное
числуклеточныхстрокGилиF,тозаписьG
i+1
илиF
i+1
теряетсмысл.Вэтом
случае следует заменить h на строку ˆ s
− 1
h. Если в разложениях (69) номер
i принимает значение i = 1, так что запись ˆ s
− 1
h теряет сысл, то следует h
разложить в сумму h = h
0
+ ˆ sh
1
, используя клеточные строки h
0
, h
1
, для
которых запись (70) имеет смысл, и рассматривать для включения в базис
вместо h клеточные строки h
0
, h
1
.
Утверждение доказано.
3. Дляклеточно-теплицевыхматрицF,G,Σ выразимсоотношение(68)
через образующие многочленные матрицы.
Утверждение 8. Пусть G, F   клеточно-теплицевые матрицы (см. (9)):
G
.
=γ ⊗ E, γ ∈R
r× t
[s],
F
.
=ϕ⊗ E, ϕ∈R
q× t
[s].
Тогда
1) существует клеточно-теплицевая матрицаΣ :
kerΣ = kerF +kerG,
Σ .
=σ ⊗ E, σ ∈R
k× t
[s];
2) строки многочленной матрицы σ (s) являются базисом пересечения
линейных оболочек многочленных строк матриц ϕ(s), α (s):
spanrσ (s) = spanrϕ(s)∩spanrα (s);
3) k6 min{q,r}.

Доказательство. 1) См. утверждение 7. 2) В силу соотношения (68),
spanrΣ = (spanrϕ(s)⊗ E)∩(spanrα (s)⊗ E) =
= (spanrϕ(s)∩spanrα (s))⊗ E.
Тогда
spanrσ (s) = spanrϕ(s)∩spanrα (s). (71)
3) Соотношение k6 min{q,r} следует из (71).
Утверждение доказано.
Соотношение(71)показывает,чтострокиобразующеймногочленноймат-
рицы σ (s) образуют базис пересечения линейных оболочек строк многочлен-
ныхматрицϕ(s)иα (s).Этосоотношениеявляетсяосновнымдляпостроения
описаний суммарных систем.
Примерыпостроенияописанийсуммарныхсистемприведенывприложе-
нии, раздел 8.3.
Суммарные системы неуправляемы
Примеры описаний суммарных систем из приложения, раздел 8.3, явля-
ются иллюстрацией к следующему утверждению.
Теорема 6. Пусть
G
.
=γ ⊗ E, γ ∈R
1× t
[s],
F
.
=ϕ⊗ E ϕ∈R
q× t
[s],
и существует описаниеΣ 6= 0 для суммарного многообразия
kerG+kerF = kerΣ .
Тогда
1)Σ =σ ⊗ E, σ ∈R
k× t
[s], k = 1;
2) многочленная матрица σ разлагается в произведение
σ =μγ, μ ∈R[s],
то есть суммарная системаΣ неуправляема в смысле предложения 5.
Доказательство. 1) См. утверждение 8. 2) Согласно утверждению 8,
σ ⊆ spanrγ ∩spanrϕ.

Пересечение spanrγ ∩spanrϕ образовано многочленными строками из неко-
торого множества
ργ, ρ ∈P ⊂ R[s].
Следовательно,
σ =μγ, μ ∈M ⊂ R[s],
M ⊆ P.
Отсюда следует утверждение теоремы.
6.6 Примеры задач восстановления тренда
1. Рассмотримпространствотраекторийиз5отсчетов ˇz∈R
5
.Всистеме
(53) примем
G =
 
a − 1 0 b 0
0 a − 1 0 b
!
= (α (s),β (s))⊗ E,
α (s) =a− s, β (s) =b,
тогда запись (1) имеет вид
y
k+1
− ay
k
=bu
k
, k = 1,2.
Рассмотрим три варианта описания трендов:
F
1
=






1 0 0 0
1 0 0
0 1 0 0
0 0 0 1 − 1






=
 
1 0
0 ϕ(s)
!
⊗ E,
ϕ(s) = 1− s,
F
2
=






1 − 1 0 0 0
0 1 − 1 0 0
0 0 0 1 0
0 0 0 0 1






=
 
ϕ(s) 0
0 1
!
⊗ E,
F
3
=



1 − 1 0 0 0
0 1 − 1 0 0
0 0 0 1 − 1



=
 
ϕ(s) 0
0 ϕ(s)
!
⊗ E.

Какпоказановприложении(раздел8.1),всетривариантасоответствуютод-
номуитомужесуммарномумногообразиютраекторийтрендплюсполезный
сигнал.
Выпишем матрицы базисов правых нуль-пространств:
G
⊥
=








1 0 0
a b 0
a
2
ab b
0 1 0
0 0 1








,
F
1⊥
=








0
0
0
1
1








, F
2⊥
=








1
1
1
0
0








, F
3⊥
=








1 0
1 0
1 0
0 1
0 1








.
Проверим условия единственности восстановления тренда согласно (60):
 
γ (s)
φ 1
(s)
!
=



α (s) β (s)
1 0
0 ϕ(s)



,
Sm



α (s) β (s)
1 0
0 ϕ(s)



=



1 0
0 σ (s)
0 0



, σ (s) =НОД(M
1
,M
2
,M
3
),
M
1
.
=
 
 
 
 
 
1 0
0 ϕ
 
 
 
 
 
, M
2
.
=
 
 
 
 
 
α β 0 ϕ
 
 
 
 
 
, M
3
.
=
 
 
 
 
 
α β 1 0
 
 
 
 
 
,
⇒σ (s) =НОД(ϕ,αϕ,β ) = 1.
Условие (60) выполнено, следовательно, тренд с описанием F
1
отделяем.
ПохожимобразомпроверяетсяотделяемостьтрендасописаниемF
2
(опу-
щено).
Проверим условие отделяемости (56) для описаний F
1
, F
2
. Пусть “∼ ”
обозначает какую-либо последовательность операций перестановки строк и

столбцов матрицы.
(G
⊥
,F
1⊥
) =








1 0 0 0
a b 0 0
a
2
ab b 0
0 1 0 1
0 0 1 1








∼ 







1 0
∗ b
∗ ∗ b
∗ ∗ ∗ 1
∗ ∗ ∗ ∗ 







,
очевидно,приb6= 0столбцы(G
⊥
,F
1⊥
)линейнонезависимы,иker(G
⊥
,F
1⊥
) =
0, условие (56) выполнено.
Далее,
(G
⊥
,F
2⊥
) =








1 0 0 1
a b 0 1
a
2
ab b 1
0 1 0 0
0 0 1 0








∼ 







∗ ∗ ∗ ∗ 1 1 ∗ ∗ a 1 ∗ ∗ 0 0 1 0
0 0 0 1








.
Приa6= 1подматрица
 
1 1
a 1
!
неособенная,следовательно,столбцы(G
⊥
,F
2⊥
)
линейно независимы, и ker(G
⊥
,F
2⊥
) = 0, условие (56) выполнено.
Покажем, что тренд с описанием F
3
не отделяем. Действительно,
 
γ (s)
φ 3
(s)
!
=



α (s) β (s)
ϕ(s) 0
0 ϕ(s)



,
Sm



α (s) β (s)
ϕ(s) 0
0 ϕ(s)



=



1 0
0 σ 3
(s)
0 0



, σ 3
(s) =НОД(M
1
,M
2
,M
3
),
M
1
.
=
 
 
 
 
 
ϕ 0
0 ϕ
 
 
 
 
 
, M
2
.
=
 
 
 
 
 
α β 0 ϕ
 
 
 
 
 
, M
3
.
=
 
 
 
 
 
α β ϕ 0
 
 
 
 
 
,
⇒ σ 3
(s) =НОД
 
ϕ
2
,αϕ,βϕ
 
=ϕ.
Условие(60)невыполнено,следовательно,трендсописаниемF
3
неотделяем.

Для описания F
3
убедимся также в нарушении условия (56):
(G
⊥
,F
3⊥
) =








1 0 0 1 0
a b 0 1 0
a
2
ab b 1 0
0 1 0 0 1
0 0 1 0 1








, x
.
=








 
b
1− a
 
1
1
−  
b
1− a
 
− 1








,
(см. пример к утверждению 9, приложение, раздел 8.1).
(G
⊥
,F
3⊥
)x = 0 ⇒ ker(G
⊥
,F
3⊥
)6= 0,
условие (56) нарушено.
Для систем с описаниями трендов F
1
, F
2
выпишем формулы (63) восста-
новления трендов:
F
(1,2)⊥
e =F
(1,2)⊥
 
F
T
(1,2)⊥
G
T
GF
(1,2)⊥
 
− 1
F
T
(1,2)⊥
G
T
Gˇz,
GF
1⊥
=
 
a − 1 0 b 0
0 a − 1 0 b
!








0
0
0
1
1








=
 
b
b
!
,
GF
2⊥
=
 
a − 1 0 b 0
0 a − 1 0 b
!








1
1
1
0
0








=
 
a− 1
a− 1
!
,
⇒ F
1⊥
e =








0
0
0
1
1








1
2b
2
 
b, b
 
Gˇz,

⇒ F
2⊥
e =








1
1
1
0
0








1
2(a− 1)
2
 
a− 1, a− 1
 
Gˇz.
Ввиду клеточно-теплицевой структуры матрицы G, невязка Gˇz может вы-
числяться рекуррентно по мере поступления новых отсчетов ˇz.
Полученные выражения для трендов F
1⊥
e и F
2⊥
e показывают, что в пер-
вом случае отделяется тренд (постоянная составляющая) в сигнале выхода
y, а во втором случае   тренд в сигнале входа u. Нарушение условий от-
деляемости трендов с описанием F
3
означает невозможность однозначного
отделения постоянных составляющих одновременно на входе и на выходе.
2. Пусть параметры a, b уравнения системы неизвестны.
Задача. По наблюдениям ˇz = z +ε суммарного сигнала системы (53)
вычислить вектор параметров θ = (a;b), траекторию z и тренд ε.
Увеличим размерность пространства траекторий: ˇz∈R
9
. Тогда
G =






a − 1 0 b 0
a − 1 b
a − 1 b
0 a − 1 0 b






.
Будемсчитать,чтопостояннаясоставляющаятрендаприсутствуеттолькона
выходе системы:
Fε = 0,
F =F
2
=















1 − 1 0
1 − 1
1 − 1
0 1 − 1
0
0
1 0
1
1
0 1















.

Построим матрицу Σ описания суммарной системы, следуя примеру Б
раздела 8.3 в приложении:
Σ = (ϕα,ϕβ )⊗ E =
=
 
s
2
− (a+1)s+a, b− bs
 
⊗ E =
=



a − (a+1) 1 0 b − b 0
a − (a+1) 1 b − b
0 a − (a+1) 1 0 b − b



.
Если наблюдения ˇz содержат стохастические возмущения:
ˇz =z +ε+η, η ∈N(0,σ 2
I),
  можно поставить и решать задачу оценки параметровa,b орторегрессион-
ными методами (раздел 1.3).
Если суммарный сигнал ˇz известен точно (η = 0), вектор параметров
(a;b) вычисляется из переопределенной системы линейных уравнений
Σ ˇz =Vγ =V
 
d+D
 
a
b
!!
= 0,
ˇz
.
= (ˇy
1
;ˇy
2
;ˇy
3
;ˇy
4
;ˇy
5
;ˇu
1
;ˇu
2
;ˇu
3
;ˇu
4
),
V
.
=



ˇy
1
ˇu
1
ˇy
2
ˇu
2
ˇy
3
ˇu
3
ˇy
2
ˇu
2
ˇy
3
ˇu
3
ˇy
4
ˇu
4
ˇy
3
ˇu
3
ˇy
4
ˇu
4
ˇy
5
0



, (72)
γ =










a
b
− (a+1)
− b
1
0










=










0
0
− 1
0
1
0










+










1 0
0 1
− 1 0
0 − 1
0 0
0 0










 
a
b
!
.
=d+D
 
a
b
!
.
Решение имеет вид
 
a
b
!
=− (D
T
V
T
VD)
− 1
D
T
V
T
Vd.

Постояннаясоставляющаятрендаε =F
2⊥
e,какбылопоказановыше,вычис-
ляется из уравнения
F
2⊥
e =F
2⊥
(F
T
2⊥
G
T
GF
2⊥
)
− 1
F
T
2⊥
G
T
Gˇz,
GF
2⊥
=






a − 1 0 b 0
a − 1 b
a − 1 b
0 a − 1 0 b
























1
1
1
1
1
0
0
0
0


















=






a− 1
a− 1
a− 1
a− 1






,
⇒ F
2⊥
e =


















1
1
1
1
1
0
0
0
0


















1
4(a− 1)
2
 
a− 1, a− 1, a− 1, a− 1
 
Gˇz.
3. Рассмотрим пример, в котором параметры объекта известны:
a = 0.99, b = 1,
G =
 
α (s), β (s)
 
⊗ E =
 
0.99− s, 1
 
⊗ E =
=






0.99 − 1 0 1 0
0.99 − 1 1
0.99 − 1 1
0 0.99 − 1 0 1






  и надлежит оценить парметры ϕ
0
, ϕ
1
уравнения тренда:
ϕ(s) =ϕ
0
+ϕ
1
s+s
2
,

F =
 
ϕ(s) 0
0 1
!
⊗ E =













ϕ
0
ϕ
1
1 0
ϕ
0
ϕ
1
1
0 ϕ
0
ϕ
1
1
0
0
1 0
1
1
0 1













.
Как и ранее, измерению доступен суммарный сигнал ˇz =z +ε.
Задача. По наблюдениям ˇz = z +ε суммарного сигнала системы (53)
вычислить вектор параметров уравнения тренда θ = (ϕ
0
;ϕ
1
), траекторию z
и тренд ε.
Построим матрицу описания суммарной системы:
Σ = (ϕα,ϕβ )⊗ E =
=
 
0.99ϕ
0
+(0.99ϕ
1
− ϕ
0
)s+(0.99− ϕ
1
)s
2
− s
3
, ϕ
0
+ϕ
1
s+s
2
 
⊗ E =
 
0.99ϕ
0
(0.99ϕ
1
− ϕ
0
) (0.99− ϕ
1
) − 1 0 ϕ
0
ϕ
1
1 0
0 0.99ϕ
0
(0.99ϕ
1
− ϕ
0
) (0.99− ϕ
1
) − 1 0 ϕ
0
ϕ
1
1
!
.
Пусть суммарный сигнал ˇz известен точно (η = 0). Тогда вектор па-
раметров θ = (ϕ
0
;ϕ
1
) вычисляется из переопределенной системы линейных
уравнений
Σ ˇz =Vγ =V
 
d+D
 
ϕ
0
ϕ
1
!!
= 0,
с вектором наблюдений ˇz и матрицей V (72). Выпишем вектор d и матрицу
D:
γ =















0.99ϕ
0
ϕ
0
(0.99ϕ
1
− ϕ
0
)
ϕ
1
(0.99− ϕ
1
)
1
− 1
0















=















0
0
0
0
0.99
1
− 1
0















+















0.99 0
1 0
− 1 0.99
0 1
0 − 1
0 0
0 0
0 0















 
ϕ
0
ϕ
1
!
.
=d+D
 
ϕ
0
ϕ
1
!
.

Решение имеет вид
 
ϕ
0
ϕ
1
!
=− (D
T
V
T
VD)
− 1
D
T
V
T
Vd.
После восстановления параметров (ϕ
0
;ϕ
1
) выписываются элементы фор-
мул отделения тренда:
G
⊥
=


















1 0 0
0.99 1
0.99
2
0.99 1
0.99
3
0.99
2
0.99 1
0.99
4
0.99
3
0.99
2
0.99 1
0 1 0
0 1
0 1
0 0 1


















, F
⊥
=


















1 1
ρ μ ρ 2
μ 2
ρ 3
μ 3
ρ 4
μ 4
0 0
0 0
0 0
0 0


















,
где ρ , μ   корни многочлена ϕ(s) =ϕ
0
+ϕ
1
s+s
2
(см. раздел 1.2).
Постоянная составляющая тренда ε =F
⊥
e вычисляется из уравнения
F
⊥
e =F
⊥
(F
T
⊥
G
T
GF
⊥
)
− 1
F
T
⊥
G
T
Gˇz.
Заметим, что в данном примере все оцениваемые параметры сосредото-
чены в “неуправляемой” части ϕ описания суммарной системы:
(ϕα,ϕβ ) =ϕ(α,β ).
Предположим, что наблюдения ˇz содержат стохастические возмущения
того или иного рода. Тогда значения ϕ
0
, ϕ
1
вычисляются как предельные
значения некоторой последовательности, построенной согласно бесконечно
растущему объему измерительной выборки. Здесь возможны два случая:
1) число L траекторий ˇz конечно, объем выборки определяется длиной
траекторий N →∞;
2) длина траекторий N конечна, объем выборки определяется числом
траекторий L→∞.
Есликорниρ ,μ многочленаϕ(s)лежатвнутриединичногокруга(|ρ |< 1,
|μ | < 1), то в пределе N → ∞ сигналы тренда, будучи экспоненциальными

траекториями (раздел 1.2), сходятся к нулю в средне-квадратическом:
lim
N→∞
1
N
kεk
2
= 0.
Это делает невозможным оценку параметров ϕ
0
, ϕ
1
любым методом, пред-
полагающим статистический предел 1-го рода (N → ∞) (например, [20, 21,
22,23]).Следовательно,статистическисостоятельныеоценкипараметровϕ
0
,
ϕ
1
уравнения тренда могут быть получены только по траекториям конечной
длины N. Это приводит к необходимости обратиться к методам 2-го рода,
например, орторегрессионным (ОР, М, ВИ) при аддитивных ошибках изме-
рений [3, 4, 5, 6, 7, 8, 11], или к линейному методу наименьших квадратов в
случае возмущений в невязке уравнения.
7 Заключение
Для оценки параметров динамичесих систем в темпе реального процес-
са, при отслеживании меняющихся характеристик динамических объектов
особую значимость приобретают методы идентификации по коротким запи-
сям участков переходных процессов. Состоятельное оценивание параметров
в этих условиях возможно только совместно с оценкой начальных условий
собственных однородных движений объекта. Оценки получаются минимиза-
цией нелинейной функции потерь. Среди большого разнообразия подходов к
решениюзадачэтоготипаособоеместозанимаюторторегрессионныеметоды
идентификации. Постановки задачи минимизации и типы функций потерь,
свойственные этим методам, приводят к итеративным алгоритмам вычисле-
ний с гарантированной сходимостью.
Разные варианты орторегрессионных методов отличаются друг от друга
вычислительной сложностью и асимптотическими свойствами оценок. Срав-
нение их затруднено ввиду нелинейного характера функции потерь. Предло-
жена схема сравнения методов по линейным приближениям, в предельных
случаях большого объема измерительной выборки и малых возмущений. Ли-
нейныеприближенияоценоксравниваютсяпостепенииспользованияинфор-
мации о линейных связях в наблюдениях. Показано, что с этой характери-
стикой напрямую связана дисперсия оценок.
Средиорторегрессионныхметодовоцениванияметодвариационнойиден-
тификации [3, 10, 11] отличается наиболее полным использованием инфор-
мации вида Mw = 0 о структуре линейного динамического объекта. Это

позволяет на коротких участках переходных процессов за счет более интен-
сивных вычислений получать состоятельные оценки параметров с лучшими
характеристиками.
Возможность получать состоятельные оценки параметров по отрезкам
траекторийконечнойдлиныпозволяетввестиврассмотрениеновыйклассза-
дач идентификации систем без свойств устойчивости и управляемости. При-
меромтакогородазадачявляютсязадачиотделениядинамическихтрендовв
измерениях траекторий динамического объекта. Получены условия разделя-
емости тренда и полезного сигнала в терминах матриц уравнения объекта и
уравнения тренда. Предложены явные формулы фильтрации тренда при из-
вестныхуравненияхтрендаиобъекта,атакжеалгоритмывычисления(иден-
тификации) неизвестных параметров уравнений объекта и тренда на основе
орторегрессионных методов.
8 Приложение
8.1 Два утверждения о свойствах динамических систем
Пусть для линейных подпространств X, Y запись (X;Y) означает мно-
жество векторов в пространстве суммарной размерности dimX +dimY:
(X;Y)
.
={(x;y)|x∈X,y∈Y}.
Обозначим N
γ .
= kerγ (s)⊗ E множество решений линейной динамической
системы с матрицей G =γ (s)⊗ E (см. (9)).
Утверждение 9. Пусть
γ (s) = (α (s),β (s))∈R
1× 2
[s],
ϕ(s)∈R[s].
Тогда
N
γ ⊃ (CN
ϕ
;N
ϕ
),
где C   матрица оператора
c : N
ϕ
→N
ϕ
с характеристическими числами
λ i
=− β (z
i
)
α (z
i
)
, i∈ 1,q, q
.
= degϕ(s), ϕ(z
i
) = 0,

и собственными векторами
u
i
=
 
z
0
i
;...;z
N− 1
i
 
, i∈ 1,q.
Другими словами, среди решений системы z ∈ N
γ для произвольного
могочлена ϕ(s) всегда найдутся траектории вида z = (w;u), u,w∈N
ϕ
, w =
Cu.
Доказательство. Пусть u =
 
z
0
;...;z
N− 1
 
для некоторого z ∈C. То-
гда ˆ su =zu, ˆ s   оператор сдвига, и (β (ˆ s)⊗ E)u =β (z)u. С другой стороны,
(α (ˆ s)⊗ E)u = α (z)u, следовательно, составной вектор x =
 
− β (z)
α (z)
u;u
 
яв-
ляется решением системы (γ (s)⊗ E)x = 0. Подставляя вместо z корни z
i
многочлена ϕ(s), получим доказываемое утверждение.
Пример. Пусть
α (s) =s+α 0
, β (s) =s+β 0
, ϕ(s) =s− ϕ
0
.
Заметим,
 
1;ϕ
0
;ϕ
2
0
 
∈N
ϕ
. Убедимся, что траектория
 
c
0
 
1;ϕ
0
;ϕ
2
0
 
;
 
1;ϕ
0
;ϕ
2
0
  
для некоторого числа c
0
является решением линейной системы с матрицей
γ (s)⊗ E. Для этого проверим равенство
 
α 0
1 0 β 0
1 0
0 α 0
1 0 β 0
1
!













1
ϕ
0
ϕ
2
0



c
0



1
ϕ
0
ϕ
2
0













= 0.
Действительно, последнее равносильно системе уравнений
(
(α 0
+ϕ
0
)c
0
+(β 0
+ϕ
0
) = 0,
ϕ
0
(α 0
+ϕ
0
)c
0
+ϕ
0
(β 0
+ϕ
0
) = 0,
откуда следует c
0
=− (β 0
+ϕ
0
)
(α 0
+ϕ
0
)
=− β (ϕ
0
)
α (ϕ
0
)
, где ϕ
0
  корень многочлена ϕ(s).
Утверждение 10. N
γ +(N
ϕ
;N
ϕ
) =N
γ +(N
ϕ
;0) =N
γ +(0;N
ϕ
).

Доказательство. Согласно утверждению 9, N
γ ⊃ (CN
ϕ
;N
ϕ
). Следо-
вательно,
N
γ +(N
ϕ
;0) =N
γ +(CN
ϕ
;N
ϕ
)+(N
ϕ
;0) =N
γ +(N
ϕ
;N
ϕ
).
Так же доказывается равенство
N
γ +(0;N
ϕ
) =N
γ +(N
ϕ
;N
ϕ
).
Утверждение доказано.
Другимисловами,установленоследующее.Пустьданомногообразиесиг-
налов системыN
γ , и мы хотим “обогатить” его сигналами трендов
N
τ .
= (N
ϕ
;N
ϕ
)
досуммыN
γ +N
τ .Оказывается,дляэтогодостаточнокN
γ прибавитьлюбое
из двух “усеченных” многообразий
N
τ 1
= (0;N
ϕ
),
N
τ 2
= (N
ϕ
;0).
8.2 Формулы косого проецирования
Выпишем формулы разложения вектора z ∈ R
n
на непрямую сумму
z = z
A
+ z
B
, z
A
∈ imA, z
B
∈ imB, где A, B   матрицы, столбцы кото-
рых образуют базисR
n
: im(A,B) =R
n
, imA∩imB = 0.
Выразим проекции z
A
, z
B
. Обозначим
z
A
.
=Aϕ, z
B
.
=Bψ.
Ясно, что
A
T
z =A
T
z
B
=A
T
Bψ, (73)
следовательно,
ψ =
 
A
T
B
 
− 1
A
T
z (74)
z
B
=Bψ =B
 
A
T
B
 
− 1
A
T
z.
Аналогично,

z
A
=z− z
B
=
 
I− B
 
A
T
B
 
− 1
A
T
 
z.
С другой стороны,
z
A
=Aϕ =A
 
B
T
A
 
− 1
B
T
z.
Следовательно, для определенных выше матриц имеем тождества
I− B
 
A
T
B
 
− 1
A
T
≡ A
 
B
T
A
 
− 1
B
T
.
I− A
 
B
T
A
 
− 1
B
T
≡ B
 
A
T
B
 
− 1
A
T
.
Несложнопроверитьэтитождествадляслучая,когдастолбцысоставной
матрицы (A,B) образуют ортогональный базис R
n
, то есть B = A, A = B
(проверку опускаем).
Таким образом, формулы
z
B
=B
 
A
T
B
 
− 1
A
T
z =
 
I− A
 
B
T
A
 
− 1
B
T
 
z,
z
A
=z− z
B
=
 
I− B
 
A
T
B
 
− 1
A
T
 
z =A
 
B
T
A
 
− 1
B
T
z
определяют косое проецирование в R
n
на подпространства imB, imA для
описанных выше матриц A, B.
Пусть теперь A, B   матрицы, столбцы которых не образуют базисR
n
:
im(A,B)⊂ R
n
, dimim(A,B)<n, ker(A,B) = 0, imA∩imB = 0.
МатрицаA
T
Bвэтомслучаенеявляетсяквадратной,ивыражение(74)теряет
смысл. Ввиду (11),
imA∩imB = 0 ⇔ kerA
T
B = 0.
Учитывая, что kerA
T
B = 0, из (73) получаем:
B
T
AA
T
z =B
T
AA
T
Bψ,
ψ =
 
B
T
AA
T
B
 
− 1
B
T
AA
T
z,

z
B
=B
 
B
T
AA
T
B
 
− 1
B
T
AA
T
z. (75)
Аналогично
z
A
=A
 
A
T
B B
T
A
 
− 1
A
T
B B
T
z.
Используя равенство z =z
A
+z
B
, получаем другую пару соотношений:
z
B
=z− z
A
=
 
I− A
 
A
T
B B
T
A
 
− 1
A
T
B B
T
 
z,
z
A
=z− z
B
=
 
I− B
 
B
T
AA
T
B
 
− 1
B
T
AA
T
 
z.
8.3 Примерыописанийдлясумммногообразийдинамическихтра-
екторий
Пример А. Рассмотрим системы с матрицами
F =ϕ(s)⊗ E, ϕ(s) =s
2
+ϕ
1
s+ϕ
0
,
G =α (s)⊗ E, α (s) =s
2
+α 1
s+α 0
.
НОД(α,ϕ ) = 1.
Пусть N = 6, тогда
F =






ϕ
0
ϕ
1
1 0
ϕ
0
ϕ
1
1
ϕ
0
ϕ
1
1
0 ϕ
0
ϕ
1
1






, G =






α 0
α 1
1 0
α 0
α 1
1
α 0
α 1
1
0 α 0
α 1
1






.
1. Согласно утверждениям раздела 1.2, множество решений системы
Fx = 0 состоит из векторов
x = (x(1);...;x(5)), x(t) =x
01
s
t
1
+x
02
s
t
2
, t∈ 1,5,
где x
01
, x
02
  произвольные числовые коэффициенты начальных условий,
s
1,2
  корни многочлена ϕ(s).
Множество решений системы Gy = 0 состоит из векторов
y = (y(1);...;y(5)), y(t) =y
01
s
t
3
+y
02
s
t
4
, t∈ 1,5,

гдеy
01
,y
02
 произвольныечисловыекоэффициентыначальныхусловий,s
3,4
  корни многочлена α (s).
Суммарное множество{z} ={x}+{y} состоит из векторов
z = (z(1);...;z(5)),
z(t) =x
01
s
t
1
+x
02
s
t
2
+y
01
s
t
3
+y
02
s
t
4
, t∈ 1,5, (76)
где x
01
, x
02
, y
01
, y
02
  произвольные числовые коэффициенты начальных
условий, {s
1
,...,s
4
}   объединение множеств корней многочленов ϕ(s) и
α (s).
Исходя из (76) заключаем, что суммарное множество {z} является мно-
жеством решений системы уравненийΣ z = 0 с теплицевой матрицейΣ , со-
ставленной из коэффициентов многочлена σ (s) =ϕ(s)α (s):
Σ = (ϕ(s)α (s))⊗ E =
 
σ 0
σ 1
σ 2
σ 3
1 0
0 σ 0
σ 1
σ 2
σ 3
1
!
.
2. Изложим еще один способ построения описания суммарной системы,
основанный на аргументах более общего вида.
Согласно утверждению 8,
Σ =σ (s)⊗ E,
spanrσ (s) = spanrϕ(s)∩spanrα (s).
Подпространство spanrϕ(s) образовано многочленами pϕ, p ∈ R[s]. Анало-
гично, подпространство spanrα (s) образовано многочленами qα , q ∈ R[s].
Пересечением этих подпространств является множество многочленов rϕα ,
r ∈R[s]. Базисом пересечения является многочлен σ = ϕα , которому соот-
ветствует числовая теплицевая матрицаΣ = (ϕ(s)α (s))⊗ E.
3. Заметим, что многообразия траекторий kerG и kerF имеют нулевое
пересечение, так как это следует из утверждения 6:
Sm
 
α (s)
ϕ(s)
!
=
 
1
0
!
⇒ kerG∩kerF = 0.

Пример Б. Рассмотрим две динамические системы с матрицами F, G:
G
.
= (α,β )⊗ E, (77)
α =α (s) =s
2
+α 1
s+α 0
, β =β (s) =s
2
+β 1
s+β 0
,
F
.
=
 
ϕ 0
0 ζ !
⊗ E, (78)
ϕ =ϕ(s) =s
2
+ϕ
1
s+ϕ
0
, ζ =ζ (s) =s
2
+ζ 1
s+ζ 0
,
НОД(α,β,ζ,ϕ ) = 1.
Пусть N = 5, тогда
G =



α 0
α 1
1 0 β 0
β 1
1 0
α 0
α 1
1 β 0
β 1
1
0 α 0
α 1
1 0 β 0
β 1
1



,
F =










ϕ
0
ϕ
1
1 0
ϕ
0
ϕ
1
1
0 ϕ
0
ϕ
1
1
0
0
ζ 0
ζ 1
1 0
ζ 0
ζ 1
1
0 ζ 0
ζ 1
1










.
Система с матрицей G имеет порядок p = 2 в числителе и знаменателе.
Уравнение (1) для нее имеет вид:
y
k+2
+α 1
y
k+1
+α 0
y
k
=u
k+2
+β 1
u
k+1
+β 0
u
k
, k∈ 1,3.
Множество траекторий системы с матрицей F состоит из независимых
однородных движений y
0
, u
0
на входе и выходе. Они описываются уравнени-
ями
y
0
k+2
+ϕ
1
y
0
k+1
+ϕ
0
y
0
k
= 0,
u
0
k+2
+ζ 1
u
0
k+1
+ζ 0
u
0
k
= 0, (79)
k∈ 1,3.
Заданиемкоэффициентовϕ
i
,ζ i
можноопределить,например,чтобымно-
жество решений{y
0
} (или{u
0
}) состояло:

1. из многочленов с действительными коэффициентами порядка не выше
заданного (в данном примере6 2);
2. изгармоническихсигналовсэкспоненциальнымзатуханием(нарастани-
ем) амплитуды
(см. раздел 1.2).
1. Построим описаниеΣ для суммарного многообразия траекторий
{z =z +z
0
} = kerG+kerF, z
.
= (y;u), z
0
.
= (y
0
;u
0
).
Согласно утверждению 8,
Σ =σ (s)⊗ E,
spanrσ (s) = spanr(α,β )∩spanr
 
ϕ 0
0 ζ !
, (80)
Подпространство spanr(α,β ) состоит из строк
(rα,rβ ), r∈R[s].
Подпространство spanr
 
ϕ 0
0 ζ !
состоит из строк
(pϕ,qζ ), p,q∈R[s].
Пересечение spanr(α,β )∩spanr
 
ϕ 0
0 ζ !
состоит из строк
(rξα,rξβ ), r∈R[s], ξ .
= НОК(ϕ,ζ ),
где НОК(ϕ,ζ )   наименьшее общее кратное многочленов ϕ, ζ .
Базисом пересечения является строка
σ = (ξα,ξβ ).
Следовательно,
Σ = (ξα,ξβ )⊗ E, ξ .
= НОК(ϕ,ζ ).

2. Получимусловия,прикоторыхмногообразиятраекторийkerGиkerF
(77), (78) имеют нулевое пересечение
Утверждение 11. Пусть
G
.
= (α,β )⊗ E, F
.
=
 
ϕ 0
0 ζ !
⊗ E,
НОД(α,β,ζ,ϕ ) = 1.
Тогда условие
kerG∩kerF = 0
равносильно















НОД(ζ,ϕ ) = 1,
НОД(ζ,β ) = 1,
НОД(α,ϕ ) = 1.
(81)
Доказательство. Ввиду утверждения 6, достаточно проверить равно-
сильность (81) и условия
Sm



α β ϕ 0
0 ζ 


=



1 0
0 σ 0 0



=



1 0
0 1
0 0



.
Последнееввидувзаимнойпростотымногочленовα,β,ζ,ϕ равносильнотому,
что
σ = НОД(M
1
,M
2
,M
3
) =НОД(ϕζ,αζ,βϕ ) = 1.
Отсюда следует (81) (проверяется от противного).
Обратно, пусть выполнено (81). Пусть α , β , ζ , ϕ обозначают множества
корнейсоответствующихмногочленов.Объединениеипересечениемножеств
будем писать как сумму и произведение. Тогда (81) равносильно условиям















ζϕ =∅,
ζβ =∅,
αϕ =∅.

Следовательно,
(ϕ+ζ )(α +ζ )(β +ϕ) =∅,
что означает
НОД(ϕζ,αζ,βϕ ) = 1.
Утверждение доказано.
Следствие. Система (53) с матрицами
G
.
= (α,β )⊗ E, F
.
=
 
ϕ 0
0 ζ !
⊗ E,
НОД(α,β,ζ,ϕ ) = 1,
допускает отделение трендов тогда и только тогда, когда выполнены усло-
вия (81).
8.4 Системы в форме 1-го порядка
Система (1) допускает равносильную с точки зрения множества решений
запись в форме уравнения 1-го порядка:
x
k+1
=Ax
k
+Bu
k
, y
k
=Cx
k
+Du
k
, x
1
=x
0
∈R
n
, k = 1,N. (82)
Среди всех равносильных систем (82) будем рассматривать системы с
наименьшей размерностью n =p
1
+...+p
r
пространства состояний{x
k
}.
Определение 1. Система(82)называетсянаблюдаемой,еслилюбоеизмене-
ние состоянияx
t
приводит к изменениям в выходном сигнале (y
t
;...;y
t+n− 1
).
Предложение 3. Система (82) наблюдаема тогда и только тогда, когда
столбцы матрицы
 
C;CA;...;CA
n− 1
 
линейно независимы.
Наименьшее значение размерностиn на множестве равносильных систем
достигается тогда и только тогда, когда система наблюдаема [24]. Этот факт
следует из известной теоремы о декомпозиции пространства состояний [25].
Для наблюдаемой системы всегда существует преобразование простран-
ства состояний
x
0
=Tx,
A
0
=TAT
− 1
, B
0
=TB, C
0
=CT
− 1
, D
0
=D, (83)
которое приводит четверку матриц (A,B,C,D) в равносильную форму вос-
станавливаемости. В этой форме наиболее просто выражается связь между
элементами матриц описаний (1) и (82).

Определение. Описание (A,B,C,D) в пространстве состояний имеет фор-
му восстанавливаемости (the observer form [26, 6.4.3]), если
A =kA
ij
k
i∈1,r
j∈1,r
, B =kB
i
k
i∈1,r
, C =kC
j
k
j∈1,r
, (84)
матрицы A
ij
, B
i
, C
j
с размерами соответственно p
i
× p
j
, p
i
× m, r× p
j
имеют
вид:
A
ii
=






0 ··· 0 − a
(0)
ii
1 ··· 0 − a
(1)
ii
.
.
.
.
.
.
.
.
.
.
.
.
0 ··· 1 − a
(p
i
− 1)
ii






, (85)
A
ij
=



0 ··· 0 − a
(0)
ij
.
.
.
.
.
.
.
.
.
.
.
.
0 ··· 0 − a
(p
i
− 1)
ij



, i6=j, (86)
B
i
=



b
(0)
i1
··· b
(0)
im
.
.
.
.
.
.
.
.
.
b
(p
i
− 1)
i1
··· b
(p
i
− 1)
im



, (87)
C
j
=α − 1
[0]



0 ··· 0
.
.
.
.
.
.
.
.
. e
j
0 ··· 0



, (88)
e
j
  j-й столбец единичной матрицы I
r
и p
1
+...+p
r
=n, p
1
6...6p
r
.
Матрицам (84–88) сопоставляется многочленная матрицаγ (s) (2) соглас-
но формулам:
γ (s) = (α (s),− β (s)),
α (s) =a(s)α [0]
, β (s) =α (s)D+b(s),
a(s) =ka
ij
(s)k
i∈1,r
j∈1,r
, b(s) =kb
ij
(s)k
i∈1,r
j∈1,m
,
a
ij
(s) =a
(0)
ij
s
0
+...+a
(p
i
− 1)
ij
s
q
i
− 1
+δ ij
s
p
i
,
b
ij
(s) =b
(0)
ij
s
0
+...+b
(p
i
− 1)
ij
s
p
i
− 1
,
где δ ij
  символ Кронекера:
δ ij
=
(
1,
0,
i =j,
i6=j.

Определение 2. Система (82) называетсяуправляемой, если выбором вход-
ного сигнала (u
t− n
;...;u
t− 1
) ее можно привести в любое наперед заданное
состояние x
t
.
Предложение 4. Система (82) управляема тогда и только тогда, когда
строки матрицы
 
B,AB,...,A
n− 1
B
 
линейно независимы.
8.5 Признаки управляемости
Сформулируем условие управляемости (определение 2) через матрицы
описания (1).
Определение3. Система(1)называетсяуправляемой,еслиуправляемарав-
носильная ей система (82).
Предложение 5. Система (1) управляема тогда и только тогда, когда
разложение
γ (s) =π (s)γ 0
(s) (89)
возможно только с унимодулярной матрицей π (s) (т.е. degdetπ (s) = 0).
Другимисловами,неуправляемостьравносильнаналичиюувсехподмат-
риц из столбцов γ (s) левого общего сомножителя π (s) с определителем мно-
гочленом, отличным от константы: degdetπ (s)> 1.
Определение 4. Многочленные матрицы α (s), β (s) называем взаимно про-
стыми слева, если из матричного равенства
(α (s),β (s)) =π (s)(α 0
(s),β 0
(s))
необходимо следует degdetπ (s) = 0.
Несложнопоказать,чтопредложение5равносильноизвестномупризнаку
управляемости Попова [27]:
Определение 5. Пусть γ (s) = (α (s),β (s)), где α (s)   неособенная подмат-
рица из столбцов γ (s). Если в системе (1) считать компоненты траектории,
соответствующие подматрице α (s), выходными, то матричная передаточная
функция системы имеет вид h(s) = α (s)
− 1
β (s). Назовем α (s) (матричным)
знаменателем, β (s)   числителем системы (1).
Предложение 6. (Признак управляемости Попова) Система (1) со знаме-
нателем α (s) и числителем β (s) управляема тогда и только тогда, когда
матрицы α (s), β (s) взаимно просты слева.

Доказательство см. [26, 27].
Предложение 7. Система (1) управляема тогда и только тогда, когда в
многочленной матрице γ (s) миноры наибольшего порядка не имеют общего
делителя степени выше нуля, т. е. каноническая форма Smγ (s) состоит
только из нулей и единиц.
Доказательство. Пусть система неуправляема, тогда все подматрицы
изстолбцовматрицыγ (s)имеютобщийделительπ (s):degdetπ (s)> 1(пред-
ложение5).Значит,всеминорынаибольшегопорядкаимеютобщийделитель
detπ (s).Обратно,еслиуминоровнаибольшегопорядкаестьобщийделитель
ρ (s), значит, форма Smγ (s)
.
=S разлагается в произведение
S =



ρ 1
(s) 0
.
.
.
0 ρ r
(s)



S
0
, ρ 1
(s)··· ρ r
(s) =ρ (s),
где S
0
  каноническая форма, состоящая только из нулей и единиц. Тогда
γ (s) =USW,
где U, W   унимодулярные матрицы элементарных преобразований
(degdetU = degdetW = 0), и верно равенство
γ (s) =USW =U



ρ 1
(s) 0
.
.
.
0 ρ r
(s)



S
0
W
.
=π (s)γ 0
(s),
π (s)
.
=U



ρ 1
(s) 0
.
.
.
0 ρ r
(s)



, degdetπ (s)> 1.
Значит, система неуправляема (предложение 5).
Предложение доказано.
8.6 Доказательство утверждения 1
Выпишем матрицы H(θ ), H
M
(θ ) в функциях потерь (24), (25). Для этого
используется запись системы (1) в форме уравнения 1-го порядка (82).

Длябольшегоудобстваизложенияпереупорядочимкомпонентыz соглас-
но (8). Соответственно переставляются и элементы матрицы Φ (23), после
чего она будет клеточно-диагональной: Φ .
=
 
Φ ⊗ I
r
0
0 Φ ⊗ I
m
 
.
=
 
Φ x
0
0 Φ u
 
. Тогда
w
.
= (x
0
;u
1
;...;u
N
), w
M
.
= (x
M,0,1
;...;x
M,0,t
;u
M,1
;...;u
M,t
), (90)
t
.
= (N− p)(p+1),
H(θ ) =













C D 0
CA CB D
.
.
.
.
.
.
.
.
.
.
.
.
CA
N− 1
CA
N− 2
B ... CB D
0 I 0
.
.
.
.
.
.
0 0 I













.
=
 
H
x
H
u
0 I
!
, (91)
Φ H(θ ) =
 
Φ x
H
x
Φ x
H
u
0 Φ u
!
, Φ x
H
x
=













C
.
.
.
CA
p− 1
CA
.
.
.
CA
p
.
.
.













, (92)
Φ x
H
u
=

























D 0
CB D
.
.
.
.
.
.
.
.
.
CA
p− 2
B ... CB D
CB D
.
.
.
.
.
.
.
.
.
CA
p− 1
B ... ... CB D
CAB CB D
.
.
.
.
.
.
.
.
.
.
.
.
CA
p
B ... ... ... CB D
... ... ... ... ... ... ... ...
CA
N− 2
B ... ... ... ... ... CB D

























,

H
M
(θ ) =











H
p,x
H
p,u
.
.
.
.
.
.
H
p,x
H
p,u
0 I
.
.
.
.
.
.
0 I











, (93)
H
p,x
.
=






C
CA
.
.
.
CA
p− 1






, H
p,u
.
=






D 0
CB D
.
.
.
.
.
.
.
.
.
CA
p− 2
B ... CB D






.
Замечание. Исходя из структуры матриц H(θ ), H
M
(θ ), можно увидеть, что
траектория z = H
M
(θ )w
M
в модели модифицированного метода (25) распада-
ется на отдельные несвязанные отрезки длины p, каждый со своими началь-
ными условиями x
M,0,i
. В то же время в модели метода ВИ (24) траектория
представляет собой единое целое с едиными начальными условиями x
0
. Это
находит выражение в структурах матриц C, C
OR
функций потерь (21), (22).
Длядоказательстваутверждения1достаточнопроверитьследующееклю-
чевое соотношение между матрицами H(θ ) и H
M
(θ ):
Φ H(θ ) =H
M
(θ )













I 0 ... 0
A B
A
2
AB B
.
.
.
.
.
.
.
.
.
.
.
.
0
.
.
. Φ u
0













.
=H
M
(θ )Q. (94)
Проверку равенства (94) удобней осуществить в 3 шага.
1-й шаг:



H
p,x
0
.
.
.
0 H
p,x









0 ... 0
B
AB B
.
.
.
.
.
.
.
.
.






=

=




















0
0
CB
.
.
.
CA
p− 1
B
0
CAB
.
.
.
CA
p
B
CB
.
.
.
CA
p− 1
B
0
.
.
.
.
.
.




















.
2-й шаг:



H
p,u
0
.
.
.
0 H
p,u



Φ u
=
=













H
p,u
0
H
p,u
0
.
.
.


























I
0
I
0
.
.
.













=
=













H
p,u
0
H
p,u
0
.
.
.













.

3-й шаг:



H
p,x
0
.
.
.
0 H
p,x









0 ... 0
B
AB B
.
.
.
.
.
.
.
.
.






+



H
p,u
0
.
.
.
0 H
p,u



Φ u
=
=




















H
p,u
0
CB
.
.
.
CA
p− 1
B
H
p,u
CAB
.
.
.
CA
p
B
CB
.
.
.
CA
p− 1
B
H
p,u
.
.
.
.
.
.




















.
Учитывая вид матрицы Φ H(θ ) (92), переходим к равенству (94).
Запись Φ H(θ ) = H
M
(θ )Q соответствует замене переменных Qw = w
M
,
которая эквивалентна некоторой системе линейных ограничений Mw
M
= 0.
Матрица M определяется соотношениями MQ = 0, ker(M
T
,Q) = 0, т. е.
столбцы составной матрицы (M
T
,Q) образуют базисR
dimw
M
, где dimw
M
есть
число компонент в векторе w
M
.
8.7 Доказательство леммы 1
Выразим x через новые переменные: x = Q
− 1/2
y. Функция J
1
(x(y)) =
J
0
+ (y− y
0
)
T
(y− y
0
) монотонно непрерывно растет вместе с увеличением
расстояния ky− y
0
k. Следовательно, если область B
y
.
= Q
1/2
B достаточно
большая, то в ней найдется точка y
C
такая, что
J
0
+(y
C
− y
0
)
T
(y
C
− y
0
)− C =J
0
+C. (95)
Пустьky− y
0
k>ky
C
− y
0
k, тогда
J
0
+(y− y
0
)
T
(y− y
0
)− C>J
0
+C,

и y не может быть точкой минимума J(x(· )) = J
1
(x(· )) +R(x(· )). Поэтому
x(y) =Q
− 1/2
y не может быть точкой минимума J(· ) =J
1
(· )+R(· ). Следова-
тельно, величинаky
C
− y
0
k =
√
2C является оценкой сверху для расстояния
между точками минимума функций J(x(· )) и J
1
(x(· )). Из (95) следуют нера-
венства
(x
1
− x
0
)
T
Q(x
1
− x
0
) = (y
1
− y
0
)
T
(y
1
− y
0
)< 2C,
(x
1
− x
0
)
T
(x
1
− x
0
)<
2C
λ min
(Q)
,
kx
1
− x
0
k<
s
2C
λ min
(Q)
.
Если область B
y
недостаточно большая для выполнения (95), то доопре-
делим функцию R(x(y)) вне B
y
произвольным согласным с условием леммы
образом, и повторив рассуждения, получим, что точка минимума функции
J(x(y))необходимолежитнапересеченииB
y
икругаky− y
0
k<
√
2C.Отсюда
следует утверждение леммы.
8.8 Линейныеоценкивслучаеразбиенияпараметровнадвегруп-
пы
Рассмотрим систему линейных уравнений:





ˇy =Fχ ∗ +η ∗ ,
Wχ ∗ = 0 ⇔ χ ∗ =W
⊥
ϕ
∗ ,
(96)
где F, W   заданные матрицы, kerF = 0, kerW
T
= 0, χ ∗ ∈ R
t
  вектор
параметров,η ∗  случайнаявеличина, распределеннаянормальноснулевым
средним и единичной дисперсией:
η ∗ ∈N(0,I).
Наблюдению доступна случайная величина
ˇy =Fχ ∗ +η ∗ =FW
⊥
ϕ
∗ +η ∗ .
Задача. По наблюдениям ˇy оценить χ ∗ .
Построим оценки параметра χ ∗ двумя способами: 1) с учетом и 2) без
учета ограничения Wχ ∗ = 0. Затем сравним свойства оценок.

Оценкаметоданаименьшихквадратовприлинейныхограниченияхнавек-
тор оцениваемых параметров. Пусть χ = χ (ˇy)   оценка χ ∗ , построенная по
наблюдению ˇy. Будем выбирать оптимальное значение χ исходя из условия
минимума функции потерь
j(χ )
.
=kˇy− Fχ k
2
при ограничении
Wχ = 0.
Введем вектор множителей Лагранжа λ и перейдем к равносильной задаче
безусловной минимизации по χ и λ функции
j
∗ (χ,λ ) =kˇy− Fχ k
2
+λ T
Wχ.
Необходимое условие экстремума состоит в равенстве нулю частных произ-
водных j
∗ (χ,λ ) по χ и λ :





(ˇy− Fχ )
T
F +λ T
W = 0,
Wχ = 0.
Транспонируем первое уравнение:





F
T
Fχ − F
T
ˇy− W
T
λ = 0
Wχ = 0.
(97)
Домножим первое уравнение слева на W (F
T
F)
− 1
, в результате получим:
W (F
T
F)
− 1
F
T
ˇy = (− )W (F
T
F)
− 1
W
T
λ.
Выразим множители Лагранжа:
λ = (− )
h
W (F
T
F)
− 1
W
T
i
− 1
W (F
T
F)
− 1
F
T
ˇy.
Наконец из уравнения (97) выразим оптимальное значение χ :
χ = (F
T
F)
− 1
F
T
ˇy− (F
T
F)
− 1
W
T
h
W (F
T
F)
− 1
W
T
i
− 1
W (F
T
F)
− 1
F
T
ˇy =

=
 
I− (F
T
F)
− 1
W
T
h
W (F
T
F)
− 1
W
T
i
− 1
W
 
(F
T
F)
− 1
F
T
ˇy
.
=
.
= Π( F
T
F)
− 1
F
T
ˇy, (98)
Заметим, что выражение
Π .
=I− (F
T
F)
− 1
W
T
h
W (F
T
F)
− 1
W
T
i
− 1
W (99)
описывает матрицу косого проецирования на подпространство imW
⊥
вдоль
подпространства im(F
T
F)
− 1
W
T
(см. раздел 8.2 приложения, с подстановкой
A
T
=W, B = (F
T
F)
− 1
W
T
,
учитывая равенства imA = kerA
T
= imW
⊥
).
Оценка метода наименьших квадратов без учета линейных ограничений
на вектор параметров. Будем выбирать оптимальное значение χ исходя из
условия минимума функции потерь
j(χ ) =kˇy− Fχ k,
опускаяограничениеWχ = 0.Несмотрянанеполныйучетаприорнойинфор-
мации, такая оценка останется состоятельной, как и оценка (98). Известно,
что безусловный минимум j(χ ) достигается при значении аргумента
χ 1
= (F
T
F)
− 1
F
T
ˇy. (100)
Состоятельность и сравнение двух оценок. Для проверки состоятельно-
сти подставим в выражения для оценок (98), (100) правило генерации исход-
ных данных (96):
χ = Π( F
T
F)
− 1
F
T
ˇy = Π( F
T
F)
− 1
F
T
(FW
⊥
ϕ
∗ +η ∗ ) =
= Π W
⊥
ϕ
∗ +Π( F
T
F)
− 1
F
T
η ∗ .
Учитываяопределениепроектора Π (99),имеем Π W
⊥
ϕ
∗ =W
⊥
ϕ
∗ ,итогда

χ =W
⊥
ϕ
∗ +Π( F
T
F)
− 1
F
T
η ∗ =
=χ ∗ +Π( F
T
F)
− 1
F
T
η ∗ .
Отсюда заключаем, что оценка χ является несмещенной, с дисперсией
D
χ = Π( F
T
F)
− 1
Π T
. (101)
По закону больших чисел, эмпирическое среднее χ L
.
=
1
L
P
L
i=1
χ (i)
оценок
 
χ (i)
	
, соответствующих разным реализациям случайной величины ˇy, схо-
дится с вероятностью 1 (п.н.) при L→∞ к истинному значению χ ∗ . Таким
образом, оценка χ L
состоятельна.
Оценкаχ 1
(100) отличается отχ (98) отсутствием проецирующего сомно-
жителя Π и имеет дисперсию D
1
= (F
T
F)
− 1
. Несложно повторить рассужде-
нияиполучить,чтооценкаχ 1,L
.
=
1
L
P
L
i=1
χ 1,(i)
также,какиχ L
,состоятельна.
Поскольку матрица Π вырождена (будучи проектором на подпростран-
ство imW
⊥
, собственное вR
t
), то вырождена и матрица дисперсий D
χ . Это
соответствуеттому,чтовсеоценкиχ расположенывподпространстве imW
⊥
.
Справедливо также следующее соотношение между матрицами дисперсий:
Π( F
T
F)
− 1
Π T
6 (F
T
F)
− 1
,
D
χ 6D
1
.
Значит, оценка χ , учитывающая линейные ограничения, в среднем меньше
уклоняется от неизвестного истинного значения χ ∗ , чем упрощенная
оценка χ 1
.
Частный случай разделения параметров на две группы. Выделим в век-
торе χ две группы параметров χ .
= (w;θ ) и соответственно разделим на две
группыстолбцовматрицуF
.
= (K,L),такчтоFχ =Kw+Lθ .Будемсчитать,
что линейные ограничения наложены только на w: Mw = 0. Как и раньше,
оцениваться будут параметры из обеих групп w, θ (то есть весь вектор χ ),
но нас будет интересовать только дисперсия θ и ее зависимость от того, учи-
тываются ли при получении оценки линейные ограничения, наложенные на
w.Такимобразом,параметрыw вэтомсмыслеявляютсявспомогательными,
вторичными
1
по отношению к θ .
1
В литературе употребляется термин “nuisance” (“мешающие” параметры) [28]; такое название мало
подходит к нашему случаю: без оценки w совместно с θ оценка θ может оказаться несостоятельной.

Система уравнений объекта (96) с учетом разделения χ на две группы
параметров записывается следующим образом:





ˇy =Fχ ∗ +η ∗ =Kw
∗ +Lθ
∗ +η ∗ ,
Mw
∗ = 0.
(102)
Будем сравнивать две модели объекта (102), полную:





y =Kw+Lθ +η,
Mw = 0
(103)
  и упрощенную:
y =Kw+Lθ +η. (104)
Заметим, что случай (102) соответствует матрице ограничений вида
W = (M,0). (105)
Далее вычислим дисперсию оценкиθ по модели (103) и покажем, что она
невырождена, в отличие от матрицы дисперсии всего вектора χ . Покажем,
что если опустить условие Mw = 0, перейдя к упрощенной модели (104), то
дисперсия оценки θ может только увеличиться.
Теорема 7. Пусть
θ = (0,I)χ,
χ .
= (w;θ ) = arg min
Mw=0
j(χ ),
j(χ )
.
=kˇy− Fχ k
2
,
гдеданные ˇy полученыизсистемы (102).СтрокиматрицыM линейнонеза-
висимы, и столбцы матрицы F линейно независимы. Тогда случайная ве-
личина θ имеет строго положительно определенную матрицу дисперсии
D
θ > 0.
Доказательство. Обозначим
(F
T
F)
− 1
=
 
K
T
K K
T
L
L
T
K L
T
L
!
− 1
.
=
 
Φ ww
Φ wθ Φ θw
Φ θθ !
.
= Φ . (106)

Поскольку θ = (0,I)χ , то имеем D
θ = (0,I)D
χ (0;I), где матрица D
χ опре-
делена выражениями (101), (99), (105). Отсюда получаем:
D
θ = Φ θθ − (0,I)Φ W
T
(WΦ W
T
)
− 1
WΦ(0; I) =
= Φ θθ − Φ θw
M
T
(MΦ ww
M
T
)
− 1
MΦ wθ . (107)
Воспользуемся формулой Фробениуса для обращения клеточных матриц
[17, с. 56]:
 
MΦ ww
M
T
MΦ wθ Φ θw
M
T
Φ θθ !
− 1
=


∗ ∗ ∗  
Φ θθ − Φ θw
M
T
[MΦ ww
M
T
]
− 1
MΦ wθ  
− 1


.
Матрица в левой части равенства может быть представлена в виде произве-
дения:
 
MΦ ww
M
T
MΦ wθ Φ θw
M
T
Φ θθ !
=
 
M 0
0 I
!
(F
T
F)
− 1
 
M
T
0
0 I
!
.
В силу условия линейной независимости строк M и линейной независимости
столбцов F эта матрица строго положительно определена, вместе со всеми
своими квадратными диагональными подматрицами. Отсюда следует
D
θ = Φ θθ − Φ θw
M
T
(MΦ ww
M
T
)
− 1
MΦ wθ > 0.
Теорема доказана.
Теорема 8. В условиях теоремы 7, пусть
θ 1
= (0,I)χ 1
,
χ 1
.
= (w
1
;θ 1
) = argminj(χ ) = (F
T
F)
− 1
F
T
ˇy.
Тогда дисперсия D
1
оценки θ 1
не меньше D
θ , и равенство D
1
= D
θ дости-
гается только и только тогда, когда imK∩imL = 0 (K
T
L = 0).
Доказательство. В силу соотношения θ 1
= (0,I)χ 1
, учитывая, что
дисперсия χ 1
равна (F
T
F)
− 1
, получаем D
1
= (0,I)(F
T
F)
− 1
(0;I) = Φ θθ .
Сравнение с выражением (107) приводит к неравенству D
1
> D
θ . Необхо-
димым и достаточным условием равенства D
1
= D
θ является Φ θw
= 0 или
K
T
L = 0, что следует из определения Φ (106). Теорема доказана.

8.9 Доказательство теоремы 3
Запишем матрицу H
M
(θ ) (93) через Кронекерово произведение:
H
M
(θ ) =
 
I⊗ H
p,x
I⊗ H
p,u
0 I
!
.
Упростим обозначения: H
.
=H
M
(θ ), Δ H
.
= Δ H
M
(θ, Δ θ ).
Покажем, что если выполнены условия: detA 6= 0, Δ C = 0, и строки C
линейно независимы   то из равенства H
T
Δ H = 0 следует Δ H = 0.
Используем свойство Кронекерова произведения:
(A⊗ B)(A
0
⊗ B
0
) = (AA
0
)⊗ (BB
0
).
Тогда
H
T
Δ H =
 
I⊗ H
T
p,x
0
I⊗ H
T
p,u
I
! 
I⊗ Δ H
p,x
I⊗ Δ H
p,u
0 0
!
=
=
 
I⊗ H
T
p,x
Δ H
p,x
I⊗ H
T
p,x
Δ H
p,u
I⊗ H
T
p,u
Δ H
p,x
I⊗ H
T
p,u
Δ H
p,u
!
.
Следовательно, условие H
T
Δ H = 0 равносильно условию
 
H
T
p,x
Δ H
p,x
H
T
p,x
Δ H
p,u
H
T
p,u
Δ H
p,x
H
T
p,u
Δ H
p,u
!
= 0.
Из равенства H
T
p,x
Δ H
p,u
= 0 следует система уравнений:















C
T
Δ D+A
T
C
T
CΔ B +A
2T
C
T
CΔ( AB)+...+A
(p− 1)T
C
T
CΔ  
A
p− 2
B
 
= 0
A
T
C
T
Δ D+A
2T
C
T
CΔ B +...+A
(p− 1)T
C
T
CΔ  
A
p− 3
B
 
= 0
............................................................
A
(p− 2)T
C
T
Δ D+A
(p− 1)T
C
T
CΔ B = 0
A
(p− 1)T
C
T
Δ D = 0
(108)
Пусть f
k
обозначает левую часть k-го уравнения f
k
= 0 в системе (108).
Несложно получить следующие соотношения:
f
2
=Af
1
− A
pT
C
T
CΔ  
A
p− 2
B
 
,

f
k
=Af
k− 1
− A
pT
C
T
CΔ  
A
p− k
B
 
,
k = 2,p.
Из равенств f
1
= 0, ... , f
p
= 0 следует
(
A
pT
C
T
CΔ  
A
p− k
B
 
= 0
k = 2,p.
Если матрица A неособенная и строки C линейно независимы, последнее
равенство означает
(
CΔ  
A
p− k
B
 
= 0
k = 2,p.
Учитывая постоянство C (Δ C = 0), можем записать
(
Δ  
CA
p− k
B
 
= 0
k = 2,p.
Крометого,изпоследнегоуравнениясистемы(108)следует Δ D = 0.Тем
самым,
Δ H
p,u
= 0.
Далее, все допустимые изменения матриц A, B, C, D, сохраняющие H
p,u
(Δ H
p,u
= 0), описываются уравнением
(A+Δ A,B +Δ B,C +Δ C,D+Δ D) = (PAP
− 1
,PB,CP
− 1
,D), detP 6= 0.
Если наложить условие локальной идентифицируемости, с необходимостью
получаем
P =I, Δ A = 0, Δ B = 0, Δ C = 0, Δ D = 0,
что означает Δ H = 0.
Такимобразом,доказаноутверждение,болеесильное,чемтеорема3:для
различимых в смысле условия (iii) систем из класса простых любое измене-
ниепараметров Δ θ (и,соответственно,матрицA,B,C,D)снеобходимостью
влечет Δ H 6= 0 (в силу различимости) и влечет H
T
Δ H 6= 0 (в силу выше-
приведенных рассуждений), то есть в силу теоремы 2 всегда D
V
<D
M
.

8.10 Доказательство теоремы 4
8.10.1 Асимптотическое распределение оценки θ L
Пусть θ ∗   точка локального минимума функционала J
.
=MJ
1
, и θ L
 
состоятельный корень уравнения J
0
L
= 0: lim
L→∞
θ L
=θ ∗ (п.н.).
Лемма 2. Если в некоторой окрестности B(θ ∗ ) точки θ ∗ существуют
непрерывные и ограниченные производные
J
0
L
, ∂J
0
L
/∂θ i
, ∂
2
J
0
L
/∂θ i
∂θ j
, i,j∈ 1,v,
то случайная величина L
1/2
(θ L
− θ ∗ ) асимптотически нормальна с нулевым
мат. ожиданием и дисперсией
(MJ
00
1
)
− 1
(MJ
0
1
J
0T
1
)(MJ
00
1
)
− 1
,
где производные J
0
1
и J
00
1
берутся в точке θ ∗ .
Доказательствопроведемпосхеме[29,5f.2],сделавнеобходимыеобоб-
щения.
Зададим число L
B
: ∀L > L
B
θ L
∈ B(θ ∗ ) (п.н.). Везде далее считаем
L>L
B
. По условию, в окрестности B(θ ∗ ) существуют непрерывные ограни-
ченные производные J
0
L
, ∂J
0
L
/∂θ i
, ∂
2
J
0
L
/∂θ i
∂θ j
, i,j ∈ 1,v. (Напомним, что J
0
L
обозначает вектор производных
(∂J
L
/∂θ 1
;...;∂J
L
/∂θ v
),
так что ∂
2
J
0
L
/∂θ i
∂θ j
.
= ∂
3
J
L
/∂θ i
∂θ j
∂θ k
). Следовательно, можно применить
разложение градиента J
0
L
(θ L
) в ряд Тейлора относительно точки θ ∗ с оста-
точным членом:
J
0
L
(θ L
) = 0 =J
0
L
(θ ∗ )+J
00
L
(θ ∗ )· (θ L
− θ ∗ )+
+
1
2
(θ L
− θ ∗ )
T
· J
000
L
(θ )· (θ L
− θ ∗ ),
гдеθ  некотораяточкаотрезка,соединяющеготочкиθ ∗ иθ L
:θ ∈ [θ L
,θ ∗ ][30,
§ 7.13]. Отсюда получаем
0 =L
1/2
(θ L
− θ ∗ )+[J
00
L
(θ ∗ )+
1
2
(θ L
− θ ∗ )
T
· J
000
L
(θ )]
− 1
× × L
1/2
· J
0
L
(θ ∗ ).
Следовательно,
L
1/2
(θ L
− θ ∗ )+[J
00
(θ ∗ )]
− 1
· L
1/2
· J
0
L
(θ ∗ ) =

=−{ [J
0
L
(θ ∗ )+
1
2
(θ L
− θ ∗ )
T
· J
000
L
(θ )]
− 1
− [J
00
(θ ∗ )]
− 1
}×
× L
1/2
· J
0
L
(θ ∗ )
.
=
.
=− E
L
· L
1/2
· J
0
L
(θ ∗ ).
По центральной предельной теореме, случайная величина
L
1/2
· J
0
L
(θ ∗ ) =L
1/2
· L
X
i=1
J
0
1,i
(θ ∗ )
имеет предельное нормальное распределение Φ( μ, Σ 2
):
μ .
=MJ
0
1,i
(θ ∗ ) = 0, Σ 2
.
=MJ
0
1,i
(θ ∗ )· J
0T
1,i
(θ ∗ ),
J
0
1,i
.
=∂J
1,i
(θ )/∂θ, J
1,i
(θ )
.
= min
w
kˇz
(i)
− H(θ )wk
2
.
Отметим, чтоMJ
1,i
(θ ) =MJ
1
(θ ).
Далее, E
L
→ 0 (п.н.), поскольку
1) по усиленному закону больших чисел J
00
L
(θ ∗ )→J
00
(θ ∗ )
.
=MJ
00
1
(θ ∗ )
(п.н.);
2) θ L
→θ ∗ (п.н.) (теорема 1);
3) производная J
000
L
(θ ) ограничена в B(θ ∗ ).
Из сходимости распределения L
1/2
· J
0
L
(θ ∗ ) к нормальному Φ( μ, Σ 2
), Σ 2
<∞,
и сходимости п.н. E
L
→ 0 следует сходимость по вероятности
L
1/2
(θ L
− θ ∗ )+[J
00
(θ ∗ )]
− 1
· L
1/2
· J
0
L
(θ ∗ )→ 0.
Следовательно,распределениеL
1/2
(θ L
− θ ∗ )сходитсякнормальномуΦ(0 ,Σ 2
1
),
где
Σ 2
1
.
= (MJ
00
1
)
− 1
(MJ
0
1
J
0T
1
)(MJ
00
1
)
− 1
.
Лемма доказана.
8.10.2 ОценкипроизводныхирегулярностьэмпирическогофункционалаJ
1
(θ )
Первая и вторая производные функционала J
1
(θ ) вычислены в [3,?], где
приведены формулы с использованием специальной матрицы из множителей
Лагранжа. В отличие от [3,?], здесь получено явное выражение второй про-
изводнойчерезэлементыматрицG,C,Π ,чтопозволилодатьпростыеоценки
сверху для слагаемых в выражении для 2-й производной.

Лемма 3. Пусть ω(γ θ )
.
= J
1
(θ ) = ˇz
T
G
T
CGˇz, ω
0
.
= ∂ω/∂γ , ω
00
.
= ∂
2
ω/∂γ 2
.
Тогда
ω
0
=γ T
V
T
C
b
V, V
.
=V(ˇz),
b
V
.
=V(b z), b z
.
= Πˇ z, (109)
ω
00
=
b
V
T
C
b
V − S
1
− S
2
, (110)
где слагаемые S
1
и S
2
ограничены сверху по евклидовой норме
kSk
.
=
 
X
s
2
ij
 
1/2
= (SpS
T
S)
1/2
(111)
неравенствами:
kS
1
k6
√
2c
0
·k ˇzk·k ˇz− b zk,
kS
2
k6c
0
·k ˇz− b zk
2
,
c
0
.
=Nr(p+1)(m+r)SpC.
Доказательство. 1) Обозначим
ω
0
ij
.
=∂ω/∂γ ij
= ˇz
T
(− ∂Π /∂γ ij
)ˇz.
Раскроем второй сомножитель:
− ∂Π /∂γ ij
=
= (∂G
T
/∂γ ij
)CG− G
T
C((∂G/∂γ ij
)G
T
+
+G(∂G
T
/∂γ ij
))CG+G
T
C(∂G/∂γ ij
) =
=E
T
ij
CG− G
T
C(E
ij
G
T
+GE
T
ij
)CG+G
T
CE
ij
=
= (E
T
ij
− G
T
CGE
T
ij
)CG+G
T
C(E
ij
− E
ij
G
T
CG).
После вынесения E
T
ij
и E
ij
за скобки получаем
− ∂Π /∂γ ij
= Π E
T
ij
CG+G
T
CE
ij
Π . (112)
Отсюда следует
ω
0
ij
= ˇz
T
G
T
CE
ij
Πˇ z. (113)
Учитывая, что E
ij
Πˇ z =
b
V
ij
и ˇz
T
G
T
= γ T
V
T
, имеем ω
0
ij
= γ T
V
T
C
b
V
ij
. Следова-
тельно, ω
0
=γ T
V
T
C
b
V.
2) Обозначим ω
00
ijkl
.
= ∂
2
ω/∂γ ij
∂γ kl
= ˇz
T
(∂G
T
CE
ij
Π /∂γ kl
)ˇz (см. (113)).
Раскроем второй сомножитель:
∂G
T
CE
ij
Π /∂γ kl
=E
T
kl
CE
ij
Π − G
T
C(E
kl
G
T
+GE
T
kl
)CE
ij
Π − 
− G
T
CE
ij
(Π E
T
kl
CG+G
T
CE
kl
Π) .
В этом равенстве два последних слагаемых получены с применением форму-
лы (112). Далее удобно сложить первое и третье слагаемые:
E
T
kl
CE
ij
Π − G
T
CGE
T
kl
CE
ij
Π = Π E
T
kl
CE
ij
Π .
Объединив 2-е и 5-е слагаемые, получим
∂G
T
CE
ij
Π /∂γ kl
= Π E
T
kl
CE
ij
Π − − G
T
C(E
kl
G
T
CE
ij
+E
ij
G
T
CE
kl
)Π − (114)
− G
T
CE
ij
Π E
T
kl
CG.
Следовательно,
ω
00
ijkl
=
b
V
T
kl
C
b
V
ij
− − z
T
G
T
C(E
kl
G
T
CE
ij
+E
ij
G
T
CE
kl
)Πˇ z− − z
T
G
T
CE
ij
Π E
T
kl
CGˇz.
Тогда
ω
00
=kω
00
ijkl
k =
b
V
T
C
b
V − S
1
− S
2
.
3) Оценим сверху нормы слагаемых S
1
и S
2
. Согласно последнему равен-
ству,S
1
,S
2
 матрицы,столбцыистрокикоторыхпронумерованыдвойными
индексами ij и kl соответственно, таким образом, что
S
ij,kl
1
.
= ˇz
T
G
T
C(E
kl
G
T
CE
ij
+E
ij
G
T
CE
kl
)Πˇ z,
S
ij,kl
2
.
= ˇz
T
G
T
CE
ij
Π E
T
kl
CGˇz.
Тогда
kS
1
k
2
6
X
ij
X
kl
kS
ij,kl
1
k
2
6
6 2
X
ij
X
kl
kˇz
T
G
T
CE
kl
G
T
CE
ij
Πˇ zk
2
6
6 2
X
ij
X
kl
kˇz
T
G
T
Ck
2
·kE
kl
G
T
Ck
2
·kE
ij
Πˇ zk
2
6
6 2N
2
· X
ij
X
kl
kˇz
T
G
T
Ck
2
·kG
T
Ck
2
·k ˇzk
2
6
6 2N
2
(r(p+1)(m+r))
2
· (SpC)
2
·k ˇz− b zk
2
·k ˇzk
2
.

Впоследних2-хнеравенствахучтено:1)i∈ 1,r,j∈ 1,(p+1)(r+m);2)kE
kl
k
2
=
N − p
k
6 N, где p
k
6 p   степень k-й строки знаменателя a(s) системы
(1); 3) kC
1/2
k
2
= SpC; 4) kG
T
Ck
2
= SpCGG
T
C = SpC; 5) kˇz
T
G
T
Ck
2
6
kˇz
T
G
T
C
1/2
k
2
·kC
1/2
k
2
=kˇz− b zk
2
SpC. Следовательно,
kS
1
k6
√
2c
0
·k ˇzk·k ˇz− b zk.
Аналогично оценивается норма слагаемого S
2
:
kS
2
k
2
6
X
ij
X
kl
kS
ij,kl
2
k
2
=
=
X
ij
X
kl
kˇz
T
G
T
CE
ij
Π E
T
kl
CGˇzk
2
.
Применив неравенстваkE
kl
k
2
=N− p
k
6N,kx
T
Π xk
2
6kxk
2
·kxk
2
, получим
kS
2
k
2
6N
2
· X
ij
X
kl
kCGˇzk
4
6
6N
2
(r(p+1)(m+r))
2
· (SpC)
2
·k ˇz− b zk
4
.
Следовательно,kS
2
k6c
0
·k ˇz− b zk
2
.
Лемма 3 доказана.
Лемма 4. Существует окрестность B(θ ∗ ) точки θ ∗ , в которой функцио-
нал J
L
(θ ) (17), (19) имеет непрерывную и ограниченную третью производ-
ную J
000
L
(θ ).
Доказательство. Отметим, что матрица G
θ системы (5) при ограни-
чениях (i)–(iii) непрерывно дифференцируема по θ .
ФункционалJ
L
(θ ) имеет непрерывную третью производную поθ , если (и
только если) непрерывную третью производную по θ имеет определенная в
условии леммы 3 функция ω(θ )
.
=ω(γ θ ). Согласно лемме 3,
ω
00
θθ =D
T
ω
00
γγ D =
=D
T
(
b
V
T
C
b
V − S
1
− S
2
)D
.
=D
T
(S
0
− S
1
− S
2
)D,
где S
0
, S
1
, S
2
  матрицы, столбцы и строки которых пронумерованы двой-
ными индексами ij и kl, так что
S
ij,kl
0
.
= ˇz
T
Π E
T
kl
CE
ij
Πˇ z
.
=
b
V
T
kl
C
b
V
ij
,

S
ij,kl
1
.
= ˇz
T
G
T
C(E
kl
G
T
CE
ij
+E
ij
G
T
CE
kl
)Πˇ z,
S
ij,kl
2
.
= ˇz
T
G
T
CE
ij
Π E
T
kl
CGˇz.
Далее не будем вычислять производнуюω
000
.
=∂ω
00
/∂θ , а поступим следу-
ющимобразом.УчитываяопределениеΠ .
=I− G
T
CG,заметим,чтофункция
ω
00
(θ ) имеет вид ω
00
(θ )≡ ϕ(C
θ ,G
θ ), где ϕ(C,G)   биквадратичная форма от
матричных аргументов C, G размеров соответственно n× n и n× l. Матриц-
функция G
θ непрерывно дифференцируема и имеет для всех θ ∈ Ω линейно
независимые строки. Следовательно, матриц-функция C
θ .
= [G
θ G
T
θ ]
− 1
в за-
мкнутом подмножестве B
1
(θ ∗ )⊂ Ω непрерывно дифференцируема и ограни-
чена,посколькуматриц-функция[G
θ G
T
θ ]
− 1
непрерывнаиограниченавB
1
(θ ∗ )
и имеет место равенство
∂
∂θ [G
θ G
T
θ ]
− 1
= [G
θ G
T
θ ]
− 1
· ∂
∂θ [G
θ G
T
θ ]· [G
θ G
T
θ ]
− 1
.
Отсюда следует, что суперпозиция ϕ(C
θ ,G
θ ) = ω
00
(θ ) во внутренних точках
множества B
1
(θ ∗ ) имеет непрерывную производную
∂
∂θ ϕ(C
θ ,G
θ ) =ω
000
(θ ),
и в замкнутом подмножестве B
2
(θ ∗ ) ⊂ B
1
(θ ∗ ) эта производная ограничена.
Следовательно, она ограничена в любой окрестности B(θ ∗ ) ⊂ B
2
(θ ∗ ) точки
θ ∗ .
Лемма доказана.
8.10.3 Математическое ожидание квадрата градиента и второй производной
эмпирического функционала J
1
(θ )
Обозначим, как и в доказательстве леммы 3,
ω(γ θ )
.
=J
1
(θ ), ω
0
.
=∂ω/∂γ .
=k∂ω/∂γ ij
k
.
=kω
0
ij
k
(вектор, элементы которого пронумерованы двойным индексом ij),
ω
00
.
=∂
2
ω/∂γ 2
.
=k∂
2
ω/∂γ ij
∂γ kl
k
.
=kω
0
ij,kl
k
(матрица с нумерацией двойным индексом строк ij и столбцов kl).
Лемма 5. В точке θ =θ ∗ :
1) Mω
0
ω
0T
=σ 2
Mω
00
+σ 2
X
T
X,
X
T
X
.
=kx
ij,kl
k
i∈1,r,j∈1,t
k∈1,r,l∈1,t
, x
ij,kl
.
=σ 2
SpΠ E
T
ij
CE
kl
Π;

2) x
ij,kl
=M(
b
V − V
∗ )
T
ij
C(
b
V − V
∗ )
kl
,
3) Mω
00
=MV
T
∗ CV
∗ .
Доказательство.1)Установимоднонесложноеравенство.ПустьA,B
  матрицы размеров l× l, такие, что для некоторого вектора x∈R
l
выпол-
неноAx = 0иx
T
B = 0.Ипустьe∈R
l
 случайнаявеличинаснулевыммат.
ожиданием и диагональной матрицей вторых моментов:Mee
T
=σ 2
I. Тогда
M(x+e)
T
A(x+e)(x+e)
T
B(x+e) =σ 2
Mx
T
ABx+Me
T
Aee
T
Be (115)
(для доказательства следует заметить, что после раскрытия скобок в левой
части равенства мат. ожидание слагаемых, в которые вектор e входит нечет-
ное число раз, равно нулю).
Далее положим в (115) A
.
= Π E
T
ij
CG, B
.
= G
T
CE
kl
Π , x
.
= z
∗ , e
.
= η . В
результате, используя (113), получим
Mω
0
ij
ω
0
kl
=σ 2
MV
T
∗ ij
CV
∗ kl
+Mη T
Π E
T
ij
CGηη T
G
T
CE
kl
Π η.
Представим вектор η в виде суммы двух ортогональных слагаемых: η .
=η k
+
η ⊥
, где η k
.
= Π η и η ⊥
.
=η − η k
. Заметим, что Gη
k
= 0, и случайные величины
η k
и η ⊥
взаимно независимы. Учитывая, чтоMGη
⊥
η T
⊥
G
T
=σ 2
C
− 1
, имеем:
Mω
0
ij
ω
0
kl
=σ 2
MV
T
∗ ij
CV
∗ kl
+σ 2
Mη T
k
E
T
ij
CE
kl
η k
.
Наконец, второе слагаемое можно преобразовать, используя равенства η k
=
Π η ,Mη T
Aη =σ 2
SpA. Это приводит к 1-му утверждению леммы.
2) Заметим, что η = ˇz− z
∗ и η k
= Π(ˇ z− z
∗ ) =b z− z
∗ . Отсюда следует
Mω
0
ij
ω
0
kl
=σ 2
MV
T
∗ ij
CV
∗ kl
+σ 2
M(
b
V − V
∗ )
T
ij
C(
b
V − V
∗ )
kl
и далее 2-е утверждение леммы.
3) Согласно определениям
Mω
00
=M(ˇz
T
G
T
CGˇz)
00
=Mˇz
T
(G
T
CG)
00
ˇz.
Подставив ˇz =z
∗ +η , получим
Mω
00
=Mz
T
∗ (G
T
CG)
00
z
∗ +Mη T
(G
T
CG)
00
η =
=Mz
T
∗ (G
T
CG)
00
z
∗ +σ 2
Sp(G
T
CG)
00
=

=Mz
T
∗ (G
T
CG)
00
z
∗ +σ 2
(SpG
T
CG)
00
.
Учтем, что
SpG
T
CG = SpCGG
T
= SpI
rankG
= rankG.
Согласно условиям (i)–(iii), rankG   постоянное число, следовательно,
(SpG
T
CG)
00
= 0,
Mω
00
=Mz
T
∗ (G
T
CG)
00
z
∗ =M
ˇz=z
∗ ω
00
.
Применив лемму 3, получаем
Mω
00
=MV
T
∗ CV
∗ .
Лемма доказана.
Учитывая, что J
0
1
.
= J
0
1θ = ω
0
γ D и J
00
1
.
= J
00
1θθ = D
T
ω
00
γγ D, приходим к
утверждению теоремы 4.
8.11 Доказательство теоремы 5
Как было указано в разделе 3, модифицированные оценки могут быть
охарактеризованы, с одной стороны, как оценки ОР с заменой z на Φ z, и с
другойстороны,какоценкиВИсзаменойC наC
OR
.Исходяизэтого,постро-
им доказательство теоремы 5, следуя доказательству теоремы 4.
1) Лемма 2 остается без изменения.
2) Лемма 3 заменяется следующим утверждением.
Лемма 6. Пусть
ω(γ θ )
.
=J
1
(θ ) = ˇz
T
G
T
C
OR
Gˇz =
= ˇz
T
Φ T
G
T
OR
C
OR
G
OR
Φˇ z,
ω
0
.
=∂ω/∂γ, ω
00
.
=∂
2
ω/∂γ 2
.
Тогда
ω
0
=γ T
V
T
C
OR
b
V
M
, (116)
V
.
=V(ˇz),
b
V
M
.
=V
OR
(b z), b z
.
= Π OR
Φˇ z,
ω
00
=
b
V
T
M
C
OR
b
V
M
− S
1
− S
2
,

где слагаемые S
1
и S
2
ограничены сверху по евклидовой норме
kSk
.
=
 
X
s
2
ij
 
1/2
= (SpS
T
S)
1/2
неравенствами:
kS
1
k6
√
2c
0
·k ˇzk·k ˇz− b zk,
kS
2
k6c
0
·k ˇz− b zk
2
,
c
0
.
=Nr(p+1)(m+r)kΦ k
2
SpC
OR
=N
4
r(p+1)
3
(m+r)
3
Sp(γ T
θ γ θ )
− 1
.
Доказательство аналогично доказательству леммы 3. Следует произ-
вести замену C, G, z на C
OR
, G
OR
, Φ z.
3) Лемма 4 сохраняет силу (в доказательстве следует произвести замену
C, G, z на C
OR
, G
OR
, Φ z).
4) Лемма 5 заменяется следующим утверждением.
Лемма 7. В точке θ =θ ∗ :
1) Mω
0
ω
0T
=σ 2
MV
T
∗ C
OR
V
∗ +σ 4
W,
0<W <c
1
I,
c
1
=N
4
(p+1)
3
r(r+m+1)
3
Sp(γ T
θ γ θ )
− 1
,
2) Mω
00
=MV
T
∗ C
OR
V
∗ +σ 2
Sp
 
C
OR
C
− 1
 
00
,
Sp
 
C
OR
C
− 1
 
00
6 4(p+1)
1/2
N
3
(r+m)
2
Sp(γ T
θ γ θ )
− 1
.
Доказательство. 1) Из леммы 6,
ω
0
ω
0T
=
b
V
T
M
C
OR
Vγγ T
V
T
C
OR
b
V
M
,
ω
0
ij
ω
0
kl
= ˇz
T
Φ T
Π OR
E
T
ORij
C
OR
G
OR
Φˇ zˇz
T
Φ T
G
T
OR
C
OR
E
ORij
Π OR
Φˇ z.
В равенстве (115) положим
A
.
= Φ T
Π OR
E
T
ORij
C
OR
G
OR
Φ ,
B
.
= Φ T
G
T
OR
C
OR
E
ORkl
Π OR
Φ ,
x
.
=z
∗ , e
.
=η.
В результате получим
Mω
0
ij
ω
0
kl
=

=σ 2
MV
T
∗ ij
C
OR
V
∗ kl
+
+Mη T
Φ T
Π OR
E
T
ORij
C
OR
G
OR
Φ ηη T
Φ T
G
T
OR
C
OR
E
ORkl
Π OR
Φ η. (117)
Вместовычислениямат.ожиданиявторогослагаемого,какэтобылосделано
в доказательстве теоремы 4, ограничимся получением оценки сверху.
Установим ряд вспомогательных утверждений.
Предложение 8. Пусть A =ka
ij
k   квадратная матрица размера n× n,
и пусть η   случайный вектор с нулевым мат. ожиданием и диагональной
матрицей вторых моментов:
Mη = 0, Mηη T
=σ 2
I
n× n
.
Тогда
σ − 4
Mη T
A
T
ηη T
Aη =
=
X
i
a
2
ii
+
X
ij
a
ii
a
jj
+
X
ij
a
ij
a
ji
+
X
ij
a
2
ij
=
= Sp(A∗ A)+(SpA)
2
+SpA
2
+SpA
T
A,
где знак ∗ обозначает бинарную операцию покомпонентного произведения
матриц одинакового размера: ij-й элемент A∗ B есть произведение ij-х
элементов A и B:
(A∗ B)
ij
=a
ij
b
ij
.
Доказательство. Распишем покомпонентно:
σ − 4
Mη T
A
T
ηη T
Aη =
=σ − 4
M
X
ijkl
a
ij
a
kl
η i
η j
η k
η l
.
Далее следует учесть, что математические ожидания сомножителей вида
η i
η i
η k
η l
, η i
η i
η i
η l
равны нулю.
Предложение 9. Пусть A =ka
ij
k   квадратная матрица размера n× n,
и
a
.
= (a
11
;...;a
nn
)
  вектор из диагональных элементов A. Тогда
(1) (SpA)
2
6na
T
a6nSpA
T
A =nkAk
2
;
(2) SpA∗ A6 SpA
T
A;

Доказательство.1)Представим SpAввидескалярногопроизведения
SpA =a
T



1
.
.
.
1



.
=a
T
b.
Тогда
(SpA)
2
= (a
T
b)
2
6 (a
T
a)(b
T
b) =na
T
a
(неравенство Коши Буняковского). Заключительная часть (1) следует из
определений следа Sp и евклидовой нормыk·k матрицы.
2) Второе неравенство также следует из определений:
SpA∗ A
.
=a
T
a6 SpA
T
A.
Предложение доказано.
Предложение 10. Пусть A = ka
ij
k, B = kb
ij
k   квадратные матрицы
размера n× n. Тогда
(1) (SpAB)
2
6 (SpA
T
A)(SpB
T
B);
(2) SpA
2
6 SpA
T
A.
Доказательство. В пространстве матрицопределимскалярное произ-
ведение
(A,B) =
X
ij
a
ij
b
ij
= SpA
T
B,
тогда (1) оказывается неравенством Коши Буняковского:
(A,B)
2
6 (A,A)(B,B).
Неравенство (2) следует из (1) при B =A. Предложение доказано.
Прямым следствием предложений 8, 9, 10 является следующее
Утверждение 12. Пусть A =ka
ij
k   квадратная матрица размера n× n,
и пусть η   случайный вектор с нулевым мат. ожиданием и диагональной
матрицей вторых моментов:
Mη = 0, Mηη T
=σ 2
I
n× n
.
Тогда
σ − 4
Mη T
A
T
ηη T
Aη 6 (n+3)SpA
T
A.

Следствие. В формуле (117) второе слагаемое ограничено сверху:
Mη T
Φ T
Π OR
E
T
ORij
C
OR
G
OR
Φ ηη T
Φ T
G
T
OR
C
OR
E
ORkl
Π OR
Φ η <
<σ 4
N
4
(p+1)
2
(r+m+1)
2
Sp(γ T
θ γ θ )
− 1
.
Доказательство. Имеет место последовательность неравенств:
Mη T
Φ T
Π OR
E
T
ORij
C
OR
G
OR
Φ ηη T
Φ T
G
T
OR
C
OR
E
ORkl
Π OR
Φ η 6
(утверждение 12)
6σ 4
(N(r+m)+3)× × SpΦ T
Π OR
E
T
ORij
C
OR
GG
T
C
OR
E
ORkl
Π OR
Φ =
=σ 4
(N(r+m)+3)kΦ T
Π OR
E
T
ORij
C
OR
G
OR
Φ k
2
6
6σ 4
(N(r+m)+3)kΦ T
Φ E
T
ORij
k
2
kC
OR
G
OR
k
2
=
(учитывая, чтоkC
OR
G
OR
k
2
= SpC
OR
G
OR
G
T
OR
C
OR
= SpC
OR
)
=σ 4
(N(r+m)+3)kΦ T
Φ E
T
ORij
k
2
SpC
OR
<
(учитывая неравенство Φ T
Φ < (p+1)I
N(r+m)× N(r+m)
⇒kΦ T
Φ k
2
< (p+1)
2
N(r+m))
<σ 4
(N(r+m)+3)(p+1)
2
N(r+m)kE
T
ORij
k
2
SpC
OR
<
(учтем, что kE
ORij
k
2
6 N, поскольку вследствие определения E
ORij
.
=
∂G
OR
/∂γ ij
число ненулевых элементов (единиц) в матрице E
ORij
равно числу
клеточных строк вида (0...0γ 0
...γ p
0...0) в матрице G
OR
)
<σ 4
(N(r+m)+3)N
2
(p+1)
2
(r+m)SpC
OR
<
<σ 4
N
3
(p+1)
2
(r+m+1)
2
SpC
OR
<
<σ 4
N
4
(p+1)
2
(r+m+1)
2
Sp(γ T
θ γ θ )
− 1
.
Следствие доказано.

Предложение 11. Пусть W > 0   симметричная п.о. матрица порядка
n, каждый элемент которой ограничен сверху неравенством:
w
ij
<c.
Тогда имеет место оценка
W <ncI
n× n
.
Доказательство. Отношение W <U по определению означает
∀x x
T
Wx<x
T
Ux.
Согласно условию,
x
T
Wx =
X
ij
x
i
w
ij
x
j
<c
X
ij
x
i
x
j
.
С другой стороны,
c
X
ij
x
i
x
j
=cx
T



1
.
.
.
1



(1··· 1)x6
(неравенство Коши Буняковского)
6cx
T
x(1··· 1)



1
.
.
.
1



=ncx
T
x
Следовательно,
W <ncI
n× n
.
Предложение доказано.
Далее, согласно (117)
Mω
0
ω
0T
=
=σ 2
MV
T
∗ C
OR
V
∗ +σ 4
W,
W ∈R
n× n
, n
.
=r(r+m)(p+1),
и(ij,kl)-йэлементматрицыW последствиюутверждения12ограниченсвер-
ху константой
c =N
4
(p+1)
2
(r+m+1)
2
Sp(γ T
θ γ θ )
− 1
.

По предложению 11,
0<W <nN
4
(p+1)
2
(r+m+1)
2
h
Sp(γ T
θ γ θ )
− 1
i
I
n× n
<
<N
4
(p+1)
3
r(r+m+1)
3
h
Sp(γ T
θ γ θ )
− 1
i
I
n× n
.
Следовательно,
Mω
0
ω
0T
=
=σ 2
MV
T
∗ C
OR
V
∗ +σ 4
W,
0<W <c
1
I,
c
1
.
=N
4
(p+1)
3
r(r+m+1)
3
Sp(γ T
θ γ θ )
− 1
.
Первое утверждение леммы доказано.
2) Согласно определениям,
Mω
00
=M (ˇz
T
Φ T
G
T
OR
C
OR
G
OR
Φˇ z)
00
=Mˇz
T
Φ T
(G
T
OR
C
OR
G
OR
)
00
Φˇ z.
Подставив ˇz =z
∗ +η , получим
Mω
00
=Mz
T
∗ Φ T
(G
T
OR
C
OR
G
OR
)
00
Φ z
∗ +Mη T
Φ T
(G
T
OR
C
OR
G
OR
)
00
Φ η =
=Mz
T
∗ Φ T
(G
T
OR
C
OR
G
OR
)
00
Φ z
∗ +σ 2
Sp(Φ T
G
T
OR
C
OR
G
OR
Φ)
00
.
Рассмотрим последний сомножитель.
Sp(Φ T
G
T
OR
C
OR
G
OR
Φ)
00
= Sp(G
T
C
OR
G)
00
= (SpG
T
C
OR
G)
00
= (118)
= (SpC
OR
GG
T
)
00
=
 
SpC
OR
C
− 1
 
00
= Sp
 
C
OR
C
− 1
 
00
.
Учитывая эту цепочку равенств, имеем
Mω
00
=Mz
T
∗ Φ T
(G
T
OR
C
OR
G
OR
)
00
Φ z
∗ +σ 2
Sp
 
C
OR
C
− 1
 
00
=
=Mω
00
(ˇz =z
∗ )+σ 2
Sp
 
C
OR
C
− 1
 
00
.
Применив лемму 6 с учетом θ =θ ∗ , ˇz =z
∗ и равенства
b
V
M
(ˇz =z
∗ ) =V(z
∗ )
.
=V
∗ ,
получим
Mω
00
=MV
T
∗ C
OR
V
∗ +σ 2
Sp
 
C
OR
C
− 1
 
00
.

Преобразуем второе слагаемое:
Sp
 
C
OR
C
− 1
 
00
=
= Sp(G
T
OR
C
OR
G
OR
)
00
ΦΦ T
= (119)
(см. (113), (114), положив C
.
=C
OR
, G
.
=G
OR
)
= Sp{Π E
T
kl
CE
ij
Π − − G
T
C(E
kl
G
T
CE
ij
+E
ij
G
T
CE
kl
)Π − − G
T
CE
ij
Π E
T
kl
CG}ΦΦ T
6
(предложение 9)
6
√
n{kΠ E
T
kl
CE
ij
Π k+
+kG
T
CE
kl
G
T
CE
ij
Π k+kG
T
CE
ij
G
T
CE
kl
Π k+
+kG
T
CE
ij
Π E
T
kl
CGk}kΦΦ T
k.
Учтем неравенстваkΠ Ak6kAk,kE
kl
k
2
6N,
kΦ k
2
= (N− p)(r+m)⇒kΦΦ T
k6 (N− p)(r+m).
Тогда
Sp
 
C
OR
C
− 1
 
00
6
√
nN (N− p)(r+m){kCk+2kG
T
CG
T
Ck+kG
T
CCGk}.
ТеперьпривлечемсоотношенияkCk =kC
1/2
k
2
= SpC,kG
T
Ck
2
= SpCGG
T
C =
SpC:
Sp
 
C
OR
C
− 1
 
00
6 4
√
nN (N− p)(r+m)SpC.
В итоге, подставив n = r(r+m)(p+1)6 (r+m)
2
(p+1) и восстановив в
правой части опущенный индекс OR, получим оценку
Sp
 
C
OR
C
− 1
 
00
6 4(p+1)
1/2
N
2
(r+m)
2
SpC
OR
6
6 4(p+1)
1/2
N
3
(r+m)
2
Sp(γ T
θ γ θ )
− 1
.
Лемма 7 доказана.
Учитывая равенства J
0
1
.
= J
0
1θ = ω
0
γ D и J
00
1
.
= J
00
1θθ = D
T
ω
00
γγ D, получаем
первые два утверждения теоремы.
ДалеенужноперейтиотSp
 
C
OR
C
− 1
 
00
коценкесверхудляSp
 
C
OR
C
− 1
 
00
θθ .
Sp
 
C
OR
C
− 1
 
00
θθ = SpD
T
 
C
OR
C
− 1
 
00
D = Sp(G
T
OR
C
OR
G
OR
)
00
Φ DD
T
Φ T
.

Следуя доказательству от формулы (119) с заменой ΦΦ T
на Φ DD
T
Φ T
, полу-
чим оценку
Sp
 
C
OR
C
− 1
 
00
θθ 6 4(p+1)
1/2
N
3
(r+m)
2
kDD
T
kSp(γ T
θ γ θ )
− 1
,
и далее 3-е утверждение теоремы.
Теорема 5 доказана.
Список литературы
[1] Белоглазов И.Н. Оптимальные совместные оценивание и идентифика-
ция в дискретных линейных системах // ДАН СССР. 1983. Т. 273. № 4.
С. 811–815.
[2] Maine R.E., Iliff K.W. Formulation and implementation of a practical
algorithm for parameter estimation with process and measurement noise //
SIAM Journal on Applied Mathematics. 1981. V. 41. No. 3. P. 558–579.
[3] Егоршин А.О. Метод наименьших квадратов и "быстрые" алгоритмы
в вариационных задачах идентификации и фильтрации (метод ВИ) //
Автометрия. 1988. № 1. С. 30–42.
[4] Крамер Г. Математические методы статистики. М.: Наука, 1975.
[5] Аоки М. Введение в методы оптимизации. М.: Наука, 1977.
[6] AokiM.,YueP.C. Onapriorierrorestimatesofsomeidentiﬁcationmethods
// IEEE Trans. on Automat. Control. 1970. V. AC-15. P. 541–548.
[7] Fuller W.A. Measurement Error Models. New York: Wiley, 1987.
[8] Бойчук Л.М., Чихрадзе Т.А. Сравнениемоделей,получаемыхпометоду
наименьших квадратов и по ортогональной регрессии // Автоматика.
1985. № 5. С. 57–61.
[9] Aoki M., Yue P.C. On the certain convergence questions in system
identiﬁcation // SIAM Journal of Control. 1970. V. 8. No. 2. P. 239–256.
[10] Ломов А.А. Статистические свойства орторегрессионных методов оце-
нивания параметров и решений систем линейных разностных уравнений
// Оптимизация, Управление, Интеллект. 1997. № 2. С. 40–51.

[11] Ломов А.А. Идентификация линейных динамических систем по корот-
ким участкам переходных процессов при аддитивных измерительных
возмущениях // Известия РАН ТиСУ. 1997. № 3. С. 20–26.
[12] Ломов А.А. Условия различимости стационарных линейных систем //
Дифференц. уравнения. 2003. Т. 39. № 2. С. 261–266.
[13] Ломов А.А. О статистических свойствах оценок параметров линейных
динамическихсистемпоизмерениямкороткихучастковпереходныхпро-
цессов // Труды III Международной конференции "Идентификация си-
стем и задачи управления" SICPRO ’04. Москва, 28-30 января 2004 г.
М.: Институт проблем управления им. В.А. Трапезникова РАН, 2004.
С. 209–224.
[14] Ломов А.А. Сравнениеметодовоцениванияпараметровлинейныхдина-
мических систем по измерениям коротких участков переходных процес-
сов // Автоматика и телемеханика. 2005. № 1.
[15] Виллемс Я.От временного ряда к линейной системе // Теория систем.
Математическиеметодыимоделирование. М.:Мир,1989.С.8–191. (Но-
вое в зарубежной науке. Сер. Математика; Т. 44).
[16] Ломов А.А. О различимости стационарных линейных систем с коэф-
фициентами,зависящимиотпараметра//Cибирскийжурналиндустри-
альной математики. 2003. Т. 6. № 4(16). С. 60–66.
[17] Гантмахер Ф.Р. Теория матриц. М. : Наука, 1988.
[18] Понтрягин Л.С. Обыкновенныедифференциальныеуравнения.М.:На-
ука, 1974.
[19] Gleser L.J. Estimation in a multivariate "errors in variables" regression
model: large sample results // The Annals of Statistics. 1981. V. 9. No. 1.
P. 24–44.
[20] ВорчикБ.Г. Идентифицируемостьлинейныхпараметрическихстохасти-
ческих систем // Автоматика и телемеханика. 1985. № 5. С. 64–78. № 7.
С. 96–109.
[21] Цыпкин А.З. Основы информационной теории идентификации. М.: На-
ука, 1984.

[22] Жданов А.И., Кацюба О.А. Идентификация по методу наименьших
квадратов параметров уравнений авторегрессии при аддитивных ошиб-
ках измерений // Автоматика и телемеханика. 1982. № 2. С. 29–38.
[23] Льюнг Л.С. Идентификация систем. М.: Наука, 1991.
[24] Ломов А.А. Минимальные описания стационарных линейных моделей
// Труды Института математики СО РАН. Т.28, Модели и методы опти-
мизации. С. 91-117. Новосибирск: ИМ СО РАН, 1994.
[25] Kalman R.E. Mathematical Description of Linear Dynamical Systems //
SIAM Journal of Control. 1963.Ser. A. V. 1. No. 2. P. 152–192.
[26] Kailath T. Linear Systems. Prentice-Hall, Englewood Cliffs, N.J., 1980.
[27] PopovV.M. SomePropertiesoftheControlSystemswithIrreducibleMatrix-
Transfer Function // Lecture Notes in Mathematics. V. 144. Seminar on
Differential Equations and Dynamical Systems, II. P. 169–180 / Berlin:
Springer-Verlag, 1969.
[28] Fellman J. On the effect of “nuisance” parameters in linear models //
Sankhya. The Indian Jornal of Statistics. 1976. V. 38. Ser. A. Pt. 2. P. 197–
200.
[29] Рао С.Р. Линейные статистические методы и их применение. М.: Наука,
1968.
[30] Никольский С.М. Курсматематическогоанализа. Т.1.М.:Наука,1990.
[31] Егоршин А.О. Вариационная дискретизация и идентификация линей-
ных стационарных дифференциальных уравнений // Труды III Между-
народной конференции "Идентификация систем и задачи управления"
SICPRO ’04. Москва, 28-30 января 2004 г. М.: Институт проблем управ-
ления им. В.А. Трапезникова РАН, 2004. С. 1824–1883.
Электронный журнал.  86
