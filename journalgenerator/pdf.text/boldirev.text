dx
dt
6
 
-
?
ДИФФЕРЕНЦИАЛЬНЫЕ УРАВНЕНИЯ
И ПРОЦЕССЫ УПРАВЛЕНИЯ
N 1, 2004
Электронный журнал,
рег. N П23275 от 07.03.97

e-mail: diff@osipenko.stu.neva.ru
Теория обыкновенных дифференциальных уравнений
МЕТОД КУСОЧНО-ЛИНЕЙНОЙ
АППРОКСИМАЦИИ ДЛЯ РЕШЕНИЯ ЗАДАЧ
ОПТИМАЛЬНОГО УПРАВЛЕНИЯ
В.И.БОЛДЫРЕВ
Россия, 630090,Новосибирск,пр.ак.Коптюга, NN 4,
Институтматематикиим.С.Л.СоболеваСОРАН,
Кибернетика,
e-mail: vibold@math.nsc.ru
Аннотация
Вработеполученыследующиеосновныерезультаты:
1. Разработан симплексный метод для решения задачи минимизации
псевдовыпуклой функции на выпуклом компактном множестве. Доказа-
на сходимость получаемой алгоритмом минимизирующей последователь-
ности.
2. Разработан метод последовательных приближений для задачи ми-
нимизациипсевдовыпуклогофункционала,определенногонамножествеко-
нечных состояний линейной системы управления. Дано обоснование пред-
лагаемогоалгоритма.
3. Дан способ построения практически ”реализуемых”управлений для
решения линейных задач с линейными терминальными ограничениями и
безних.
4.Разработаналгоритмдлярешениякраевыхнелинейныхзадачуправ-
ления.Дифференциальные уравнения и процессы управления, N. 1, 2004
Введение
Математическое моделирование многих динамических процессов, воз-
никающихнапрактике(промышленноeпроизводство,экономика,экология,
химия, биология, движение летательных аппаратов и т.д.) является в на-
стоящее время основным инструментом получения знаний о их поведении
при различных способах воздействия. Одна из главных целей моделирова-
ния — поиск такого управляющего воздействия, при котором достигается
в некотором смысле“максимальный эффект”. Например, минимальные за-
тратыресурса (времени)напроизводствоединицыпродукцииилиперевод
управляемогообъектаизначальногосостояниявзаданноеконечное.
Наиболее удобным и распространенным средством описания динами-
ческих процессов являются дифференциальные уравнения. Возникающие
при этом задачи, как правило, хорошо известны в теории оптимального
управления.Однако,подавляющеебольшинствоизнихнеимеютпростого
(аналитического)решенияитребуютразработкичисленныхметодов.
Актуальнойпроблемеразработкиэффективныхметодовчисленногоре-
шениялинейныхинелинейныхзадачоптимальногоуправленияпосвящена
настоящаяработа.
Линейные задачи оптимального управления привлекают внимание ис-
следователейподвумосновнымпричинам:
— возможностью простого описания и получения конструктивных эф-
фективныхметодов (алгоритмов)решения;
— возможностью использования линеаризации нелинейных задач и,
следовательно, управлением нелинейными системами с помощью линеари-
зованныхмоделей.
Как правило, для линейных задач удается доказать локальную и гло-
бальную сходимость предлагаемых методов решения, исследовать также
скоростьсходимостииполучитьееоценки.Мыограничимсярассмотрени-
емдетерминированныхзадач,вкоторыхуправляемаясистемаописывается
обыкновеннымидифференциальнымиуравнениямибеззапаздыванийвфа-
зовых координатах и управлении. Исследование свойств решений любых
задач преследует конечную и, по-видимому, главную цель — найти реше-
ние задачи в явном виде, но, если этого сделать невозможно, предложить
численныйметодегопоиска.Методырешенияопираютсянатеоретические
факты и, естественно, используют теоремы о виде оптимального управ-
Электронныйжурнал.  29Дифференциальные уравнения и процессы управления, N. 1, 2004
ления, о конечности числа переключений, о существовании оптимального
управления,оединственностиителесностиобластейдостижимостилиней-
ных систем. Следует подчеркнуть, что телесность области достижимости
зависиттолькоотобластиуправленияипараметровсистемы,анеотвида
функционалазадачи,фазовыхитерминальныхограничений.
Известно, что принцип максимума сводит задачу оптимального уп-
равления к решению двухточечной краевой задачи для системы диф-
ференциальных уравнений. Характерным для задач оптимального уп-
равления является то, что аналитическое решение задачи удается полу-
читьлишьвредкихслучаях.Всвязисэтимбольшуюрольиграютчислен-
ные методы построения оптимального управления. Потребности практики
и бурный прогресс вычислительной техники стимулировали разработку
вычислительныхметодовоптимальногоуправления.
Работывобластисозданиячисленныхметодовоптимальногоуправле-
ния интенсивно ведутся с середины прошлого века, с момента появления
принципа максимума Л. С. Понтрягина [68] и динамического программи-
рования Р. Беллмана [10]. Трудности при решении задач оптимального
управления вызваны необходимостью решать краевую задачу, большой
размерностью систем, наличием ограничений на управление и фазовые
координаты, многоэкстремальностью. Это привело к большому разнооб-
разиювычислительныхметодовихпреодоления.
Методы решения задач оптимального управления можно условно раз-
битьна:
1) градиентные методы в пространстве управлений, основанные на
формулеприращениядляпервойвариациифункционала (книмможноот-
нестинекоторыеметодыиз [18], [61], [75], [92], [95]);
2) методы, связанные с варьированием и перебором траекторий в про-
странствефазовыхсостояний (см. [7], [60], [83], [97], [116]);
3)методырешениядвухточечнойкраевойзадачи,полученнойизприн-
ципа максимума (к ним можно отнести некоторые методы, описание кото-
рыхможнонайтивработах [18], [20], [39], [62], [78]);
4) методы, использующие дискретизацию задачи с последующим при-
менениемлинейногоинелинейногопрограммирования (см.,например, [38],
[84]);
5) методы последовательных приближений, основанные на процедурах
линеаризацииивариацииуправлений (см.,например, [1], [5], [21]–[25], [26],
Электронныйжурнал.  30Дифференциальные уравнения и процессы управления, N. 1, 2004
[45], [46], [48], [51], [52], [53], [56], [58], [59], [73], [74], [76], [80], [81], [84], [85]);
6) методы штрафных функционалов или модифицированного функцио-
налаЛагранжа (см.,например, [23], [34], [38], [58], [67], [84], [105], [112]).
Первые работы по численным методам решения задач оптимального
управления сделаны Д.Е.Охоцимским и Т.М.Энеевым [65], Л.И.Шатров-
ским [87], А.Брайсоном и В.Денхемом [17]. В последствии было опубли-
ковано значительное количество статей и книг на эту тему. Можно вы-
делить несколько различных направлений в разработке численных мето-
дов, существенно отличающихся друг от друга. Прежде всего, следует
упомянуть прямые методы, основанные на спуске в пространстве управ-
лений.Рядисследованийсвязанснепрямымиметодами,вкоторыхспомо-
щью принципа максимума Л.С.Понтрягина исходная задача редуцирова-
ласьккраевой.Циклработпочисленнымметодамоптимальногоуправле-
ния был выполнен Н.Н.Моисеевым [61] и его учениками И.А.Крыловым,
Ф.Л.Черноусько,И.А.Вателемидр.Вэтихработахбылразработанпод-
ход,основанныйнавариацияхвпространствесостояний.
Другое направление, развиваемое Р.П.Федоренко [84], базируется
на использовании идей метода линеаризации. Методы условного гра-
диента и проекции градиента были перенесены В.Ф.Демьяновым и
А.М.Рубиновым [37] на задачи оптимального управления. Указанный
Н.Н.Моисеевым [61] в 1971 году подход, основанный на методах нели-
нейного программирования, нашел широкое развитие в работах Э.Полака
[66], Ю.Н.Ермольева, В.П.Гуленко, Т.И.Царенко [40], А.И.Пропоя [69],
Д.Табака и Б.Куо [77], Ю.Г.Евтушенко [38] и др. Обзор различных чис-
ленныхметодовоптимальногоуправлениясодержитсяв [18], [37], [52], [58],
[62], [84], [85], [86].
Рассмотрим методы численного решения задачи оптимального управ-
ления,некасаясьредукцииееккраевойзадачеиметодоврешениякраевой
задачи.
Пусть динамический процесс описывается системой нелинейных обык-
новенныхдифференциальныхуравнений
˙ x =f(x,u,t), t∈T = [t
0
,t
1
], x(t
0
) =x
0
. (1)
Здесь x — n-мерный вектор фазовых координат; u — s-мерный вектор
управления,принадлежащийклассукусочно-непрерывныхфункций,u(t)∈
U,где U ⊂R
s
—выпуклоекомпактноемножество.
Требуется найти допустимое управление u(t), минимизирующее функ-
Электронныйжурнал.  31Дифференциальные уравнения и процессы управления, N. 1, 2004
ционал
F
0
(u)≡ϕ
0
(x(t
1
)) (2)
придополнительныхусловиях
F
i
(u)≡ϕ
i
(x(t
1
)) = 0 (≤ 0), i = 1,m (m≤n). (3)
Предполагается, что вектор-функция f(x,u,t) непрерывна по t и непре-
рывно дифференцируема по x и u; функции ϕ
i
(x), i = 0,m, — непрерывно
дифференцируемыпо x.
Длякаждогофункционала F
i
(u), i = 0,m,введемгамильтониан
H
i
(ψ,x,u,t) = (ψ
i
,f(x,u,t))
исопряженнуюсистему
˙
ψ
i
=−f
x
(x,u,t)
∗
ψ
i
, ψ
i
(t
1
) =−ϕ
ix
(x(t
1
)). (4)
Тогда градиенты функционалов F
i
(u), i = 0,m, вычисляются по фор-
мулам
F
0
i
(u) =−H
i
u
(ψ,x,u,t).
Метод последовательных приближений для решения задач оп-
тимального управления со свободным правым концом (m = 0) использует
принцип максимума Л.С.Понтрягина. Основу метода составляют различ-
ныетипылинеаризациидинамическойсистемывместессоответствующи-
мипроцедурамиварьированияуправлений [5], [26], [52], [56], [58], [73], [74],
[76], [84].
Пусть для допустимого управления u(t) вычислена траектория x(t) и
решениесопряженнойсистемы (4)для i = 0.Введемфункцию
Δ
v
H[t] = Δ
v
H(ψ(t),x(t),u(t),t) =H(ψ(t),x(t),v,t)−H(ψ(t),x(t),u(t),t)
и пусть функция ¯ u = ¯ u(t), t ∈ T, такая, что ¯ u(t) в каждый момент t ∈ T
являетсярешениемследующейзадачи
Δ
¯ u(t)
H[t] = max
v∈U
Δ
v
H[t], t∈T. (5)
Пустьдлязаданногоуправления u
k
(t)вычисленатраектория x
k
(t),ре-
шение сопряженной системы (4) для i = 0, управление ¯ u
k
(t) из условия
максимума (5). Тогда последовательные приближения в соответствии с
Электронныйжурнал.  32Дифференциальные уравнения и процессы управления, N. 1, 2004
методом [52] можно записать так: u
k+1
(t) = ¯ u
k
(t), k = 1,.... Но, к сожа-
лению, для этого простого варианта метода нельзя гарантировать сходи-
мость. Различные модификации этого метода, позволяющие улучшить его
сходимость,изложеныв [58].
Построимфункцию
Δ
¯ u
kH[t] =H(ψ
k
,x
k
,¯ u
k
,t)−H(ψ
k
,x
k
,u
k
,t).
Найдем τ
k
=τ
u
k изусловиямаксимума
Δ
¯ u
k
(t)
H[τ
k
] = max
t∈T
Δ
¯ u
k
(t)
H[t]. (6)
Последовательныеприближениявсоответствиисметодом [26]строятсяпо
формулам
u
k+1
(t) =
(
¯ u
k
(t), t∈T
ε
k
;
u
k
(t), t∈T −T
ε
k
,
(7)
T
ε
k
={t∈T : Δ
¯ u
k
(t)
H[t]≥ε
k
Δ
¯ u
k
(t)
H[τ
k
]}
или
T
ε
k
= [τ
k
−ε
k
(τ
k
−t
0
), τ
k
+ε
k
(t
1
−τ
k
)],
где
ε
k
∈ [0,1]
отыскиваетсяизусловияубыванияфункционала F
0
(u).
Из условия максимума (6) следует, что если Δ
¯ u
k
(t)
H[τ
k
] = 0, то допу-
стимоеуправлениеu
k
(t)удовлетворяетпринципумаксимума.Методытипа
[52],[58],такжекакиитерационныйпроцесс (7),нуждаютсявдополнении,
связанном с тем, что принцип максимума может вырождаться. Поэтому в
[26] итерационный процесс (7) дополняется вычислительной процедурой,
основанной на необходимом условии оптимальности особого управления
(необходимом условии оптимальности второго порядка). Описанию моди-
фикаций метода улучшения допустимого управления второго порядка для
задачоптимальногоуправленияпосвященаработа [8].Такиеметодыявля-
ются достаточно громоздскими, поэтому в вычислительной практике они
неполучилиширокогоприменения.Болеепредпочтительнымвэтомотно-
шении является метод [5], полученный на основе линеаризации управляе-
мой системы без общепринятой коррекции линейного члена в разложении
правойчасти.
Электронныйжурнал.  33Дифференциальные уравнения и процессы управления, N. 1, 2004
Наиболее эффективным в рамках принципа максимума является ме-
тод улучшения управления [73]. Этот метод дает следующую процедуру
варьированияуправления u(t):
u
μ
(t) =
(
u(t), g(t,ψ(t,u))<μ;
v(t,ψ(t,u)), g(t,ψ(t,u))≥μ,
(8)
где
v(t,ψ) = arg max
v∈U
[ψ
∗
f(x(t),v,t)],
g(t,ψ) =ψ
∗
Δ
v(t,ψ)
f[t],
Δ
v
f[t] =f(x(t),v(t),t)−f(x(t),u(t),t).
Параметр μ ≥ 0 подбирается так, чтобы обеспечить уменьшение функци-
онала F(u). Используемая в данном методе линеаризация однозначно ори-
ентирована на получение принципа максимума. При такой линеаризации
формируется и выводится в остаток слагаемое Δ
w
f
x
[t]Δx (для возмущен-
ногоуправленияw(t) =u(t)+Δu(t)).Такаяоперацияснижаеткачествоап-
проксимации Δ
w
F(u) и сказывается на эффективности соответствующих
методов.Этообстоятельствоучтеновметоде [5].Процедураварьирования
вэтомметодевыглядитследующимобразом:
u(t,ψ,ρ) =
(
u(t), g(t,ψ)<ρ;
v(t,ψ), g(t,ψ)≥ρ.
(9)
Длякаждого ρ≥ 0находитсярешение ψ
ρ
(t)сопряженнойсистемы
˙
ψ =−f
x
(x(t),u(t,ψ,ρ),t)
∗
ψ, ψ(t
1
) =−ϕ
0x
(x(t
1
)). (10)
Врезультатеформируютсяуправлениеu
ρ
(t) =u(t,ψ
ρ
(t),ρ)ипараметрρ≥
0 подбирается так, чтобы обеспечить уменьшение функционала F(u
ρ
) ≤
F(u).
Разница между двумя приведенными способами варьирования вполне
наглядна.В(7)сопряженнаятраекторияψ(t,u)зафиксированаотноситель-
ноуправленияu(t)иварьированиепроизводитсянабазезаранееизвестной
функции переключения g(t,ψ(t,u)). В (9), (10) происходит совместное ва-
рьирование управления и сопряженной вектор-функции. Управление u
ρ
(t)
вырабатывается на основе функции переключения g(t,ψ
ρ
(t)) с возмущен-
ным решением ψ
ρ
(t) = ψ(t,u
ρ
) сопряженной системы. Процедура варьиро-
вания (9), (10) для каждого ρ требует, в отличие от (7), дополнительного
интегрированиясопряженнойсистемы.
Электронныйжурнал.  34Дифференциальные уравнения и процессы управления, N. 1, 2004
Численное решение задач оптимального управления с терминальными
ограничениями существенно усложняется по сравнению с решением задач
со свободным правым концом. Это связано с необходимостью учитывать
дополнительные ограничения, причем итерационные методы зависят от
типа ограничений. В задачах с ограничениями-неравенствами [74] мето-
ды последовательных приближений конструируются в классе допустимых
управлений с сохранением всех функциональных ограничений на каждой
итерации. В задачах с ограничениями-равенствами методы работают в
классе доступных управлений, когда функциональные ограничения не вы-
полнены.
Рассмотримвначалезадачуоптимальногоуправления(1)–(3)приогра-
ниченияхтипанеравенства.РазвиваемыйВ.А.Срочков [74]подходсвязан
с линеаризацией функционалов задачи в рамках процедур игольчатого ва-
рьирования. Пусть u(t), t ∈ T — допустимое управление, x(t) = x(t,u)
—соответствующаяемуфазоваятраектория.Выделимнабориндексовак-
тивныхограниченийвместесиндексомцелевогофункционала
I ={0}∪{i = 1,m : F
i
(u) = 0}.
Будемиспользоватьобозначения
Δ
v(t)
H
i
[t,u] =H
i
(ψ
i
(t),x(t),v(t),t)−H
i
(ψ
i
(t),x(t),u(t),t),
H
i
u
[t,u] =H
i
u
(ψ
i
(t),x(t),u(t),t).
Как известно, для решения задачи об улучшении управления u(t)
используется принцип максимума. В традиционной формулировке прин-
ципа максимума обычно присутствуют множители Лагранжа, вопрос
об отыскании которых остается открытым. Поэтому в монографии
В.А.Срочко [74] другая форма представления необходимых условий
(принципа максимума, дифференциального принципа максимума) более
приемлема для реализации. Вводится характеристика допустимого управ-
ления
δ(u) = max
v∈V
min
i∈I
Z
T
Δ
v(t)
H
i
[t,u]dt.
Здесь V — множество допустимых управлений. Очевидно, что δ(u) ≥ 0,
и управление u(t) удовлетворяет принципу максимума тогда и только то-
гда, когда δ(u) = 0. Аналогичным образом в случае дифференциального
Электронныйжурнал.  35Дифференциальные уравнения и процессы управления, N. 1, 2004
принципамаксимумавводитсявеличина:
η(u) = max
v∈V
min
i∈I
Z
T
(H
i
u
[t,u], v(t)−u(t))dt.
Тогда равенство η(u) = 0 эквивалентно выполнению дифференциального
принципамаксимумадляуправления u(t).
Для варьирования управления u(t) выбирается некоторое управле-
ние v ∈ V и вводится функция варьирования χ(t), t ∈ T, из про-
странства L
∞
(T), принимающая только два значения {0,1}. Функция
варьирования нормируется с помощью параметра α ∈ [0,1]:
R
T
χ(t)dt =
α(t
1
−t
0
).ОбозначимчерезX
1
α
семействофункцийварьирования.Совокуп-
ностьварьированныхуправленийстроитсяввиде
u
v,χ
(t) =u(t)+χ(t)(v(t)−u(t)), t∈T.
Длятого,чтобыприварьированииуправленияu∈V обеспечитьуменьше-
ние функционалов V
i
(u), i∈I, необходимо при малых α выбрать парамет-
рыварьированияv∈V,χ∈X
1
α
изусловияминимизациисоответствующих
вариаций δV
i
(u,v,χ), i∈I,т.е.решитьзадачу
min
i∈I
Z
T
χ(t)Δ
v(t)
H
i
[t,u]dt→ max, v∈V, χ∈X
1
α
. (11)
Методпоследовательныхдопустимыхприближенийдлярешениязада-
чи (1)–(3) построен на основе процедуры игольчатого улучшения (метод
игольчатой линеаризации). Пусть u
k
(t), t ∈ T, — допустимое управление;
x
k
(t),t∈T, —соответствующаяфазоваятраектория;ε
k
—положительное
число.Выделиминдексноемножество
I
k
(ε
k
) ={0}∪{i = 1,m : V
i
(u
k
)≥−ε
k
}.
Для i∈I
k
(ε
k
)обозначим
Δ
v
H
ik
[t] = Δ
v
H
i
(ψ
ik
(t),x
k
(t),u
k
(t),t),
где ψ
ik
(t) —решениесопряженнойсистемы
˙
ψ =−H
i
x
(ψ,x
k
(t),u
k
(t),t), ψ(t
1
) =−ϕ
ix
(x
k
(t
1
)).
Решение задачи (11) находится в результате декомпозиции ее на две
подзадачи. Решается первая вспомогательная задача (она получается при
Электронныйжурнал.  36Дифференциальные уравнения и процессы управления, N. 1, 2004
α = 1 (χ(t)≡ 1)):
min
i∈I
k
(ε
k
)
Z
T
Δ
v(t)
H
ik
[t]dt→ max, v∈V. (12)
Пусть ¯ u
k
(t), t∈T, —решениеэтойзадачи;
δ
k
= min
i∈I
k
(ε
k
)
Z
T
Δ
¯ u
k
(t)
H
ik
[t]dt.
Пусть
g
k
i
(t) = Δ
¯ u
k
(t)
H
ik
[t] I
k
(ε
k
).
Решается вторая вспомогательная задача с параметром α ∈ [0,1] (при
v(t) = ¯ u
k
(t)):
min
i∈I
k
(ε
k
)
Z
T
χ(t)g
k
i
(t)dt→ max, χ∈X
1
α
. (13)
Пусть χ
k
α
(t), t∈T, —решениеэтойзадачи;
δ
k
α
= min
i∈I
k
(ε
k
)
Z
T
χ
k
α
(t)g
k
i
(t)dt.
Тогдасемействоварьируемыхуправленийимеетвид
u
k
α
(t) =u
k
(t)+χ
k
α
(t)(¯ u
k
(t)−u
k
(t)), t∈T.
Переходкочередномуприближениюосуществляетсяпоправилу:
а)если δ
k
≤ε
k
,то ε
k+1
=ε
k
/2, u
k+1
(t) =u
k
(t);
б)если δ
k
>ε
k
,то ε
k+1
=ε
k
, u
k+1
(t) =u
k
α
k
(t).
При этом шаг α
k
∈ (0,1] выбирается из условия уменьшения функционала
присохраненииограничений:
F
0
(u
k+1
)<F
0
(u
k
), F
i
(u
k+1
)≤ 0, i = 1,m.
Доказываетсясходимостьметодапоневязкепринципамаксимума.
Замечание. Если в задаче (1)–(3) функциональное ограничение неак-
тивно на управлении u ∈ V (V
i
(u) < 0, i = 1,m), то решение вспомога-
тельных задач (12), (13) можно представить в явном виде. В этом случае
I ={0}, и вспомогательное управление определяется условием максимума
функцииПонтрягина (соответствующеецелевомуфункционалу):
¯ u(t) = arg max
v∈U
H
0
(ψ
0
(t),x(t),v,t), t∈T.
Электронныйжурнал.  37Дифференциальные уравнения и процессы управления, N. 1, 2004
Оптимальнаяфункцияварьированияимеетвид
χ
α
(t) =





0, g
0
(t)<μ
α
;
1, g
0
(t)>μ
α
;
0∨1, g
0
(t) =μ
α
,
где μ
α
— множители Лагранжа, обеспечивающие интегральное условие
R
T
χ
α
(t)dt = α(t
1
−t
0
). В общем случае, когда I 6= {0}, вспомогательные
задачи требуют численного решения. Для минимаксных задач построен
специализированныйметодигольчатогоулучшения.
Метод локального варьирования, связанный с дифференциальным
принципоммаксимума,описываетсяподобнымобразом.Обозначим
H
ik
u
[t] =H
i
u
(ψ
ik
(t),x
k
(t),u
k
(t),t),
иперваявспомогательнаязадачапринимаетвид:
min
i∈I
k
(ε
k
)
Z
T
(H
ik
u
[t],v(t)−u
k
(t))dt→ max, v∈V. (14)
Пусть ¯ u
k
(t), t∈T, —еерешение;
η
k
= min
i∈I
k
(ε
k
)
Z
T
(H
ik
u
[t],¯ u
k
(t)−u
k
(t))dt.
Обозначим
w
k
i
(t) = (H
ik
u
[t],¯ u
k
(t)−u
k
(t));
X
2
α
={χ∈L
∞
(T) : 0≤χ(t)≤α, t∈T}
—множествофункцийварьирования.
Втораявспомогательнаязадачаимеетвид:
min
i∈I
k
(ε
k
)
Z
T
χ(t)w
k
i
(t)dt→ max, χ∈X
2
α
. (15)
Пусть χ
k
α
(t), t∈T, —еерешение;
η
k
α
= min
i∈I
k
(ε
k
)
Z
T
χ
k
α
(t)w
k
i
(t)dt.
Электронныйжурнал.  38Дифференциальные уравнения и процессы управления, N. 1, 2004
Образуемсемействоварьируемыхуправлений
u
k
α
(t) =u
k
(t)+χ
k
α
(t)(¯ u
k
(t)−u
k
(t)), t∈T.
Переход к очередному приближению осуществляется следующим обра-
зом:
а)если η
k
≤ε
k
,то ε
k+1
=ε
k
/2, u
k+1
(t) =u
k
(t);
б)если η
k
>ε
k
,то ε
k+1
=ε
k
, u
k+1
(t) =u
k
α
k
(t).
Шаг α
k
∈ (0,1] выбирается из условия уменьшения функционала при со-
хранении ограничений. Доказывается сходимость метода по невязке диф-
ференциальногопринципамаксимума.Вспомогательныеинтегральныеза-
дачи (14), (15) решаются в рамках метода параметризации с помощью
процедуры нелокального спуска для семейства квадратичных функциона-
лов.
Замечание. Если на управлении u ∈ V все ограничения неактивны
(I ={0}),торешениявспомогательныхзадачимеютвид
¯ u(t) = arg max
v∈U
(H
0
u
[t,u],v),
χ
α
(t) =α, t∈T.
Врезультате,получаемстандартнуюпроцедуруслабогоулучшения,соот-
ветствующуюметодуусловногоградиента:
u
α
(t) =u(t)+α(¯ u(t)−u(t)), t∈T.
Рассмотрим теперь задачу оптимального управления (1)–(3) при огра-
ничениях типа равенства. В этом случае, цель итерации — уменьшение
функционала Лагранжа и функционала невязки типа максимума по огра-
ничениямзадачи.
Введем функционал, характеризующий невязку выполнения ограни-
чений-равенстввзадаче (1)–(3):
F(u) = max
1≤i≤m
|F
i
(u)|.
Пустьλ = (λ
0
,λ
1
,...,λ
m
) —вектормножителейЛагранжавзадаче (1)–(3)
сусловием λ
0
∈{0,1}.Введемобщуюсопряженнуювектор-функцию
ψ(t,λ) =
m
X
i=0
λ
i
ψ
i
(t)
Электронныйжурнал.  39Дифференциальные уравнения и процессы управления, N. 1, 2004
исоответствующуюфункциюПонтрягина
H(λ,ψ,x,u,t) =
m
X
i=0
λ
i
H
i
(ψ
i
,x,u,t).
Понятно,что ψ(t,λ)являетсярешениемсистемы
˙
ψ =−H
x
(λ,ψ,x,u,t), ψ(t
1
) =−
m
X
i=0
λ
i
ϕ
ix
(x(t
1
)).
Причем
H(λ,ψ,x,u,t) = (ψ,f(x,u,t)).
Обозначим
Δ
v(t)
H[t,λ] =H(λ,ψ(t,λ),x(t),v(t),t)−H(λ,ψ(t,λ),x(t),u(t),t).
Отметим, что функция H обслуживает функционал Лагранжа задачи (1)–
(3)
L(u,λ) =
m
X
i=0
λ
i
F
i
(u).
Говорят, что управление u(t) удовлетворяет принципу максимума
(ПМ) в задаче (1)–(3), если найдется вектор λ 6= 0, λ
0
≥ 0 такой, что
выполняетсяусловие
Δ
v
H[t,λ]≤ 0, v∈U, t∈T,
и удовлетворяет дифференциальному принципу максимума (ДПМ), если
выполняетсяусловие
(H
u
[t,λ], v−u(t))≤ 0, v∈U, t∈T.
Для того, чтобы выбрать параметры варьирования v ∈ V, χ ∈ X из
условияминимизациисоответствующихвариацийδF
i
,необходиморешить
задачу
Z
T
χ(t)Δ
v(t)
H
0
[t]dt→ max, v∈V, χ∈X;
Z
T
χ(t)Δ
v(t)
H
i
[t]dt =αF
i
(u), i = 1,m;
Z
T
χ(t)dt =α(t
1
−t
0
).
(16)
Электронныйжурнал.  40Дифференциальные уравнения и процессы управления, N. 1, 2004
Здесь
X ={χ∈L
∞
(T) :χ(t)∈{0,1}}.
Проводится декомпозиция задачи (16). Полагая α = 1 (χ(t)≡ 1), полу-
чаемпервуювспомогательнуюзадачунапоискуправления v(t):
Z
T
Δ
v(t)
H
0
(ψ
0
(t),x(t),u(t),t)dt→ max, v∈V;
Z
T
Δ
v(t)
H
i
(ψ
i
(t),x(t),u(t),t)dt =F
i
(u), i = 1,m.
(17)
Пусть ¯ u(t), t ∈ T, — ее решение,
¯
λ = (
¯
λ
0
,...,
¯
λ
m
),
¯
λ
0
∈ {0,1}, — соответ-
ствующий вектор множителей Лагранжа. Согласно принципу максимума
длязадачи (17)
¯ u(t) = arg min
v∈U
H(
¯
λ,ψ(t,
¯
λ),x(t),v,t), t∈T.
Образуемвспомогательныефункции
g(t,
¯
λ) = Δ
¯ u(t)
H[t,
¯
λ],
g
i
(t) = Δ
¯ u(t)
H
i
[t], i = 1,m.
Для нахождения функции варьирования χ(t) решается вторая вспомо-
гательнаязадача
Z
T
χ(t)g(t,
¯
λ)dt→ max, χ∈X;
Z
T
χ(t)g
i
(t)dt =αF
i
(u), i = 1,m;
Z
T
χ(t)dt =α(t
1
−t
0
).
(18)
Пусть χ
α
(t) — решение задачи (18). Образуем α-параметрическое семей-
ствоуправленийварьирования
u
α
(t) =u(t)+χ
α
(t)(¯ u(t)−u(t)), t∈T.
Вспомогательные задачи (17), (18) позволяют построить семейство управ-
лений u
α
∈ V, α ∈ [0,1], со свойством локального (для малых α > 0)
улучшенияподвумфункционалам F(u), L(u,
¯
λ):
F(u
α
)<F(u) ( F(u)> 0),
Электронныйжурнал.  41Дифференциальные уравнения и процессы управления, N. 1, 2004
L(u
α
,
¯
λ)<L(u,
¯
λ) ( δ(u)> 0).
Метод последовательного улучшения доступных управлений на осно-
ве процедуры слабого варьирования строится подобным образом. Слабое
варьирование управления u(t), t ∈ T, проводится с помощью функций ва-
рьирования χ(t), t∈T,измножества
X
2
α
={χ∈L
∞
(T) : 0≤χ(t)≤α, t∈T}.
Здесь α ∈ [0,1] — параметр варьирования. Задача в вариациях формули-
руетсяточнотакже,каквслучаеигольчатоговарьирования:
Z
T
χ(t)(H
0
u
[t],v(t)−u(t))dt→ max, v∈V, χ∈X
2
α
;
Z
T
χ(t)(H
i
u
(t),v(t)−u(t))dt =αF
i
(u), i = 1,m.
Проводится декомпозиция этой задачи на две подзадачи. Полагая
χ(t) ≡ 1, получаем первую вспомогательную задачу на поиск управления
v(t):
Z
T
(H
0
u
[t],v(t)−u(t))dt→ max, v∈V;
Z
T
(H
i
u
(t),v(t)−u(t))dt =F
i
(u), i = 1,m.
(19)
Пусть ¯ u(t), t ∈ T, — ее решение,
¯
λ = (
¯
λ
0
,...,
¯
λ
m
),
¯
λ
0
= 0∨1, — соответ-
ствующийвектормножителей.Согласнопринципумаксимума
¯ u(t) = arg min
v∈U
(H
u
[t,
¯
λ],v), t∈T.
Образуемвспомогательныефункции
w(t,
¯
λ) = (H
u
[t,
¯
λ],¯ u(t)−u(t)),
w
i
(t) = (H
i
u
[t],¯ u(t)−u(t)), i = 1,m.
Для нахождения функции варьирования χ(t) решается вторая вспомога-
тельнаязадача
Z
T
χ(t)w(t,
¯
λ)dt→ max, χ∈X
2
α
;
Z
T
χ(t)w
i
(t)dt =αF
i
(u), i = 1,m.
(20)
Электронныйжурнал.  42Дифференциальные уравнения и процессы управления, N. 1, 2004
Посколькуфункция χ(t) =αявляетсядопустимой,торешениезадачи (20)
очевидно: χ
α
(t) = α, t ∈ T. Тогда семейство управлений варьирования
имеетвид
u
α
(t) =u(t)+α(¯ u(t)−u(t)), t∈T.
Шаг α ∈ [0,1] выбирается из условия улучшения по двум функционалам
F(u)и L(u,
¯
λ).
Из приведенных результатов видно, что для варьирования управления
конструируются однопараметрическое семейство управлений и формули-
руются специальные вспомогательные задачи. Подходящее значение па-
раметра подбирается с помощью линейного поиска. Однако, возможности
линейногопоискаограниченыиприводяткмедленнойсходимостиминими-
зирующейпоследовательности.Поэтомув[12],[33],[41],[81]используюется
многопараметрическое семейство управлений. Применение многопарамет-
рического (пространственного) поиска существенно расширяет возможно-
сти варьирования: кривая спуска (наискорейшего спуска) в фазовом про-
странствеотслеживаетсяспомощьюкусочно-линейнойаппроксимации (не
с помощью отрезков, а с помощью последовательности симплексов). При
этом вместо второй вспомогательной задачи конструируется специальная
задача для нахождения параметров. Кроме того, отметим, что такой спо-
соб отслеживания кривых спуска может использоваться при минимизации
негладкихфункцийконечногосостояния (типамаксимумавогнутыхфунк-
ций).
Следует подчеркнуть, что приведенный список работ далеко не пол-
ный.Однако,ужесамфактсуществованиямножестваметодоврешенияза-
дач оптимального управления говорит о том, что нельзя однозначно уста-
новитьпревосходствоодногоалгоритманаддругим.Поповодувыбораал-
горитма можно лишь сказать, что необходимо стараться минимизировать
следующийприближенныйпоказатель:
(степень обусловленности) × (время счета одной итерации)
(скорость сходимости)
.
Еслиобозначитьскоростьсходимостичерез r,то
r = 1дляалгоритмовсходящихсялинейно,
r = 2дляалгоритмов,сходящихсяквадратично,и
1<r≤ 2дляалгоритмов,сходящихсясверхлинейно.
Степень обусловленности — это коэффициент, который должен отражать
Электронныйжурнал.  43Дифференциальные уравнения и процессы управления, N. 1, 2004
отклонения формы области поиска от сферической, т. е. быть малым для
почти сферической выпуклой области и большим, если область имеет
неудачнуюформу.Фактическоеегозначениезависитиотконкретногоал-
горитма. Естественно, показатель обусловленности выбирается на основе
опыта. Поэтому актуальна проблема разработки новых численных мето-
дов решения задач оптимального управления, максимально учитывающих
специфику решаемых задач и обладающих малой вычислительной трудо-
емкостью.Решению этой проблемыипосвященаработа.
Научная новизна определяется следующими результатами, получен-
ными автором. На основе линейной интерполяции и кусочно-линейной ап-
проксимациифункциинавыпукломкомпактноммножестверазработаны:
— симплексный метод решения задачи минимизации выпуклой функ-
циинавыпукломкомпактноммножестве;
—приближенныйсимплексныйметодиегомодификация;
—методпоследовательныхприближенийдлязадачиминимизациивы-
пуклогофункционала,определенногонамножествеконечныхсостоянийли-
нейнойсистемыуправления;
— применение симплексного метода для решения линейных задач
управленияслинейнымитерминальнымиограничениями;
— способ построения практически ”реализуемых”управлений для ли-
нейных систем с детерминированными возмущениями и терминальными
ограничениями;
—методкусочно-линейнойаппроксимациидлярешениякраевыхнели-
нейных задач, возникающих в результате применения принципа максиму-
маЛ.С.Понтрягина.
Результаты опубликованывработах [11], [12], [13], [15], [14].
Работасостоитизтрехразделовивведения.
В разделе 1 для задачи нелинейного программирования — задачи ми-
нимизации псевдовыпуклой функции на выпуклом компактном множестве
— описывается симплексный алгоритм (точный) для нахождения решения
(алгоритм 1.1). Алгоритм 1.1 генерирует последовательность симплексов,
на каждом из которых в качестве вспомогательной задачи находится ми-
нимум (точный)целевойфункцииспомощьюалгоритма 1.2.Описываются
два варианта приближенного симплексного алгоритма (алгоритм 1.3), в
котором отыскание локального минимума заменяется определением доста-
точно грубого его приближения. Приводится доказательство сходимости
Электронныйжурнал.  44Дифференциальные уравнения и процессы управления, N. 1, 2004
симплексногоалгоритма.Длязадачиминимизациипсевдовыпуклогофунк-
ционала, определенного на множестве конечных состояний линейной си-
стемы управления, описывается алгоритм для нахождения оптимального
управленияввидевыпуклойкомбинацииэкстремальныхуправленийвспо-
могательныхлинейныхзадачахМайера.
Вразделе2длялинейнойсистемыуправленияслинейнымитерминаль-
ными ограничениями решается задача минимизации выпуклого функцио-
нала на множестве конечных состояний. Для эффективного решения вспо-
могательных экстремальных задач, получаемых в результате применения
метода модифицированной функции Лагранжа и метода параметризации
целевой функции, используется симплексный алгоритм. Дается способ по-
строения практически ”реализуемых”управлений, с помощью которых ли-
нейнаясистемапереводитсяизлюбойначальнойточкивнекоторуюконеч-
ную точку при дополнительных ограничениях и без них. Эти управления
формируются в виде линейных комбинаций управлений, вычисляемых до
началапроцессауправления.
В разделе 3 для решения краевых нелинейных задач, возникающих в
результатепримененияпринципамаксимумаЛ.С.Понтрягина,описывает-
ся алгоритм, являющийся комбинацией метода неподвижной точки и ква-
зиньютоновского метода. Использование кусочно-линейной аппроксимации
функции на триангуляциях позволяет расширить область применимости
алгоритмадлянахождениярешениякраевыхзадач.
В каждом разделе приведены результаты счета, оформленные в виде
таблиц. Программы, по которым производились расчеты, можно найти на
интернетсайте http://viboldirev.narod.ru
Электронныйжурнал.  45Дифференциальные уравнения и процессы управления, N. 1, 2004
1 Симплексный алгоритм для решения экстремаль-
ных задач
В данном разделе рассматривается задача минимизации псевдовыпуклой
функции на выпуклом компактном множестве. Предлагается симплексный
алгоритмдлянахождениярешения.Приводитсядоказательствоегосходи-
мости.Даетсяописаниеприближенногосимплексногоалгоритма.Рассмат-
ривается задача оптимального управления со свободным правым концом.
Критериемкачестваявляетсяпсевдовыпуклыйфункционал,определенный
намножествеконечныхсостоянийлинейнойсистемыуправления.Предла-
гается алгоритм для нахождения решения. Приводятся результаты счета.
Основныерезультатыданногоразделаопубликованывработах [12], [13].
Задача минимизации квадратичной формы на выпуклом компактном
множестве Q в n-мерном евклидовом пространстве была решена Гильбер-
том [104], который предложил находить минимум квадратичной формы с
помощью вычисления локальных минимумов на подходящим образом вы-
бранной последовательности линейных сегментов во множестве Q. Барр
[96] обобщил итеративную процедуру Гильберта так, что минимизация
производитсянапоследовательностивыпуклыхмногогранников(методвы-
пуклых оболочек, см. так же [41], [81], [33]). В [110], как альтернатива
процедуре Барра, был предложен симплексный алгоритм, в котором на
каждом шаге минимизация выполняется на выпуклой оболочке n + 1-ой
точки (т.е. на n-симплексе). Алгоритмы, в которых аппроксимация реше-
нийосуществляетсяспомощьюсимплексов,вдальнейшембудемназывать
симплексными.
Вданномразделерешаетсязадачаминимизациипсевдовыпуклойфунк-
ции ϕ(x), определенной на выпуклом компактном множестве Q евклидова
пространства [12].Поискминимумафункцииобычновэтомслучаеосуще-
ствляетсяфактическиспомощьюопорныхкмножествуQгиперплоскостей
(внешнее представление множества). Любая же точка выпуклого множе-
ства является линейной комбинацией не более n+1 крайней точки этого
множества (внутреннее представление). Поэтому целесообразно использо-
вать именно это внутреннее представление множества при поиске мини-
мума функции конечного состояния. В то же время, в результате решения
вспомогательнойзадачилинейногопрограммированияполучаетсякрайняя
точкамножества,темсамым,полученноерешениевспомогательнойзадачи
является ”мостом”между внешним и внутренним представлениями множе-
Электронныйжурнал.  46Дифференциальные уравнения и процессы управления, N. 1, 2004
ства.
Предлагаемыйв [12]алгоритмрешениязадачиминимизациипсевдовы-
пуклой функции на выпуклом компактном множестве строится на основе
методов [106]. В работе [106] для нахождения максимума псевдовогнутой
функции (см. [108], стр. 140–144]), заданной на многограннике предлага-
ется алгоритм, который находит точный максимум целевой функции за
конечное число шагов. Этот алгоритм использует внутреннее представле-
ние допустимого множества, разлагая его на симплексы переменной раз-
мерности. Используя линейную программу, алгоритм вырабатывает по-
следовательность симплексов, которые содержат локальные относительно
симплексов максимумы. Получаемая последовательность локальных мак-
симумовстроговозрастающая,инаибольшийизнихявляетсяглобальным
максимумом на допустимом множестве. Нахождение локальных максиму-
мов на этих симплексах сводится к максимизации целевой функции на аф-
финныхмногообразиях (см. [71],стр. 19–29).
Предлагаемый алгоритм вырабатывает с помощью решения вспомо-
гательной задачи линейного программирования симплексы в допустимом
множестве. На этих симплексах осуществляется минимизация псевдовы-
пуклойцелевойфункции.Приэтомпредполагается,чтофункцияконечного
состояниядолжнадопускатьрешениевзамкнутойформеуравнений,выте-
кающих из необходимых условий оптимальности. В идейном плане способ
нахождения локального относительно симплекса минимума такой же, как
ив [106].Вотличиеот [106]процесснахожденияглобальногонамножестве
достижимости минимума будет уже бесконечным. Однако, использование
симплексов в процессе минимизации делает вычислительную процедуру
достаточноэффективной.
Одним из способов решения задачи оптимального управления с помо-
щью принципа максимума Л.С.Понтрягина [68] является сведение ее ре-
шения к решению краевой задачи (см., например, [70], [61], [66], [84]). Для
решениякраевойзадачи,возникающейврезультатепримененияпринципа
максимума, предложены различные приближенные методы (методы про-
гонки, метод Ньютона, квазиньютоновские методы, методы градиентно-
го типа — проекции градиента, условного градиента [61], [66], [84], [32],
[56], [41], [81]). При нахождении минимума функционала на множестве ко-
нечныхсостоянийлинейнойсистемыуправлениярешениеисходнойзадачи
сводитсякрешениюсериивспомогательныхлинейныхзадачоптимального
управления (задачМайера),кнахождениюминимумацелевойфункцииик
Электронныйжурнал.  47Дифференциальные уравнения и процессы управления, N. 1, 2004
определению допустимого управления, переводящего систему в найденную
точку минимума. В случае решения задачи минимизации нормы конеч-
ного состояния управляемой системы решение исходной задачи сводится
к вычислению минимума квадратичной формы на компактном выпуклом
множестве Qв n-мерномевклидовомпространстве.
В данном разделе рассматривается задача минимизации псевдовыпук-
логофункционалаϕ(x),определенногонамножествеQконечныхсостояний
линейнойсистемыуправления.Решениеисходнойзадачисводится:
1) к решению задачи нелинейного программирования ϕ(x) → min
x∈Q
(к
нахождениювектора ˆ x∈Q),азатем:
2)кнахождениюуправления,приводящеготраекториюсистемывточ-
ку ˆ x.
Приводимый в этом разделе алгоритм решения задачи минимиза-
ции функционала на множестве конечных состояний линейной системы
управления строится на основе методов [33], [106]. В работе [33] описыва-
ется алгоритм для решения задачи минимизации нормы конечного состо-
яния управляемой системы. Оптимальное управление в исходной задаче
находится в виде выпуклой комбинации оптимальных управлений вспомо-
гательных задач Майера, поиск минимума квадратичной функции (нор-
мы конечного состояния) на множестве достижимости состоит в последо-
вательном решении задач квадратичного программирования — задач по
определению точки выпуклой оболочки (симплекса), ближайшей к началу
координат (метод выпуклых оболочек, см. также [41], [81]). Задача нахо-
ждения минимума квадратичной функции на симплексе решается с помо-
щью конечно-шаговой процедуры, на каждой итерации которой определя-
етсябезусловныйминимумквадратичнойфункции.
Вработе[106]длянахождениямаксимумапсевдовогнутойфункции(см.
[108], стр. 140–144]), заданной на многограннике предлагается алгоритм,
который находит точный максимум целевой функции за конечное число
шагов. Этот алгоритм использует внутреннее представление допустимого
множества.Предлагаемыйв [12]алгоритмвырабатываетспомощьюреше-
ния вспомогательной задачи Майера симплексы во множестве достижимо-
сти. На этих симплексах, в отличие от [33], осуществляется минимизация
псевдовыпуклойцелевойфункции.
Электронныйжурнал.  48Дифференциальные уравнения и процессы управления, N. 1, 2004
1.1. Основные понятия и определения
Основным инструментом в нашем построении является кусочно-ли-
нейная аппроксимация (PL-аппроксимация) отображения f : R
n
→ R
n
.
Эта аппроксимация определяется через значения f в вершинах n-мерных
симплексов.
Пусть P = {x
0
,...,x
n
} — множество (аффинный базис). Аффинная
оболочка множества P является линейным многообразием M = {x : x =
Pα,
n
P
i=0
α
i
= 1}.Еслиточкаx∈M,тоонаможетбытьпредставленаввиде
x =Pα,
n
X
i=0
α
i
= 1. (1.1)
ВыпуклаяоболочкааффиннонезависимыхточекмножестваP представля-
ет собой n-мерный симплекс (n-симплекс): σ = {x : x = Pα, α
i
≥ 0, i =
0,n,
n
P
i=0
α
i
= 1}.
Величина diam σ = max{kx
1
−x
2
k
∞
: x
i
∈ σ, i = 1,2} называется
диаметром симплекса. Говорят, что отображение L
P
x = Ax+c является
линейнойаппроксимациейотображенияf : R
n
→R
n
,еслиf(x
i
) =Ax
i
+c,
i = 0,n. Здесь A — действительная невырожденная n×n-матрица, c —
действительный n-вектор.
Пусть точка x лежит в некотором симплексе σ (не обязательно един-
ственном),ипоэтомуимеетбарицентрическоепредставлениеотносительно
вершинсимплекса σ:
x =
n
X
i=0
α
i
x
i
,
n
X
i=0
α
i
= 1, α≥ 0, i = 0,n. (1.2)
Значение L
P
вточке x∈σ даетсясоотношением
L
P
x =
n
X
i=0
α
i
f(x
i
), (1.3)
где α
i
удовлетворяет (1.2). Если x лежит в пересечении двух или более
симплексов, то x лежит в относительной внутренности некоторой j-грани
τ. Для любого j ∈ {0,...,n} j-грань τ в σ есть выпуклая оболочка неко-
торых (j +1) вершин симплекса τ: τ = [x
i
0
,...,x
i
j
]. Только ненулевым α
i
вформуле (1.2)соответствуютвершиныτ,которыеявляютсяобщимидля
Электронныйжурнал.  49Дифференциальные уравнения и процессы управления, N. 1, 2004
любого симплекса τ, содержащего x. Таким образом, определение отобра-
женияL
P
зависиттолькоотxинезависитотвыборачастногосимплекса,
содержащего x. Отображение L
P
явно обладает интерполяционным свой-
ством.
Пусть ΔX = (x
0
−x
n
,...,x
n−1
−x
n
), ΔF = (f(x
0
−x
n
),...,f(x
n−1
−x
n
)).
Изальтернативногопредставленияформул (1.1)и (1.3)x =x
n
+
n−1
P
i=0
α
i
(x
i
−
x
n
)и L
P
x =f(x
n
)+
n−1
P
i=0
α
i
(f(x
i
)−f(x
n
))следует,что
L
P
x = ΔF(ΔX)
−1
x+(f(x
n
)−ΔF(ΔX)
−1
x
n
). (1.4)
Триангуляция пространства R
n
есть набор n-симплексов T = {σ
i
: i =
1,2,...}, объединение которых покрывает пространство R
n
, элементы ко-
торогопересекаютсяпопарнопоодной(самоебольшее)общейj-грани,при-
чем пересечение этого объединения с любым ограниченным множеством
состоитизконечногочисласимплексов.
Величина mesh T = sup{diam σ : σ ∈ T} называется мелкостью три-
ангуляции T. Приведем в качестве примера триангуляцию Фройденталя
[107], [94]. Эта триангуляция пространства R
n
определяется точкой x
0
и
имеет мелкость, пропорциональную заданному положительному числу δ.
Будем обозначать ее T
n
[x
0
,δ] и определять следующим образом. Верши-
ны триангуляции являются узловыми точками множества x
0
+δZ
n
, где Z
обозначаетмножествоцелыхчисел.Тогдаn-симплексσ можетбытьопре-
деленвершинойz
0
∈Z
n
иперестановкойπ множества{1,...,n},аименно:
σ = [x
0
,...,x
n
], x
0
= x
0
+δz
0
и x
i
= x
i−1
+δe
π(i)
, i = 1,n. Здесь e
1
,...,e
n
— стандартный ортонормированный базис. Диаметр любого симплекса σ
в T
n
[x
0
,δ]есть δ,такчтомелкостьютриангуляцииФройденталяявляется
также δ.
Кусочно-линейное отображение F
T
: R
n
→ R
n
на триангуляции опре-
деляетсязначениямиотображенияf ввершинахсимплексовтриангуляции
T.Внутрисимплексоввсегопространства R
n
отображениеF
T
определяет-
сяинтерполяцией.Значит,
F
T
x =
n
X
i=0
α
i
f(x
i
), x∈σ∈T, (1.5)
где α
i
определяетсявсилу (1.2).Аналогичноформуле (1.4)имеем:
F
T
x = ΔF(ΔX)
−1
x+(f(x
n
)−ΔF(ΔX)
−1
x
n
). (1.6)
Электронныйжурнал.  50Дифференциальные уравнения и процессы управления, N. 1, 2004
Известно, что идея метода секущих для нахождения решения систе-
мы нелинейных алгебраических уравнений основано на замене нелинейно-
го отображения f линейным интерполирующим отображением. Нуль ли-
нейного отображения принимается в качестве очередного приближения к
решениюнелинейнойсистемы,т.е.на (k+1)-йитерацииx
k+1
являетсяре-
шениемлинейнойсистемыL
P
x = 0.Используяпредставления (1.3), (1.4)и
применяя стандартную нумерацию точек в зависимости от номера итера-
ции,получимследующиедвавидаметодасекущих
x
k+1
=
n
X
i=0
α
i
x
k−i
, k = 0,1,..., (1.7)
где коэффициенты разложения α
i
находятся в результате решения линей-
нойсистемы
n
P
i=0
α
i
f(x
k−i
) = 0,
n
P
i=0
α
i
= 1;
x
k+1
=x
k
−ΔX
k
(ΔF
k
)
−1
f(x
k
), k = 0,1,... . (1.8)
Методы кусочно-линейной аппроксимации (PL-методы) успешно ис-
пользуются для решения системы нелинейных алгебраических уравнений
f(x) = 0 или для нахождения неподвижных точек x таких, что f(x) = x.
Показано, что определенные реализации этих методов имеют квадратич-
ную скорость сходимости, когда они подходят достаточно близко к реше-
нию, и в этих случаях (без использования производных отображения) вы-
числительныезатратысравнимысзатратамиметодаНьютона [114], [117].
Можно показать, что если f имеет якобион f
0
(x), который непрерывен
по Липшицу в окрестности симплекса σ, то существуют константы K
1
и
K
2
такие,что
kf(x)−F
T
xk≤K
1
(diam σ)
2
и kf
0
(x)−ΔF(ΔX)
−1
k≤K
2
(diam σ),
гдеx∈σ инормыявляются sup-нормами.Длятого,чтобыгарантировать
локальное существование решений уравнения, необходимо предположить
регулярность отображения f, т.е. матрица f
0
(x) должна иметь полный
ранг. Аналогичное условие для F
T
состоит в том, что ΔF имеет полный
ранг.
При работе PL-метода генерируется последовательность симплексов
σ
k
,диаметрыкоторых ε
k
≡ diam σ
k
стремятсякнулю,инаэтихсимплек-
сахнаходятсярешения x
k
линейнойсистемы F
T
x = 0 (см. (1.5), (1.6)),т.е.
системы
n
P
i=0
α
i
f(x
ik
) = 0,
n
P
i=0
α
i
= 1, α
i
≥ 0, i = 0,n (здесь x
ik
— вершины
Электронныйжурнал.  51Дифференциальные уравнения и процессы управления, N. 1, 2004
симплекса σ
k
). Подчеркнем дополнительно, что симплексы σ
k
принадле-
жат некоторой триангуляции. В гомотопном методе, в методе непрерыв-
ной деформации эти n-симплексы являются n-гранями (n+1)-симплексов.
Обычно, такие грани называют полностью размеченными или полными.
В (n + 1)-симплексе имеются две полностью размеченные n-грани. Этот
(n + 1)-симплекс, содержащий полностью размеченную грань, и сама n-
граньназываютсяпоперечными.Такимобразом,PL-алгоритмымогутрас-
сматриватьсякакнепрерывнаядеформация F
k
(кусочно-линейной аппрок-
симации отображения f на симплексах σ
k
триангуляции) к F
∞
= f и как
отслеживаниепутиизнулейx
k
аппроксимацииF
k
приk→∞.Приопреде-
ленных условиях на отображение f можно показать, что путь x
k
сходится
кнулюотображения f (см.,например, [113], [114], [117]).
Рассмотрим теперь применение метода линейной аппроксимации и
метода кусочно-линейной аппроксимации для решения задач оптимиза-
ции. Пусть задана псевдовыпуклая функция ϕ: R
n
→ R
1
. Функция ϕ:
D⊆R
n
→R
1
называетсяпсевдовыпуклойнавыпукломмножествеD
0
⊆D
(см. [108],стр. 140–144]),еслидлялюбых x,z∈D
0
имеетместо
(ϕ
0
(z),x−z)≥ 0⇒ϕ(x)≥ϕ(z).
Очевидно, что задача безусловной минимизации ϕ(x) → min
x∈R
n
сводится к
решению нелинейной системы алгебраических уравнений g(x)≡ϕ
0
(x) = 0.
Решение этих уравнений можно осуществить указанными выше методами
секущихи PL-методами.
Рассмотримзадачунелинейногопрограммирования
ϕ(x)→ min
x∈Q
, (1.9)
гдеϕ(x) —псевдовыпуклаяфункция,аQ —замкнутоевыпуклоекомпакт-
ное множество конечномерного пространства V. Пусть V
∗
— сопряженное
пространство.Определимотображение z :V
∗
→V следующимобразом:
z(g) = arg min
x∈Q
(g,x). (1.10)
Валгоритмахоптимизацииименноэтоотображениеслужитфундаментом
дляпостроенияминимизирующейпоследовательности.Прирешениизада-
чи нелинейного программирования вида (1.9) V = R
n
, g = ϕ
0
(y), g ∈ V
∗
,
y ∈ Q. Для задачи оптимального управления пространство V является
пространством фазовых координат, а элемент g ∈ V
∗
определяется крае-
вым условием ψ(t
1
) = −g сопряженной системы (в частности, для задачи
минимизациифункции ϕ(x)конечногосостояния g =ϕ
0
(y), y∈Q).
Электронныйжурнал.  52Дифференциальные уравнения и процессы управления, N. 1, 2004
1.2. Алгоритм решения задачи нелинейного программирования
Рассмотримзадачунелинейногопрограммирования
ϕ(x)→ min
x∈Q
, (1.11)
где ϕ(x) — псевдовыпуклая функция, а Q — выпуклое компактное мно-
жество. Ниже приводится алгоритм решения задачи (1.11), являющийся
обобщением метода условного градиента. Суть метода условного гради-
ента заключается в том, что на каждом шаге проводится линеаризация
функции ϕ(x) в точке y
k
, решается вспомогательная линейная задача ми-
нимизации
(ϕ
0
(y
k
),x)→ min
x∈Q
,
а минимизатор z
k
∈ ∂Q в этой задаче определяет направление движения
дляполученияследующегоприближения.Такимобразом,
(ϕ
0
(y
k
),z
k
)≤ (ϕ
0
(y
k
),x) длявсех x∈Q, z
k
∈∂Q,
y
k+1
=y
k
+θ
k
(z
k
−y
k
), 0≤θ
k
≤ 1,
где θ
k
—решениезадачиодномернойминимизации
ϕ(y
k
+θ(z
k
−y
k
))→ min
θ∈[0,1]
.
Более эффективным методом для решения задачи (1.11) является сим-
плексныйметод (методвыпуклыхоболочек [96], [33], [41]).Онможетбыть
интерпретирован как обобщение метода условного градиента (решается
вспомогательная задача минимизации целевой функции не на отрезке, а
на симплексе). Пусть в результате вычислений на k-й итерации получе-
ны крайние точки z
0
,...,z
q
, q ≤ n, множества Q. Множество (выпуклая
оболочка q+1точки)
σ
k
=
(
x∈Q : x =
q
X
i=0
α
i
z
i
, α
i
≥ 0, i = 0,q,
q
X
i=0
α
i
= 1
)
естьq-мерныйсимплекс.Накаждомшагесимплексногометодапроводится
линеаризация функции ϕ(x) в точке y
k
, решается вспомогательная линей-
ная задача минимизации (ϕ
0
(y
k
),x)→ min
x∈Q
, а минимизатор z
k
”замещает”в
симплексе σ
k
вершину z
i
0
. Эта точка является противолежащей вершиной
Электронныйжурнал.  53Дифференциальные уравнения и процессы управления, N. 1, 2004
по отношению к грани, в которой находится точка y
k
. В дальнейшем ба-
зис, определяющий такую грань минимальной размерности, будем обозна-
чать S
k
. Полученный таким образом очередной симплекс σ
k+1
и симплекс
σ
k
имеют общую грань, в которой находится точка y
k
. Такие симплексы
называются смежными, а каждый из них — поперечным. Следующее при-
ближениеy
k+1
получаетсяврезультатерешениязадачиминимизациивида
ϕ(x)→ min
x∈σ
k+1
.Такимобразом,
(ϕ
0
(y
k
),z
k
)≤ (ϕ
0
(y
k
),x) длявсех x∈Q, ϕ(y
k+1
)≤ϕ(y
k
).
Обозначим P = {z
0
,...,z
q
} — аффинный базис, Δ(P)
Δ
≡ [z
0
,...,z
q
] —
выпуклая оболочка P (замкнутый симплекс или просто симплекс), ri σ —
внутренностьсимплекса σ относительноегоафиннойоболочки.
Алгоритм 1.1 (решениезадачинелинейногопрограммирования):
0. Задать ¯ z ∈Q. Вычислить g
0
=ϕ
0
(¯ z). Найти крайнюю точку z
0
∈Q,
решивзадачу (g
0
,x)→ min
x∈Q
.Положить y
0
=z
0
, P
1
={z
0
}, σ
1
= [z
0
], k = 1.
1. Вычислить g
k
= ϕ
0
(y
k−1
). Найти крайнюю точку z
k
∈ Q, решив
задачу (g
k
,x)→ min
x∈Q
.
2. a)Если (g
k
,z
k
−y
k−1
) = 0,процесспрекращается;
b) Если (g
k
,z
k
−y
k−1
) < 0, то дополнить базис P
k
вектором z
k
: P
k
=
P
k
∪{z
k
}, σ
k
= Δ(P
k
).Перейтикследующемушагу.
3. Найти решение y
k
задачи нелинейного программирования ϕ(x) →
min
x∈σ
k
,приняввкачественачальнойточкиy
k−1
.ПоложитьP
k+1
=S
k
,σ
k+1
=
τ
k
, k =k+1.Перейтикшагу 1.
Приведенный алгоритм является прямым методом в том смысле, что
получаемаяималгоритмическаяпоследовательностьопределяетсянадопу-
стимом множестве. Он вырабатывает строго убывающую последователь-
ность {ϕ(y
k
)} значений функции ϕ(x). В то же время алгоритмом гене-
рируется последовательность смежных симплексов {σ
k
}, для каждого из
которых y
k
являетсялокальнымминимизаторомфункции ϕ(x),т.е.
ϕ(y
k
) = min
x∈σ
k
ϕ(x). (1.12)
Вершинами симплекса σ
k
являются крайние точки z
k
множества Q, по-
лучаемые с помощью решения вспомогательной задачи математического
Электронныйжурнал.  54Дифференциальные уравнения и процессы управления, N. 1, 2004
программирования (ϕ
0
(y
k
),x)→ min
x∈Q
.Симплексσ
k
определяетсяаффинным
базисом P
k
= {z
0
,...,z
q
}, 0 ≤ q ≤ n. Но так как локальный минимум y
k
может лежать на грани размерности p≤ n−1 симплекса σ
k
(в симплексе
σ
p
k
меньшей размерности, чем размерность σ
k
), то некоторые весовые ко-
эффициенты (по меньшей мере, 1) в барицентрическом представлении y
k
будутравны 0.Пусть
y
k
=P
k
w =z
0
w
0
+...+z
q
w
q
.
Тогдаможнозаписать
S
k
={z
j
, j ∈J(w)}, τ
k
= Δ(S
k
),
где J(w) ={j : w
j
6= 0, j = 0,q}.Очевидно,что S
k
⊂P
k
, τ
k
⊂σ
k
.
Пустьy(τ) —криваяспуска,проходящаячерезточкиy
k
.Тогдаможно
сказать,чтоэтакриваяотслеживаетсяпоследовательностьюсмежныхсим-
плексов,асамапоследовательностьсимплексовобразуеткусочно-линейное
многообразие. Таким образом, кривая спуска содержится в этом многооб-
разии и аппроксимируется ломанной, полигонами которой являются от-
резки [y
k−1
,y
k
]. Такой способ задания кривых является уникальным. Из-
вестно, что, если минимум ϕ(x) на Q достигается в точке ˆ x, то условие
(ϕ
0
(ˆ x),x−ˆ x)≥ 0длявсехx∈Qявляетсянеобходимымусловиемминимума
(и достаточным в выпуклом случае). Эквивалентно (ϕ
0
(y
k−1
),z−y
k−1
)< 0
для некоторого z ∈Q означает, что y
k−1
не является минимизатором на Q
(см. шаг 2. b) алгоритма 1.1). Поэтому величина δ(x) = sup
z∈Q
(ϕ
0
(x),x−z)
может быть неотрицательной и равной нулю в точках, в которых выпол-
няетсяусловиеэкстремума.Следовательно,онаможетслужитьмеройбли-
зости к минимуму. Справедливо следующее утверждение (см. теорему 3.1
из [106]).
Лемма 1.1.Пустьϕ является псевдовыпуклой, и пусть ¯ z — решение
задачи (ϕ
0
(y),x)→ min
x∈Q
. Тогдаy — минимизируетϕ наQ в том и только
том случае, когда имеет место равенство
(ϕ
0
(y),¯ z−y) = 0.
Лемма 1.2 ([43],стр. 48) (необходимоеусловиеглобальногоминимума
функциинамножестве). Пусть ϕ(x) — выпуклая и непрерывно дифферен-
цируемая функция; Q — выпуклое компактное множество. Точка ˆ y ∈ Q
Электронныйжурнал.  55Дифференциальные уравнения и процессы управления, N. 1, 2004
является решением задачи (1.11) тогда и только тогда, когда
(ϕ
0
(ˆ y),z− ˆ y)≥ 0 z∈Q.
1.3. Минимизация функции на симплексе
Впредыдущемпунктедлянахожденияминимизаторафункцииϕ(x)на
выпуклом множестве Q необходимо было решать (шаг 3 алгоритма 1.1)
вспомогательнуюзадачу
ϕ(x)→ min
x∈σ
. (1.13)
Здесь σ — q-симплекс, σ⊂R
n
(0≤q≤n).
Пусть начальная точка z = Pw, P = {z
0
,...,z
q
}, σ = Δ(P), M =
{x : x = Pα,e
∗
α = 1} — q-многообразие, где e = (1,...,1)
∗
. Решение
задачи (1.13) сводится к решению конечного числа (не превосходящего n)
задач минимизации функций ϕ(x) на многообразиях M
p
уменьшающейся
размерности p≤n−1.
Алгоритм 1.2 (решениезадачиминимизациинасимплексе):
1.Найтирешение x
0
задачиминимизации
ϕ(x)→ min
x∈M
, (1.14)
x
0
=Pw
0
.
a)Если w
0
i
> 0длявсех i = 0,q,то x
0
∈ ri σ являетсяминимизатором ¯ x
функции ϕна σ.Полагаем y =x
0
, S =P,процесспрекращается.
b) Если по меньшей мере одно w
0
i
< 0, то x
0
6∈ ri σ. Получили ϕ(x
0
) <
ϕ(y
k−1
).Перейтикследующемушагу.
2.Определитьточкуx
p
пересеченияотрезка [z,x
0
]сграницейсимплек-
са σ. Пусть x
p
= Pw
p
= z
0
w
p
0
+... +z
q
w
p
q
. Получим x
p
= z +λ(x
0
−z),
0 < λ ≤ 1, w
p
i
= λw
0
i
+ (1−λ)w
i
≥ 0, i = 0,q, причем для некоторого j
w
p
j
= 0, λ =
 
max
i∈J(w)
w
i
−w
0
i
w
i
 
−1
.
3.УдаляемизP вершиныz
j
,j 6∈J(w
p
),которыенеявляютсяносителя-
ми x
p
, что приводит к уменьшению аффинного базиса. Полученный базис
P
p
порождаетподсимплекс σ
p
⊂σ.
Электронныйжурнал.  56Дифференциальные уравнения и процессы управления, N. 1, 2004
a)Если σ
p
имеетнулевуюразмерность, y =x
p
являетсяегоединствен-
ной точкой и, таким образом, относительным локальным минимизатором
ϕна σ
p
.Полагаем y =x
p
, S =P
p
,процесспрекращается.
b) Если σ
p
имеет размерность > 0, полагаем z =x
p
, P =P
p
, M =M
p
,
σ =σ
p
,переходимкшагу 1.
Вдальнейшембудутполезныследующиелеммы (см. [106],лемма 3.4).
Лемма 1.3. Пусть ϕ псевдовыпукла и пусть ϕ(x
0
) < ϕ(z). Тогда
любое x
p
=λx
0
+(1−λ)z, 0<λ≤ 1, удовлетворяет неравенству ϕ(x
p
)<
ϕ(z).
Доказательство. Допустим противное, что ϕ(x
p
) ≥ ϕ(z). Отсюда в
силупсевдовыпуклостиследует: (ϕ
0
(z),x
p
−z)≥ 0.Преобразуявыражение
дляx
p
,получимx
0
−z =
1
λ
(x
p
−z), 1≤
1
λ
< +∞.Домножимлевуюиправую
частиравенстваскалярнона ϕ
0
(z):
(ϕ
0
(z),x
0
−z) =
1
λ
(ϕ
0
(z),x
p
−z)≥ 0.
Из этого неравенства в силу псевдовыпуклости функции ϕ следует, что
ϕ
0
(x
0
)≥ϕ(z).Получилипротиворечие,котороедоказываетлемму.
Лемма 1.4 [106]. Пусть y и z такие, что ϕ(x) ≥ ϕ(y) для всех x ∈
[y,z]. Тогда (ϕ
0
(y),z−y)≥ 0.
Решение задачи (1.13) условной минимизации является конечно-шаго-
вой последовательной процедурой нахождения критических точек функци-
оналаϕ(x)намногообразияхM
p
(уменьшающейсяразмерности),содержа-
щих грани симплекса σ
k
. Отметим, что удобнее осуществлять минимиза-
цию на многообразиях в пространстве барицентрических координат, так
как используется внутреннее представление множества Q. Если найден-
ная на шаге 1 алгоритма 1.2 критическая точка x
0
∈ ri σ, то цель итера-
ций при переходе от минимизатора y
k−1
∈ ri σ
k−1
⊂ Q к минимизатору
y
k
∈ ri σ
k
⊂ Q достигнута, а именно y
k
= x
0
, ϕ(y
k
) < ϕ(y
k−1
). Если же
точка x
0
6∈ ri σ, то находится x
p
— точка пересечения отрезка [x
0
,y
k−1
] с
границей σ ⊂ M. Дальнейшее удаление из базиса P ненесущих вершин
не влияет на положение x
p
в σ, так как в этом случае изменяется только
барицентрическая система координат (w заменяется на w
p
). Точка же x
p
находится в ri σ
p
⊂ σ, σ
p
⊂ σ, то есть в подсимплексе, соответствующем
подбазису P
p
⊂P.
По лемме 3.1 x
p
удовлетворяет неравенству ϕ(x
p
) < ϕ(y
k−1
) и, таким
образом,новыйминимизатор x
0
насоответствующемподмногообразии M
p
Электронныйжурнал.  57Дифференциальные уравнения и процессы управления, N. 1, 2004
будет удовлетворять неравенству ϕ(x
0
)≤ ϕ(x
p
) < ϕ(y
k−1
). Если x
0
∈ ri σ
p
,
то итерация завершилась успешно. В противном случае, x
0
6∈ ri σ
p
проце-
дураповторяетсяпри σ =σ
p
, P =P
p
, M =M
p
.
Заметим, что наиболее трудоемким в алгоритме 1.2 является шаг 1 —
нахождение критической точки функции ϕ(x) на многообразии. Очевидно,
что min
x∈M
ϕ(x) = min
α
ϕ(Pα). В правой части последнего равенства берется
минимум по α при условии e
∗
α = 1.Можно легко избавиться от ограниче-
ния e
∗
α = 1.Пусть
D = (z
0
−z
q
,...,z
q−1
−z
q
), β = (α
0
,...,α
q−1
)
∗
.
Тогда α
n
= 1−
n−1
P
i=0
β
i
, а задача (1.14) преобразуется к задаче без огра-
ничений ϕ(Dβ +z
q
) → min
β
. Поэтому для нахождения критической точки
функции ϕ(x)нужнорешитьотносительно β системууравнений.
D
∗
ϕ
0
(Dβ +z
q
) = 0. (1.15)
В силу сказанного, ясно что для большей эффективности алгоритма необ-
ходимо чтобы система (1.15) допускала решение в замкнутой форме. Это
имеет место, например, если ϕ(x) — положительно определенная квадра-
тичнаяфункция.
1.4. Сходимость симплексного алгоритма
Утвержденияосходимостиалгоритма 1.1приводятсявследующейте-
ореме.
Теорема 1.1 (сходимость алгоритма 1.1). Пусть Q — выпуклое ком-
пактное множество в R
n
, ϕ(x) — псевдовыпуклая функция на R
n
, {y
k
},
k = 0,1..., — последовательность, генерируемая алгоритмом 1.1. Тогда:
1) если последовательность {y
k
} конечна (т.е. {y
0
,y
1
,...,y
l
,y
l+1
}),
то y
l
является решением задачи (1.11);
2) если последовательность {y
k
} бесконечна, то каждая ее точка
сгущения является решением задачи (1.11), т.е. ϕ(y
k
) монотонно убыва-
ет и lim
k→∞
(ϕ
0
(y
k−1
),y
k−1
−z
k
) = 0.
Доказательство.Доказательствосходимостиминимизирующейпосле-
довательности проводится по схеме доказательства теоремы 3 [109] с уче-
томспецификисимплексногоалгоритма.
Электронныйжурнал.  58Дифференциальные уравнения и процессы управления, N. 1, 2004
Предположим, что алгоритм генерирует только конечную последова-
тельностьy
0
,...,y
l
,y
l+1
.Тогдаϕ(y
l+1
) =ϕ(y
l
).Действительно,на (l+1)-й
итерациинашаге 1алгоритмабудетполученакрайняяточка z
l+1
,тоесть
(ϕ
0
(y
l
),z−z
l+1
)≥ 0 z∈Q. (1.16)
Пусть ˜ y
l+1
∈I ≡ [y
l
,z
l+1
]такое,что
ϕ(˜ y
l+1
)≤ϕ(z) z∈I.
Значит,
ϕ(˜ y
l+1
)≤ϕ(y
l
). (1.17)
Всилужепункта 3алгоритма
ϕ(y
l+1
)≤ϕ(z) z∈σ
l+1
.
Втожевремя, ˜ y
l+1
∈ [y
l
,z
l+1
]⊂σ
l+1
.Поэтомуϕ(y
l+1
)≤ϕ(˜ y
l+1
).Учитывая
(1.17) и предположение ϕ(y
l+1
) = ϕ(y
l
), получаем ϕ(˜ y
l+1
) = ϕ(y
l
) ≤ ϕ(z)
длявсех z∈I.Новсилулеммы 4этоозначает,что
(ϕ
0
(y
l
),z
l+1
−y
l
)≥ 0. (1.18)
Из (1.16)и (1.18)следует,что
(ϕ
0
(y
l
),z−y
l
)≥ 0 z∈Q
и,следовательно,всилулеммы 2, y
l
—решениезадачи (1.11).
Предположим теперь, что алгоритм генерирует бесконечную последо-
вательность {y
k
}, и пусть ˆ y будет точкой сгущения этой последователь-
ности. Тогда существует неограниченное подмножество K
1
целых чисел
такое,чтоподпоследовательность{y
k
}
K
1
сходитсяк ˆ y.
Пусть ˜ y
k
∈ I
k
≡ [y
k−1
,z
k
] такое, что ϕ(˜ y
k
) ≤ ϕ(z) для всех z ∈ I
k
. Но
множество Q компактно по предположению, поэтому существует неогра-
ниченное подмножество K ⊂ K
1
такое, что подпоследовательности {z
k
}
K
,
{˜ y
k
}
K
, {y
k+1
}
K
сходятся к некоторым точкам ˆ z,
ˆ
˜ y,
ˆ
ˆ y соответственно. Тот
факт, что эти последовательности сходятся, обеспечивается тем, что по-
следовательность {y
k
}
K
сходится к ˆ y. В силу непрерывности отображения
ϕ
0
(·)искалярногопроизведениясправедливыследующиесоотношения:
(ϕ
0
(ˆ y),ˆ z)≤ (ϕ
0
(ˆ y),z) z∈Q, (1.19)
ϕ(
ˆ
˜ y)≤ϕ(z) z∈I
∗
≡ [ˆ y,ˆ z], (1.20)
Электронныйжурнал.  59Дифференциальные уравнения и процессы управления, N. 1, 2004
ˆ
˜ y∈I
∗
, (1.21)
ϕ(
ˆ
ˆ y)≤ϕ(
ˆ
˜ y). (1.22)
Предположим теперь, что ϕ(
ˆ
ˆ y)≤ϕ(ˆ y)−δ для некоторого δ > 0. Тогда су-
ществуетlтакое,чтоϕ(y
k+1
)≤ϕ(y
k
)−δ/2длявсехk≥lвK,тоестьмо-
нотонно убывающая последовательность {ϕ(y
k
)} не ограничена снизу. Но
этоневозможно,посколькуϕ —непрерывноеотображение,аQкомпактно.
Отсюда следует, что не существует δ > 0 такое, что ϕ(
ˆ
ˆ y) ≤ ϕ(ˆ y)−δ, то
есть
ϕ(
ˆ
ˆ y)≥ϕ(ˆ y). (1.23)
Формулы (1.20)–(1.23) означают, что ϕ(
ˆ
ˆ y) = ϕ(ˆ y) = ϕ(
ˆ
˜ y) ≤ ϕ(z) для всех
z∈I
∗
.Всилужелеммы 4имеем
(ϕ
0
(ˆ y),ˆ z− ˆ y)≥ 0.
Но тогда из формулы (1.19) следует, что (ϕ
0
(ˆ y),z− ˆ y)≥ 0 для всех z ∈Q,
ипоэтому ˆ y —решениезадачи (1.16).
Теоремадоказана.
Отметим, что теорема 1.1 свидетельствует о том, что последователь-
ностьлокальныхнаσ
k
минимизаторовсходится,всилувыпуклости (псев-
довыпуклости) функции ϕ, к глобальному на Q минимизатору этой функ-
ции (см.лемму 2).
1.5. О приближенном решении вспомогательных задач
Симплексный алгоритм, описанный в пункте 1.2, требует на каждой
итерациирешениявспомогательнойзадачи —минимизациифункции ϕ(x)
на симплексе. Но точное решение этой задачи само может быть предель-
ной точкой итерационного процесса. Следовательно, симплексный метод
нуждаетсявмодификациишага 3.
Решениевспомогательныхзадачнашаге 3симплексногометодаможет
бытьсвязановобщемслучаесбольшимивычислительнымизатратами.В
частном же случае, используя конкретный вид функции ϕ(x) (например,
ϕ(x) =kxk), задачу (1.13) на шаге 3 можно решать приближенно, а имен-
но, можно решать задачу (1.14) лишь при p = q. Это же означает, что
вовсенеобязательнорешатьзадачу (1.13)доконца,аможноограничиться
определениемотделяющейопорнойгиперплоскости.Далеедоконцапункта
будемполагать ϕ(x) =kxk.
Электронныйжурнал.  60Дифференциальные уравнения и процессы управления, N. 1, 2004
Пусть
Y =L(P) = (z
0
,...,z
q
) —матрица,определяющаясимплекс;
M = Γ(P) = {x ∈ R
q−1
: x = Yω, e
∗
ω = 1} — аффинная оболочка P,
т.е. q-мерноемногообразие.Пусть z
0
=Yγ∈σ⊂M;
J(γ) ={j :γ
j
6= 0, j = 0,q};
S =P\{z
j
0
},где j
0
:γ
j
0 = 0,т.е. j
0
6∈J(γ);
τ = Δ(S) — (q−1)-мернаяграньсимплекса σ;
Z =L(S) —матрица,определяющаягрань τ.
Пусть p = q, ϕ(x) = kxk. В этом случае критическая точка x
0
= 0.
Поэтому для барицентрического представления x
0
необходимо решить си-
стему линейных алгебраических уравнений вида Yα = 0, e
∗
α = 1. Однако,
длявычисленияочереднойкрайнейточкидопустимогомножестваQможно
использоватьнеградиентфункцииϕ(x)вточкеминимума (найденногона
предыдущей итерации), а его некоторое приближение. В качестве такого
приближения можно взять, например, вектор нормали к гиперплоскости,
содержащей общую грань смежных симплексов. Напомним, что именно в
этой грани находится точка минимума, определенная на предыдущей ите-
рации. Пусть гиперплоскость описывается уравнением (x,w)−1 = 0. Так
как вершины грани лежат в этой плоскости, то для определения норма-
ли получаем систему алгебраических уравнений Z
∗
w−e = 0. Приведем
упрощенныйвариантприближенногосимплексногоалгоритма.
Алгоритм 1.3 (приближенныйсимплексныйалгоритм):
0.Задать ¯ z∈Q.Вычислить g
0
= ¯ z/k¯ zk.Найтикрайнююточку z
0
∈Q,
решив задачу (g
0
,x) → min
x∈Q
. Положить v
0
= z
0
, P
1
= {z
0
}, σ
1
= Δ(P
1
),
p = 1, β
0
= 1; β
i
= 0, i = 1,n; k = 1.
1.
a)если p<n,вычислить g
k
=v
k−1
/kv
k−1
k;
b) если p = n найти решение w
k−1
∈ R
n
сопряженной системы линей-
ныхалгебраическихуравнений:
Z
∗
k−1
w−e = 0.
Положить g
k
=w
k−1
/kw
k−1
k;
c)определитькрайнююточкуz
k
∈Q,решивзадачу(g
k
,x)→ min
x∈Q
.Если
p<n,положить p =p+1.
Электронныйжурнал.  61Дифференциальные уравнения и процессы управления, N. 1, 2004
2.Положитьδ
k
= (g
k
,z
k
−v
k−1
).Еслиδ
k
= 0,топроцесспрекращается;
впротивномслучаедополнитьбазис P
k
вектором z
k
,аименно:
P
k
=P
k
∪{z
k
},
Y
k
=L(P
k
),
q =|P
k
| (числоэлементов P
k
),
σ
k
= Δ(P
k
),
M
k
= Γ(P
k
).
Перейтикследующемушагу.
3. Найти критическую точку функции ϕ(x) на многообразии M
k
, т.е.
решитьсистемулинейныхалгебраическихуравненийотносительно α:
Y
k
α = 0, e
∗
α = 1.
Если α
i
> 0длявсех i = 0,q,то x
0
=Y
k
α∈ ri σ
k
.Вэтомслучае
a) если q < n, то положить v
k
= x
0
, β
i
= α
i
, i = 0,q, S
k
= P
k
, Z
k
=
L(S
k
), k =k+1,перейтикшагу 1;
b) если q = n, процесс прекращается, так как произошел ”захват”гло-
бальногоминимизаторасимплексом;еслижекакое-либо α
i
0 < 0,перейтик
следующемушагу.
4. Определить точку z
0
пересечения отрезка [x
0
,v
k−1
] с границей сим-
плекса σ
k
. Пусть z
0
= Y
k
γ и z
0
= x
0
+ λ(v
k−1
− x
0
), 0 ≤ λ < 1; γ
i
=
α
i
+ λ(β
i
− α
i
) ≥ 0, i = 0,q, причем для некоторого j
0
имеем γ
j
0 = 0;
λ = max
i∈J(γ)
α
i
α
i
−β
i
.
5.Удалитьизбазиса P
k
точку z
j
0
, j
0
6∈J(γ).
Положить S
k
= P
k
\{z
j
0
}, Z
k
= L(S
k
), P
k+1
= S
k
, σ
k+1
= τ
k
, v
k
= z
0
,
β =γ, k =k+1;перейтикшагу 1.
Сходимость последовательности {ϕ(v
k
)} значений функции к миниму-
му гарантируется теоремой 1.1, так как выполнены все необходимые для
нее условия. Основное требование теоремы строгого убывания значений
ϕ(v
k
) обеспечивается шагами 3 и 4 приведенного алгоритма (см. также
[12],лемма 2]).
Приведем еще одну версию приближенного симплексного алгоритма,
основанную на линейной интерполяции отображения z : R
n
→R
n
, а имен-
но z(g) = arg min
x∈Q
(g,x). В силу шага 1 c) алгоритма 1.3 z
k
= z(g
k
), k =
0,1,.... Поэтому, получив на шаге 4 алгоритма 1.3 коэффициенты разло-
Электронныйжурнал.  62Дифференциальные уравнения и процессы управления, N. 1, 2004
жения γ
i
, i ∈ J(γ), на шаге 1 b) можно не решать сопряженную систему,
аположитьw
k−1
=
P
i∈J(γ)
γ
i
g
i
.Остальныеоперацииалгоритма 1.3остаются
безизменений.
Электронныйжурнал.  63Дифференциальные уравнения и процессы управления, N. 1, 2004
1.6. Постановка задачи оптимального управления
Рассмотрим следующую задачу оптимального управления. На траек-
торияхуправляемойсистемы
˙ x =A(t)x+B(t)u, t∈T = [t
0
,t
1
], x(t
0
) =x
0
, u(t)∈U (1.24)
минимизироватьфункционал
F(u)≡ϕ(x(t
1
)). (1.25)
Здесь x — n-вектор фазового пространства V; u — s-вектор управления;
A(t), B(t) − n×n-и n×s-матрицысоответственно.
Будем считать, что матрицы A(t), B(t) определены при t ∈ T, ве-
щественны и непрерывны. Предположим, что функция ϕ(x) непрерывно
дифференцируема по x и псевдовыпукла на R
n
, U ⊂ R
s
— выпуклое ком-
пактноемножество.Предположим,чтосистема (1.24)полностьюуправля-
ема. Класс U допустимых управлений определим как множество кусочно-
непрерывных на T вектор-функций u(t) со значениями в U. Обозначим
через Qмножестводостижимостисистемы (1.24)вмомент t =t
1
.
Согласно [55] (стр. 178, теорема 1.1) Q — выпуклый компакт. Обозна-
чим через x(t,u) решение системы (1.24) при фиксированном допустимом
управлении u(t). Пусть u(t) — допустимое управление, удовлетворяющее
условиюмаксимума
(ψ(t,u),A(t)x(t,u)+B(t)v)→ max
v∈U
, t∈T. (1.26)
Здесь ψ(t,u) —решениесопряженнойсистемы
˙
ψ =−A
∗
(t)ψ, ψ(t
1
) =−ϕ
0
(x(u,t
1
)). (1.27)
Заметим, что управление u(t) является оптимальным управлением в
задаче минимизации линейного функционала (g,x(t
1
,v))→ min
v∈U
на тра-
екториях линейной системы (1.24) при g =ϕ
0
(x(t
1
,u)) и при фиксирован-
номуправленииu(t).Отсюдаследует,чтоконецтраекторииx(t,u) (вектор
x(t
1
,u))являетсярешениемзадачиминимизации
(g,ξ−x(t
1
,u))→ min
ξ∈Q
.
Очевидно, что z = x(t
1
,u) — крайняя точка множества Q. В силу прин-
ципамаксимуманахождениеоптимальногорешения{ˆ u(t),ˆ x(t)}сводитсяк
Электронныйжурнал.  64Дифференциальные уравнения и процессы управления, N. 1, 2004
решению серии вспомогательных линейных задач оптимального управле-
ния (задачМайера)вида
(g,x(t
1
,u))→ min
u∈U
,
причем (1.27)принимаетвид
˙
ψ =−A
∗
(t)ψ, ψ(t
1
) =−g. (1.28)
Такимобразом,решениеисходнойзадачи (1.24), (1.25)сводится:
1) к решению задачи нелинейного программирования ϕ(x) → min
x∈Q
(к
нахождениювектора ˆ x∈Q),затем
2) к нахождению управления ˆ u(t), приводящего траекторию системы
(1.24)вточку ˆ x,т.е. x(t
1
,ˆ u) = ˆ x.
1.7. Симплексный алгоритм решения задачи оптимального
управления
В этом пункте будет дано формальное обоснование симплексного ал-
горитма для решения задачи (1.24), (1.25). Подробное его описание для
решения задачи нелинейного программирования, эквивалентной исходной
задаче,приведеновпункте1.2.
Рассмотрим задачу минимизации выпуклого функционала F(u) ≡
ϕ(x(t
1
,u)), u ∈ U, на множестве конечных состояний системы (1.24). В
сокращеннойформеэтузадачуможнопредставитьввиде
ϕ(x)→ min
x∈Q
, (1.29)
где ϕ(x) — выпуклая и непрерывно дифференцируемая функция, Q — вы-
пуклоекомпактноемножество.
Введемфункцию
H(ψ,x,v,t) = (ψ,A(t)x+B(t)v), t∈T, v∈U.
Определимэкстремальноеуправлениеспомощьюсоотношения
(ψ(t,u),A(t)x(t,u)+B(t)¯ u(t))=max
v∈U
(ψ(t,u),A(t)x(t,u)+B(t)v), t∈T,
где ψ(t,u) —решениесопряженнойсистемы:
˙
ψ =−A
∗
(t)ψ, ψ(t
1
,u) =−ϕ
0
(x(t
1
,u)).
Электронныйжурнал.  65Дифференциальные уравнения и процессы управления, N. 1, 2004
Или,иначе
(ψ(t,u),B(t)¯ u(t)) = max
v∈U
(ψ(t,u),B(t)v), t∈T. (1.30)
Заметим,чтоуправление ¯ u(t)одновременноявляетсяоптимальнымуправ-
лениемвзадачеминимизациилинейногофункционала
(ϕ
0
(x(t
1
,u)),x(t
1
,v))→ min
v∈U
натраекторияхлинейнойсистемы (1.24),гдеu(t) —фиксированноеуправ-
ление.
Однимизметодоврешениязадачи (1.29)являетсяметодусловногогра-
диента.Пустьнаk-йитерацииужепостроены:u
k
(t) —допустимоеуправ-
ление,x
k
(t) =x(t,u
k
), ¯ u
k
(t)—экстремальноеуправление(1.30).Идеямето-
дасостоитвтом,чтодляуменьшенияцелевогофункционалаиспользуется
решениезадачиодномернойминимизации:
ϕ(y
k
+Θ(z
k
−y
k
))→ min
Θ∈[0,1]
, (1.31)
где y
k
= x(t
1
,u
k
), z
k
= x(t
1
,¯ u
k
). Пусть
˜
Θ — решение задачи (1.31), y
k+1
=
y
k
+
˜
Θ(z
k
−y
k
).Тогдауправление,приводящеетраекториюсистемы (1.24)
вточку y
k+1
,имеетвид
u
k+1
(t) =u
k
(t)+
˜
Θ(¯ u
k
(t)−u
k
(t)).
Более эффективным методом для решения задачи (1.24) является сим-
плексный метод (метод выпуклых оболочек [96], [33], [41]). В работах [96],
[33], [41] симплексный метод рассматривается для квадратичной функции
ϕ(x)вида ϕ(x) =kx−x
0
k
2
,где x
0
—фиксированныйвектор.
Идея симплексного метода заключается в том, что для уменьшения
целевого функционала ϕ(x) используется решение задачи многопарамет-
рической минимизации — задачи минимизации целевой функции на сим-
плексе (выпуклой оболочке n+1 точек множества достижимости). Пусть
в результате вычислений на k-й итерации получены крайние точки мно-
жества достижимости z
0k
= x(t
1
,¯ u
0k
),...,z
nk
= x(t
1
,¯ u
nk
). Так как любая
точка выпуклого множества Q является выпуклой комбинацией не более
чемn+1крайнихточекизэтогомножества,вкачествепараметровможно
взять коэффициенты барицентрического представления точек этого мно-
жества. Поэтому введем вектор параметров α = (α
0
,...,α
q
)
∗
. Обозначим
Электронныйжурнал.  66Дифференциальные уравнения и процессы управления, N. 1, 2004
Y
k
= (z
0k
,...,z
nk
).Пусть
σ
k
=
(
z∈R
n
:z =Y
k
α, α
i
≥ 0, i = 0,q,
q
X
i=0
α
i
= 1
)
— q-мерный симплекс, σ
k
⊂ Q. Тогда уменьшение целевой функции ϕ(x)
намножестве Qможетбытьдостигнутоврезультатерешениязадачими-
нимизациивида
ϕ(z(˜ α)) = min
z∈σ
k
ϕ(z). (1.32)
Врезультатерешениязадачи (1.32)будетнайденаточкаy
k+1
=z(˜ α) =
Y
k
˜ α, а управление, приводящее траекторию системы (1.24) в точку y
k+1
будетиметьвид
u
k+1
(t) =
q
X
i=0
˜ α
i
¯ u
ik
(t).
Такимобразом,рассматриваемыйметодработаетвклассеэкстремальных
управлений,удовлетворяющихусловиюмаксимумафункцииПонтрягина.
Пусть
Δ
u
H(t) =H(ψ(t,u),x(t,u),¯ u(t),t)−H(ψ(t,u)x(t,u),u(t),t).
Всилу (1.25) Δ
u
H(t)≥∅, t∈T.Обозначим
δ(u) =
t
1
Z
t
0
Δ
u
H(t)dt.
Если δ(u) = 0, то Δ
u
H(t) = 0 почти для всех t ∈ T, то есть u(t) удовле-
творяет принципу максимума Понтрягина. Поэтому величину δ(u) можно
рассматривать как критерий выполнения (нарушения) необходимых усло-
вийоптимальности.
Обозначим: b u(t) — оптимальное управление; b x(t) = x(t,b u); ¯ x
k
(t) =
x(t,¯ u
k
); ψ
k
(t) =ψ(t,u
k
).Всилувыпуклости ϕ(x)имеем:
0≤F(u
k
)−F(b u)≡ϕ(x(t
1
,u
k
))−ϕ(x(t
1
,b u))≤
≤ (ϕ
0
(x(t
1
,u
k
)),x(t
1
,u
k
)−x(t
1
,b u))≤
≤ (ϕ
0
(x(t
1
,u
k
)),x(t
1
,u
k
)−x(t
1
,¯ u
k
))≡δ
k
.
Электронныйжурнал.  67Дифференциальные уравнения и процессы управления, N. 1, 2004
Однако, δ
k
можнозаписатьвинойформе:
δ
k
=
t
1
Z
t
0
[−(A
∗
ψ
k
,¯ x
k
−x
k
)+(ψ
k
,A(¯ x
k
−x
k
))+
+(ψ
k
,B(t)¯ u
k
−B(t)u
k
)]dt =
t
1
Z
t
0
(ψ
k
,B(t)¯ u
k
−B(t)u
k
)dt.
Из неравенств 0≤F(u
k
)−F(b u)≤δ
k
и из условия lim
k→∞
δ
k
= 0 следует, что
последовательность {u
k
(t)} минимизирующая. То, что δ
k
→ 0 при k →∞,
утверждаетсявтеоремепункта 1.4.Такимобразом,основываясьна (1.32),
можнопостроитьсимплексныйалгоритмдлярешениязадачиоптимально-
го управления (1.24), (1.25). Подробное описание алгоритма для решения
экстремальныхзадачдановпунктах 1.2и 1.3.Поэтомуостановимсяздесь
наспецификеалгоритмадлярешениязадачоптимальногоуправления.
Дляработыалгоритмавначалеопределяетсяприближение ¯ zконечного
состояния системы с помощью задания нулевого приближения управления
¯ u(t), t ∈ T, т.е. вычисляется ¯ z = x(t
1
,¯ u). После этого находятся крайние
точкиz
k
множествадостижимостиQкакрезультатдействияотображения
z : V
∗
→ V, т.е. z
k
= z(g
k
), g
k
∈ V
∗
. Здесь g
k
определяет краевое условие
ψ(t
1
) =−g
k
длясопряженнойсистемы.Этонаиболеетрудоемкийпообъему
вычислений шаг в алгоритме. Для задачи оптимального управления он
состоитизследующихдействий (определяющихотображение z(g)):
1) вычисление решения ψ(t) сопряженной системы (1.27) при g
k
=
ϕ
0
(y
k−1
), а именно ψ(t
1
) = −g
k
, и нахождение при этом экстремального
управления ¯ u
k
(t)изусловиямаксимума (1.26);
2) вычисление решения системы (1.24) при u = ¯ u
k
(t) и нахождение
крайней точки z
k
=z(g
k
)≡x(t
1
,¯ u
k
). На следующем шаге алгоритма нахо-
дится локальный относительно симплекса σ
k
минимизатор y
k
∈ σ
k
. Этот
поиск можно осуществить [12] с помощью нахождения критических точек
функционала ϕ(x)намногообразиях,содержащихгранисимплекса σ
k
.
Итак,пустьнанекоторой (k−1)-йитерацииполучены:y
k−1
,P
k
—аф-
финный базис, σ
k
= Δ(P
k
) — симплекс. Тогда на очередной k-й итерации
алгоритмавыполняютсяследующиеоперации.
1. Вычисляется g
k
= ϕ
0
(y
k−1
), крайняя точка z
k
∈ Q в результате ре-
шениязадачи (g
k
,x)→ min
x∈Q
.
Электронныйжурнал.  68Дифференциальные уравнения и процессы управления, N. 1, 2004
2.Если(g
k
,z
k
−y
k−1
) = 0,топроцесспрекращается;впротивномслучае
базис P
k
дополняетсявектором z
k
: P
k
=P
k
∪{z
k
}, σ
k
= Δ(P
k
).
3. Отыскивается решение y
k
задачи нелинейного программирования
ϕ(x)→ min
x∈σ
k
, принимая в качестве начальной точки y
k−1
; процесс повторя-
етсясп. 1.
1.8. Численные примеры
В этом пункте приводятся в качестве иллюстрации работы алгорит-
ма 1.1результатычисленныхрасчетовдвухтестовыхпримеров.Примеры
решались с точностью ε = 10
−4
(равенство нулю скалярного произведе-
ния проверялось с точностью до ε, см. шаг 2 алгоритма 1.1). За единицу
трудоемкости работы алгоритма 1.1 принимается ”итерация”, равная объ-
ему вычислений при интегрировании сопряженной и прямой системы, т.е.
объему вычислений, требуемых для получения очередного приближения
(очереднойкрайнейточкимножествадостижимости).
Обозначения:
k —номеритерации;
g
k
—краевоеусловиедлясопряженнойсистемы (см. (1.28));
z
k
≡x(¯ u
k
,t
1
) —крайняяточкамножествадостижимости;
μ(g
k
) = (g
k
,z
k
).
Пример 1.1.
˙ x
1
=x
2
,
˙ x
2
=x
3
,
˙ x
3
=u;
x(0) = (1,0,0)
∗
,
T = [0,3],
U = [−1,1],
F =ϕ(x) =
(x,x)
1+(x,x)
,
где (x,x) =x
2
1
+x
2
2
+x
2
3
.
Начальноеприближение u
0
(t)≡ 0, t∈T.
Результатысчета:
b
F = 0.006352,
ˆ g = (0.0816,−0.1191,0.0638)
∗
,
Электронныйжурнал.  69Дифференциальные уравнения и процессы управления, N. 1, 2004
ˆ x = (0.0413,−0.0603,0.0323)
∗
,
ˆ u(t) ={a
i
:t∈ (t
i−1
,t
i
], i = 1,7},
где
i 0 1 2 3 4 5 6 7
t
i
0.0 0.7561 0.7743 0.7863 2.2614 2.2988 2.3269 3.0
a
i
− −1.0 −0.7828 0.1396 1.0 0.0775 −0.1396 −1.0
Ходитерацийиллюстрируетсятаблицей 1.1.
Таблица 1.1
k g
k
z
k
μ(g
k
),ϕ(z
k
)
0.5 −3.5 −1.75
1 0 −4.5 0.371429
0 −3
0.466939 −1.29737 −0.451717
2 −0.323265 −0.97866 0.181074
−0.21551 0.753047
0.296572 1.57109 0.0315992
3 −0.48208 1.18975 0.0457256
0.278262 0.500291
0.233283 −1.36322 0.0105798
4 −0.29256 −1.35445 0.0158861
0.137586 −0.491784
0.148127 0.407119 −0.00267961
5 −0.19017 0.580816 0.0142739
0.0495741 0.957537
0.126143 0.118448 0.0173863
6 −0.178173 0.110583 0.0118349
0.0838308 0.264196
0.0975113 −0.698147 0.00840837
7 −0.155281 −1.10755 0.00894662
0.109809 −0.869661
Электронныйжурнал.  70Дифференциальные уравнения и процессы управления, N. 1, 2004
Продолжение Таблицы 1.1
0.0898542 0.21512 0.0135197
8 −0.139606 −0.0357704 0.0079771
0.0852702 −0.126697
0.0943983 −0.984196 0.0105886
9 −0.130487 −1.08686 0.00746415
0.0722009 −0.530831
0.0887548 −0.282145 0.013279
10 −0.12816 −0.378542 0.00706527
0.0699338 −0.145752
0.0843498 0.356225 0.0129797
11 −0.126153 0.219152 0.00661472
0.0680933 0.15536
0.084435 0.0142296 0.0127332
12 −0.121868 −0.0526816 0.00649501
0.0628975 0.0812663
0.0811125 0.0408247 0.01263
13 −0.12022 −0.0918303 0.00636339
0.0666701 −0.0258179
0.0811994 0.151056 0.012539
14 −0.119569 0.0433215 0.0063519
0.0638795 0.0853687
0.0816549 −0.0207134 0.0125487
15 −0.119104 −0.116907 0.0063519
0.0638224 0.00495144
Пример 1.2. (См. [106].)
˙ x
1
=x
2
+u,
˙ x
2
=−u,
˙ x
3
=x
1
;
x(0) = (0.5,0,0)
∗
,
Электронныйжурнал.  71Дифференциальные уравнения и процессы управления, N. 1, 2004
T = [0,1.5],
U = [−1,1],
F =ϕ(x) = (c,x)+(x
∗
Ax)
1
2
,
где c = (0,0,1)
∗
,
A =V
∗
V =
0.38 0.39 0.35
0.39 0.42 0.35
0.35 0.35 0.34
,
V =
0.2 0.1 0.3
0.3 0.4 0.3
0.5 0.5 0.4
.
Начальноеприближение:
u
0
(t)≡ 0, t∈T.
Результатысчета:
b
F = 1.226594;
b g = (0.6114, 0.6423, 1.5644)
∗
;
b x = (−0.0197, 0.7887, 0.4679)
∗
;
b u(t) ={a
i
:t∈ (t
i−1
,t
i
], i = 1,3},
где
i 0 1 2 3
t
i
0.0 0.3187 1.4631 1.5
a
i
− 1.0 −1.0 1.0
Ходитерацийиллюстрируетсятаблицей 1.2.
Электронныйжурнал.  72Дифференциальные уравнения и процессы управления, N. 1, 2004
Таблица 1.2
k g
k
z
k
μ(g
k
),ϕ(z
k
)
0.610845 −0.0626435 1.21233
1 0.617595 0.926013 1.22856
1.58047 0.429424
0.610208 −0.0197915 1.22638
2 0.644187 0.788765 1.22659
1.56084 0.467918
0.611419 −0.0251575 1.22657
3 0.642348 0.803247 1.22659
1.56445 0.464054
Электронныйжурнал.  73Дифференциальные уравнения и процессы управления, N. 1, 2004
2 Решение линейной задачи оптимального управле-
ния с терминальными ограничениями
Для линейной системы управления с терминальными ограничениями рас-
сматривается задача минимизации выпуклой функции конечного состоя-
ния. Задача оптимального управления редуцируется к задаче нелинейного
программирования — минимизировать выпуклую функцию на множестве
при дополнительных ограничениях. Используя метод модифицированной
функции Лагранжа, решение этой задачи сводится к решению последова-
тельности задач минимизации выпуклой функции на выпуклом компакт-
ном множестве. Для эффективного решения полученных вспомогательных
экстремальныхзадачпредлагаетсяиспользоватьсимплексныйалгоритм.
В данном разделе описывается способ построения финитных управле-
ний для линейных систем. Приводится конкретный вид управления для
случаялинейныхсистемсдетерминированнымивозмущениямиисистемс
терминальными ограничениями. Получаемые финитные управления явля-
ются линейными комбинациями управлений, переводящих за фиксирован-
ное время единичные орты R
n
в 0 для линейных нестационарных систем.
Такиефинитныеуправленияудобнывпрактическихприложениях,таккак
они могут быть вычислены до начала процесса управления. Это свойство
управленийявляетсявесьмаважнымприреализациибыстродействующих
процессов. В качестве иллюстрации приводятся расчеты тестовых приме-
ров.Данныйразделнаписаннаосноверабот [11], [13].
Созданиеэффективныхвычислительныхметодовтеорииоптимального
управления является одним из приоритетных направлений в теории опти-
мальных процессов. Эти методы разработаны и показали свою эффектив-
ность в задачах со свободным правым концом (см., например, [58], [66],
[26]). Для задач оптимального управления с краевыми условиями появля-
ютсядополнительныезатруднения.
Отметимосновныеподходыкчисленномурешениюзадачоптимально-
го управления для систем, описываемых обыкновенными дифференциаль-
нымиуравнениями:
1) методы последовательных приближений, основанные на процедурах
линеаризациииварьированияуправлений [58], [84], [76], [74];
2) методы штрафных функционалов или модифицированного функцио-
налаЛагранжа [58], [84], [38], [23];
Электронныйжурнал.  74Дифференциальные уравнения и процессы управления, N. 1, 2004
3) дискретизация задачи с последующим применением методов линей-
ногоинелинейногопрограммирования [84], [38].
Основная трудность при разработке методов первого типа состоит в
построении множеств варьирования управления. Рассматриваемый ниже
метод примыкает ко второй группе и использует идеи математического
программирования применительно к задачам оптимального управления.
При использовании методов выпуклого программирования решение исход-
ной задачи обычно определяется как предел минимизирующей последова-
тельности решений более простых (вспомогательных) экстремальных за-
дач. В данном разделе предлагается алгоритм, рассчитанный на исполь-
зование для решения вспомогательных задач быстросходящегося метода
(симплексного алгоритма). Подробное описание симплексного алгоритма
приводитсявпунктах 1.2и 1.3раздела 1длярешениязадачинелинейного
программирования, а в пунктах 1.6 и 1.7 раздела 1 — для решения задач
оптимальногоуправлениясосвободнымправымконцом.
2.1. Постановка задачи
Рассмотримуправляемуюсистему
˙ x =A(t)x+B(t)u, t∈T = [t
0
,t
1
], x(t
0
) =x
0
, u(t)∈U. (2.1)
Здесь x — фазовый n-вектор; u — s-вектор управления; U — выпуклое
компактное множество, A(t), B(t) — n×n- и n×s- матрицы соответ-
ственно. Будем считать, что матрицы A(t), B(t) определены при t ∈ T,
вещественныинепрерывны.
Предположим,чтосистема (2.1)полностьюуправляема.Класс Uдопу-
стимых управлений определим как множество кусочно-непрерывных на T
вектор-функцийu(t)созначениямиb∈U.Обозначимчерезx(t,u)решение
системы (2.1)прификсированномдопустимомуправлении u(t).
Задача. Минимизировать функционал
F
0
(u)≡ϕ
0
(x(t
1
,u)), u∈U, (2.2)
на траекториях системы (2.1) при дополнительном условии
x(t
1
,u)∈R ={x :Cx+d = 0}, (2.3)
где r(x) =Cx+d∈R
m
— заданная вектор-функция терминального огра-
ничения.
Электронныйжурнал.  75Дифференциальные уравнения и процессы управления, N. 1, 2004
Предположим, что функция ϕ
0
(x) выпуклая и непрерывно дифферен-
цируемая, а для ограничений (2.3) выполняются условия регулярности:
компонентывектор-функции r(x)имеютлинейно-независимыеградиенты.
Обозначим через Q множество достижимости системы (2.1) в момент
t = t
1
: Q = {x(t
1
,u) : u ∈ U}. Как известно, при сделанных предположе-
ниях Q — выпуклый компакт. Перепишем исходную задачу (2.1)–(2.3) в
сокращеннойформе:
ϕ
0
(x)→ min, Cx+d = 0, x∈Q, (2.4)
и сделаем дополнительные предположения, связанные с корректным пере-
ходом к двойственной задаче. Каждому вектору z = (z
1
,...,z
m
)
∗
сопоста-
виммножество R(z) ={x :Cx+d =z}ипредположим,что:
1) int Q∩R(z)6= O
 
;
2) Q∩R(z)6= O
 
внекоторойокрестноститочки z
0
= 0.
Искомоерешениеb xзадачи (2.4)можетбытьопределенокакпределпо-
следовательности минимумов модифицированной функции Лагранжа [58],
то есть решение исходной задачи (2.1)–(2.3) может быть определено как
предел минимизирующей последовательности решений задач оптимально-
го управления со свободным правым концом. Применение метода модифи-
цированной функции Лагранжа приводит к необходимости решать задачи
минимизациивыпуклойфункциинавыпукломкомпактноммножестве.Для
этой цели в данной работе предлагается использовать симплексный алго-
ритм.
Основу симплексного алгоритма для решения задач оптимального
управления составляют: свойство суперпозиции линейных систем; сим-
плексность; замещения; сходимость последовательности локальных мини-
мумов вспомогательных задач к глобальному. В результате работы сим-
плексного алгоритма оптимальное решение b x задачи (2.4) получается в
видевыпуклойкомбинацииточеквыпуклогокомпактногомножества (мно-
жества достижимости). Оптимальное управление, приводящее систему в
эту точку, в силу линейности системы (2.1), также получается в виде ли-
нейной комбинации некоторых вспомогательных (полученных на преды-
дущих итерациях вычислительного процесса) управлений. Поэтому, если
оптимальное управление содержит участки особого управления, то такие
участки в приближенном кусочно-постоянном управлении получаются ав-
томатически, что является достоинством предлагаемого подхода. Прибли-
женный симплексный алгоритм, приведенный в пункте 1.4, в сочетании с
Электронныйжурнал.  76Дифференциальные уравнения и процессы управления, N. 1, 2004
теоремой об отделимости выпуклых множеств в конечномерном простран-
стве может служить основой создания алгоритмов для решения многих
задачоптимальногоуправления (втомчислеисподвижнымиконцами).
2.2. Модифицированная функция Лагранжа
Рассмотримвкачествеисходнойзадачу
ϕ
0
(x)→ min, Cx+d = 0, x∈Q. (2.5)
Введем функцию Лагранжа L(x,λ) = ϕ
0
(x) + (λ,Cx +d) на Q×R
m
.
Известно (см., например, [10, стр. 111]), что если функция Лагранжа L,
соответствующая задаче (2.5), имеет на Q× R
m
седловую точку (ˆ x,
ˆ
λ),
то ˆ x является решением задачи (2.5). Однако, алгоритм, осуществля-
ющий непосредственный поиск седловой точки функции Лагранжа схо-
дится весьма медленно. Это объясняется тем, что радиус кривизны по-
верхности {ϕ
0
(x(λ)), r(x(λ))} может оказаться слишком большим. Здесь
x(λ) = arg min
x∈Q
L(x,λ) — точка множества Q, в которой заданная функ-
ция L достигает своего минимума на Q, а множители Лагранжа λ задают
параметризациюэтойповерхности.
Определим
L
1
(λ) = inf
x∈Q
L(x,λ) и
L
2
(x) = sup
λ∈R
m
L(x,λ).
Очевидно,что L
1
(λ)≤L
2
(x)привсех x∈Q, λ∈R
m
.
Лемма 2.1 ([35], стр. 112). Точка (ˆ x,
ˆ
λ)∈Q×R
m
является седловой
для функции L тогда и только тогда, когда L
1
(
ˆ
λ) =L
2
(ˆ x).
ВведемврассмотрениемодифицированнуюфункциюЛагранжа
M(x,λ,α)=ϕ
0
(x)+(λ,Cx+d)+
α
2
kCx+dk
2
на Q×R
m
(α∈R
1
, α> 0 − коэффициентштрафа).
Задача
M(x,λ,α)→ min
x∈Q
(2.6)
неэквивалентна (2.5),ноаппроксимируетеестембольшейточностью,чем
больше α. Коэффициент штрафа α в отличие от метода штрафов уже не
Электронныйжурнал.  77Дифференциальные уравнения и процессы управления, N. 1, 2004
обязательнодолженбытьдостаточновелик.Слагаемое αkr(x)k
2
имеетце-
льюлишьобеспечитьвыпуклостьупомянутойповерхностиснеоченьболь-
шимрадиусомкривизны.
Аналогично тому, как это делается с обычной функцией Лагранжа,
определим
M
1
(λ,α) = inf
x∈Q
M(x,λ,α), (2.7)
атакже
M
2
(x,α) = sup
λ∈R
m
M(x,λ,α).
Используя модифицированную функцию Лагранжа M, тогда можно запи-
сать
M
2
(x,α)→ min
x∈Q
ивкачестведвойственной —рассмотретьзадачу
M
1
(λ,α)→ max
λ∈R
m
. (2.8)
Приэтомимеетместонеравенство [10,стр. 116]
sup
λ∈R
m
M
1
(λ,α)≤ inf
x∈Q
M
2
(x,α).
Известно достаточно большое количество алгоритмов (см., например,
[38], [35]), базирующихся на решении двойственной задачи (2.8). Предло-
женные алгоритмы отличаются друг от друга способом решения вспомо-
гательной задачи минимизации (2.7), а также способом пересчета двой-
ственныхпеременныхλипараметраα.Алгоритмданногоразделавоснове
содержиталгоритм [72],ноотличаетсяотнегоиотостальныхалгоритмов
тем,чтодлярешениявспомогательнойзадачи(2.7)используетсясимплекс-
ныйалгоритм [12].Подробноеописаниеегоприводитсявразделе 1.
Отметим, что ради устойчивости вычислительного процесса в ал-
горитме используется масштабирование β =
1
α
, а вместо функции
M(x,λ,α) —функция
˜
M(x,λ,β) =βM(x,λ,α), β =
1
α
.
Очевидно, что функции
˜
M(x,λ,β) и M(x,λ,α) имеют одни и те же седло-
выеточки.Приведемалгоритмотысканияседловойточкимодифицирован-
нойфункцииЛагранжа
˜
M(x,λ,β).
Электронныйжурнал.  78Дифференциальные уравнения и процессы управления, N. 1, 2004
Пусть заданы константы (определяемые опытным путем) c
1
, η;
γ ∈ (0,1), δ ∈ (0,1) и известны на (l +1)-м шаге итерационного процесса
x
l
,λ
l
,β
l
.Определимрешение x
l+1
задачи
M(x,λ
l
,β
l
)→ min
x∈Q
. (2.9)
Для отыскания решения x
l+1
задачи (2.9) используем симплексный алго-
ритм.Обозначимчерезi
l
числоитерацийсимплексногоалгоритма,необхо-
димыхдляопределенияx
l+1
.Этавеличинаиспользуетсявкачествехарак-
теристики трудоемкости решения вспомогательной задачи (2.9) симплекс-
нымалгоритмом.
Полагаем
λ
l+1
=





λ
l
+β
l
r(x
l+1
), i
l
>η,
λ
l
+β
l
r(x
l+1
), i
l
≤η, и kr(x
l+1
)k
2
≤γkr(x
l
)k
2
,
λ
l
, i
l
≤η, и kr(x
l+1
)k
2
>γkr(x
l
)k
2
.
(2.10)
Определяем
β
l+1
=
(
δβ
l
, i
l
≤η,
β
l
, .
(2.11)
Для полученных значений λ
l+1
, β
l+1
вновь решается задача (2.9). Таким
образомобщаясхемаалгоритмаимеетследующийвид:
1.Задать x
0
, λ
0
, β
0
, ε
0
.Положить l = 0.
2.Определитьрешение x
l+1
задачи (2.9)симплекснымалгоритмом.
3.Еслиkr(x
l
)k≤ε
0
,вычисленияпрекращаются.Еслиβ
l
≤c
1
,вычисле-
нияпрекращаются,таккаксистемаограниченийнесовместна.
4.Вычислить λ
l+1
поформуле (2.10).
5.Вычислить β
l+1
поформуле (2.11).
6.Положить l =l+1иперейтикпункту 2.
Заметим,чтоприпоискерешениядвойственнойзадачи (2.8)необходи-
мо вычислять значения функции (2.7). Однако такое вычисление само по
себетребуетрешенияэкстремальнойзадачи (2.9).Дляеерешенияпредла-
гаетсяиспользоватьсимплексныйалгоритм.
2.3. Метод параметризации целевой функции
В предыдущем пункте исходная задача оптимального управления
F
0
(u) → min
u∈U
при дополнительном условии x(t
1
,u) ∈ R или в иной форме
Электронныйжурнал.  79Дифференциальные уравнения и процессы управления, N. 1, 2004
ϕ
0
(x) → min
x∈Q∩R
редуцировалась к серии задач без дополнительных огра-
ничений ϕ(x(t
1
,u)) ≡ M(x(t
1
,u)λ,α) → min
u∈U
при фиксированных λ,α или
ϕ(x) ≡ M(x,λ,α) → min
x∈Q
при фиксированных λ,α. В данном пункте рас-
сматриваетсясведениеисходнойзадачикдругойсериизадачбездополни-
тельныхограничений.Введемфункцию
N(x,τ) = [ϕ
0
(x)−τ]
2
+kCx+dk
2
. (2.12)
Пустьпрификсированном τ(τ ≤ϕ(ˆ x))решается τ-задача:
ϕ(x)≡N(x,τ)→ min
x∈Q
. (2.13)
Очевидно, что при ˆ τ = ϕ(ˆ x) имеем N(ˆ x(ˆ τ)) = 0. Пусть x(τ) — решение
задачи (2.13)прификсированном τ.
Лемма 2.2 ([38], стр. 185). Пусть τ
1
< τ
2
и x(τ
1
), x(τ
2
) — решения
τ-задачи. Тогда ϕ
0
(x(τ
1
))≤ϕ
0
(x(τ
2
)).
Из леммы следует, что значения целевой функции ϕ
0
(x(τ)) является
монотонно возрастающей функцией переменной τ. Предположим, что из-
вестна некоторая нижняя оценка τ
0
оптимального значения ϕ
0
(x(τ)), т.е.
τ
0
≤ ϕ
0
(ˆ x). Такую оценку можно получить, например, численно решив
вспомогательнуюзадачу
ϕ
0
(x)→ min
x∈Q
(2.14)
илиF
0
(u)→ min
u∈U
.Методпараметризациицелевойфункциисостоитвпосле-
довательномнахожденииточекx(τ
k
)иувеличениипараметраτ
k
такимоб-
разом,чтостремитсякϕ
0
(ˆ x).Ключевыммоментомметодаявляетсяспособ
измененияпараметра τ отитерациикитерации.МорисономД.предложен
следующийвариант.
Пусть на k-й итерации известно некоторое значение параметра τ
k
≤
ϕ
0
(ˆ x).Изрешениявспомогательнойзадачи (2.13)найдемточкуx(τ
k
).Если
N(x(τ
k
),τ
k
) = 0,торасчетызаканчиваются.Впротивномслучаеположим
τ
k+1
=τ
k
+
p
N(x(τ
k
),τ
k
), (2.15)
и итеративный процесс продолжается. Доказательство сходимости итера-
тивногопроцессаприводитсяв [38].
Отметим, что в методе параметризации целевой функции величина
ρ =
1
2[ϕ
0
(x)−τ]
является коэффициентом штрафа. Метод параметризации по-
этому, по существу, отличается от метода внешних штрафных функций
Электронныйжурнал.  80Дифференциальные уравнения и процессы управления, N. 1, 2004
толькотем,чтовнемавтоматическиопределенаполитикаизменениявспо-
могательного параметра τ, в то время как в методе внешних штрафных
функций пользователь должен специально определять правило изменения
ρ.
Понятно, что эффективность метода в целом связана с возможностью
”быстрого”решенияτ-задачи (2.13).Всвязисэтим,длярешениявспомога-
тельныхзадач (2.13), (2.14)предлагаетсяиспользоватьсимплексныйалго-
ритм,описанныйвразделе 1.
2.4. Построение финитных управлений для линейных систем без
ограничений
Рассмотрим сначала построение управлений в линейных управляемых
системах в простейшем случае. Пусть задана система линейных обыкно-
венныхдифференциальныхуравненийвида:
˙ x =A(t)x+B(t)u+f(t), t∈ [t
0
,t
1
], (2.16)
где x — фазовый n-вектор; u — s-вектор управления, A(t), B(t) — n×n-
и n×s-матрицы соответственно. Будем считать, что матрицы A(t), B(t)
ивектор f(t)определеныпри t∈ [t
0
,t
1
],вещественныинепрерывны.
Пусть заданы вектора x
0
, x
1
— начальное и конечное состояние систе-
мы (2.16). Предполагается, что матрицы A(t) и B(t) образуют полностью
управляемую пару {A(t),B(t)}. Допустимыми управлениями будем счи-
татькусочно-непрерывныефункциивида
u(t) =N(t)λ, (2.17)
гдеλ∈R
n
—постоянныйвектор,N(t) —s×n-кусочно-непрерывнаяогра-
ниченнаяна [t
0
,t
1
]матрица.
Пустьx(t)—решениесистемы(2.16)приуправлении(2.17).Требуется
найти вектор-функцию u = u(t), чтобы решение системы (2.16), начинаю-
щеесяпри t =t
0
вточке x(t
0
) =x
0
,попадалопри t =t
1
вточку x(t
1
) =x
1
.
Задачанахожденияоптимальногоуправления,переводящеголинейную
систему в некоторое конечное состояние, исследована достаточно полно.
Однако, численная реализация предложенных алгоритмов решения этих
задач сопряжена в силу их итерационности со значительными затратами
машинного времени. Это является одним из препятствий применения та-
кихалгоритмовдлябыстропротекающихпроцессов.Предлагаемыйспособ
Электронныйжурнал.  81Дифференциальные уравнения и процессы управления, N. 1, 2004
построения финитных управлений позволяет преодолеть, в некоторой сте-
пени, эту трудность. Задачу нахождения управлений вида (2.17) условно
можноразбитьнадве:нахождениематрицыN(t),затемвектораλ.Столб-
цами матрицы N(t) являются управления, переводящие за время t
1
−t
0
единичные орты R
n
в начало координат. Такие управления могут быть
вычислены до начала процесса управления. Параметр же λ вычисляется
достаточнопросто.
Непрерывные управления вида (2.17) были введены в 1960 году
Р. Калманом [42] при рассмотрении достаточных условий управляемости
линейной системы, а также для задачи минимизации энергии управления
(см.,например, [6]).
Кусочно-непрерывныеуправлениявида (2.17)былиполученывработе
[2] при рассмотрении задачи оптимального быстродействия в результате
решениятрансцендентныхуравнений.Приограниченииуправлений (2.17)
по амплитуде в [3] описывается многогранная область начальных условий
для системы управления, из которой возможен перевод системы в нача-
ло координат за фиксированное время. Кусками поверхности этого много-
гранника являются (n− 1)-симплексы, вершины которых лежат на осях
координат. Здесь приводится простая и общая схема получения финитных
управлений.
Предлагаемыйспособпостроенияфинитногоуправлениябазируетсяна
свойстве суперпозиции линейных систем. Возьмем в качестве j-го столбца
матрицы N(t)управление v
j
(t), j = 1,n,переводящеелинейнуюсистему
˙ y =A(t)y+B(t)v
j
, y(t
0
) =e (2.18)
завремя T =t
1
−t
0
източки e
j
в 0
N
j
(t)≡N(t)e
j
=v
j
(t), j = 1,n.
Здесь e
j
— единичный орт, N
j
(t) — j-й столбец матрицы N(t). Так как
{A(t),B(t)} полностью управляемая пара, то такие кусочно-непрерывные
управлениясуществуют [42], [44].
Пусть Φ(t) —фундаментальнаяматрицарешенийсистемы
˙ y =A(t)y,
причем Φ(t
0
) =E — единичная матрица. В силу указанного выше выбора
Электронныйжурнал.  82Дифференциальные уравнения и процессы управления, N. 1, 2004
матрицы N(t)имеетместосоотношение:
Φ(t
1
)e
j
+
t
1
Z
t
0
Φ(t
1
)Φ
−1
(t)B(t)N
j
(t)dt = 0,
отсюда
e
j
+
t
1
Z
t
0
Φ
−1
(t)B(t)N
j
(t)dt = 0
иливматричнойформе:
E +
t
1
Z
t
0
Φ
−1
(t)B(t)N(t)dt = 0. (2.19)
Отметим,чтоматрицаN(t)определяетсяуказаннымспособомнеоднознач-
но. Эта неоднозначность может быть устранена дополнительными требо-
ваниями
F(N
j
)→ min,
где F —некоторыйфункционал.
Определимтеперьпараметрλдляуправления(2.17).Подставимуправ-
ление (2.17) в систему (2.16), запишем ее решение в форме Коши, при
t =t
1
,положив
y
1
=
t
1
Z
t
0
Φ(t
1
)Φ
−1
(t)f(t)dt = 0.
Врезультатеполучим:
x
1
= Φ(t
1
)x
0
+Φ(t
1
)
t
1
Z
t
0
Φ
−1
(t)B(t)N(t)dtλ+y
1
.
Новсилусоотношения (2.19)
t
1
Z
t
0
Φ
−1
(t)B(t)N(t)dt =−E,
поэтому
x
1
−y
1
= Φ(t
1
)(x
0
−λ)
Электронныйжурнал.  83Дифференциальные уравнения и процессы управления, N. 1, 2004
отсюда
λ =x
0
−Φ
−1
(t
1
)(x
1
−y
1
).
Такимобразом,справедливаследующая
Теорема 2.1. Пусть система (2.16) полностью управляема. Тогда
финитное управление, переводящее систему (2.16) из точки x
0
в точку
x
1
за фиксированное время t
1
−t
0
, имеет вид:
u(t) =N(t)(x
0
+Φ
−1
(t
1
)(y
1
−x
1
)),
y
1
=
t
1
Z
t
0
Φ(t
1
)Φ
−1
(t)f(t)dt = 0,
(2.20)
причем j-м столбцом матрицы N(t) является управление, переводящее
систему (2.18) за время t
1
−t
0
из точки e
j
в начало координат (здесь e
j
— j-й единичный орт).
Приведемконкретныйвидфинитныхуправлений (2.20)дляслучая,ко-
гдаматрицаN(t)удовлетворяетнекоторымдополнительнымтребованиям.
Пусть качество управления вспомогательной системы (2.18) оценива-
етсяфункционалом:
F(v) =
t
1
Z
t
0
f
0
(v(τ))dτ.
Задача состоит в нахождении управлений ˆ v
j
(t), которые переводят систе-
му (2.18) из состояния y(t
0
) = e
j
в состояние y(t
1
) = 0 и минимизируют
критерийкачества:
F(ˆ v
j
) = minF(v
j
), j = 1,n.
Положим
H(ψ,y,v) = (Ay(t)+Bv(t),ψ(t)−f
0
(v(t)),
где ψ(t) —удовлетворяетдифференциальномууравнению
˙
ψ =−A
∗
(t)ψ. (2.21)
Пусть ˆ v(t) — оптимальное управление, а ˆ y(t) — соответствую-
щая оптимальная траектория. Тогда согласно принципу максимума
Л.С.Понтрягина [68] найдется непрерывная вектор-функция
ˆ
ψ(t) 6≡ 0, яв-
ляющаяся решением уравнения (2.21) и такая, что выполняется условие
максимума
H(
ˆ
ψ(t),ˆ y(t),ˆ v(t)) = (A(t)ˆ y(t),
ˆ
ψ(t))+max
v
[(B(t)v,
ˆ
ψ(t))−f
0
(v)]. (2.22)
Электронныйжурнал.  84Дифференциальные уравнения и процессы управления, N. 1, 2004
1. Предположим, что столбцы матрицы N(t) должны удовлетворять
требованиям:
1
2
t
1
Z
t
0
N
j∗
(t)N
j
(t)dt→ min, j = 1,n. (2.23)
Это означает, что необходимо построить оптимальное управление для си-
стемы (2.18), переводящее ее из точки y = e
j
в точку y = 0, за время
T =t
1
−t
0
идоставляющеефункционалу
F(v
j
) =
1
2
t
1
Z
t
0
v
j∗
(t)v
j
(t)dt (2.23
0
)
наименьшее возможное значение. В силу условия максимума (2.22) опти-
мальноеуправление ˆ v
j
имеетвид:
ˆ v
j
(t) =B
∗
(t)ψ
j
(t), (2.24)
где ψ
j
(t) — решение сопряженной системы (2.21) с некоторым начальным
условием ψ(t
0
) = c
j
, подлежащим определению, ψ
j
(t) = Φ
−1∗
(t)c
j
. Пусть
R(t) = Φ
−1
(t)B(t).Тогдаоптимальноеуправлениезапишетсяввиде:
ˆ v
j
(t) =R
∗
(t)c
j
. (2.25)
Подставим управление (2.25) в систему (2.18). Так как это управление
переводитсистемуизточки e
j
в 0завремя t
1
−t
0
имеем:
Φ(t
1
)e
j
=
t
1
Z
t
0
Φ(t
1
)R(t)R
∗
(t)c
j
dt = 0.
Отсюда,обозначив
D(T) =
t
1
Z
t
0
R(t)R
∗
(t)dt,
получим
c
j
=−D(T)e
j
.
Такимобразом,оптимальноеуправление (2.24)приметвид:
ˆ v
j
(t) =−R
∗
(t)D
−1
(T)e
j
.
Электронныйжурнал.  85Дифференциальные уравнения и процессы управления, N. 1, 2004
Но так как по построению ˆ v
j
является j-м столбцом матрицы
ˆ
N(t), полу-
чим
ˆ
N(t) =−R
∗
(t)D
−1
(T),
асоответствующеефинитноеуправление (2.20)имеетвид:
u(t) =−R
∗
(t)D
−1
(T)[x
0
+Φ
−1
(t
1
)(y
1
−x
1
)]. (2.26)
Отметим, что финитное управление (2.26) является оптимальным управ-
лениемдлясистемы (2.16),переводящимееизточкиx
0
вточкуx
1
имини-
мизирующеефункционал
F(u) =
1
2
t
1
Z
t
0
u
∗
(t)u(t)dt.
Однако, это свойство теряется (как видно из последующих пунктов 2–4),
еслинауправление v
j
вспомогательнойсистемы (2.18)наложеныдополни-
тельныеограниченияпоамплитуде.
2. Пусть столбцы матрицы N(t) удовлетворяют требованию (2.23),
причем
|N
j
i
(t)|≤l
j
i
, i = 1,s; j = 1,n, (2.27)
где l
j
i
— константы. В этом случае необходимо найти удовлетворяющее
ограничению (2.27)управлениедлясистемы (2.18),переводящееееизточ-
ки y =e
j
в y = 0, за время t
1
−t
0
и доставляющее минимум функционалу
(2.23’).Всилу (2.22)оптимальноеуправлениевданномслучаеимеетвид:
ˆ v
j
(t) =ϕ(B
∗
(t)ψ
j
(t),l
j
), j = 1,n, ϕ∈R
s
для почти всех t∈ [t
0
,t
1
]. Здесь функция ϕ: R
s
×R
s
→ R
s
означает следу-
ющее:
ϕ
i
(z,l) =
(
z
i
, z
i
∈ (−l
i
,l
i
);
l
i
sign(z
i
) ,
l
i
> 0, i = 1,s, z,l∈R
s
.
Вданномслучаеначальноеусловиесопряженнойсистемы (2.21)ψ(t
0
) =c
j
,
j = 1,n, может быть найдено по сравнению с предыдущим пунктом уже
алгоритмически [6].Тогдафинитноеуправление (2.20)имеетвид:
u(t) =
n
X
j=1
λ
j
ϕ(B
∗
(t)ψ
j
(t),l
j
) (2.28)
Электронныйжурнал.  86Дифференциальные уравнения и процессы управления, N. 1, 2004
дляпочтивсех t∈ [t
0
,t
1
],
λ =x
0
+Φ
−1
(t
1
)(y
1
−x
1
).
Приведенные в пунктах 1, 2 финитные управления (2.26) и (2.28) явля-
ютсянепрерывнымиограниченнымифункциями.Вследующихдвухпунк-
тах приводятся финитные управления, являющиеся кусочно-постоянными
функциями.
3. Предположим, что столбцы матрицы N(t) удовлетворяют требова-
ниям
t
1
Z
t
0
s
X
i=1
|N
j
i
(t)|dt→ min, j = 1,n,
а также выполняются ограничения (2.27). Поэтому управления ˆ ϕ
j
(t), ми-
нимизирующиефункционал
F(v
j
) =
t
1
Z
t
0
s
X
i=1
|v
j
1
(t)|dt, j = 1,n,
ипереводящиесистему (2.18)из y =e
j
в 0завремя t
1
−t
0
,имеютвид:
ˆ v
j
(t) =ϕ
0
(B
∗
(t)ψ
j
(t),l
j
), j = 1,n, ϕ
0
∈R
s
дляпочтивсех t∈ [t
0
,t
1
].Функция ϕ
0
: R
s
×R
s
→R
s
означаетследующее
ϕ
0i
(z,l) =
(
0, z
i
∈ (−1,1);
l
i
sign z
i
,
l
i
> 0, i = 1,s, z∈R
s
, l∈R
s
.
Вданномслучаеуправление (2.20)имеетвид:
u(t) =
n
X
j=1
λ
j
ϕ
0
(B
∗
(t)ψ
j
(t),l
j
)
дляпочтивсех t∈ [t
0
,t
1
],
λ =x
0
+Φ
−1
(t
1
)(y
1
−x
1
).
4.Предположим,чтостолбцыматрицыN(t)должныбыть ”минималь-
ныпоамплитуде”.Смыслэтихсловтаков:найдутсячислаμ
j
> 0,j = 1,n,
Электронныйжурнал.  87Дифференциальные уравнения и процессы управления, N. 1, 2004
прикоторыхзаданноевремяT =t
1
−t
0
являетсяоптимальнымпобыстро-
действию при переводе системы (2.18) управлениями вида ˆ v
j
(t) = μ
j
v
j
(t)
източкиy =e
j
в 0 (см.,например, [88], [41], [81]).Приэтомсчитается,что
управления v
j
(t)стесненыограничениямипоамплитудевида
|v
j
i
(t)|≤l
j
i
, i = 1,s; j = 1,n,
где l > 0 ∈ R
s
− const. Подобная задача является обратной в смысле
Н.Н.Красовского по отношению к задаче быстродействия с теми же огра-
ничениями.Оптимальныеуправления ˆ v(t)ичислаμ
j
могутбытьнайдены
алгоритмомиз [88], [41], [81].
ВсилупринципамаксимумаЛ.С.Понтрягинаоптимальноеуправление
ˆ v
j
(t)вданномслучаеимеетвид
ˆ v
j
(t) =μ
j
l
j
sign(B
∗
(t)ψ
j
(t)), j = 1,n.
Тогдафинитноеуправление (2.20)имеетвид:
u(t) =
n
X
j=1
λ
j
μ
j
l
j
sign(B
∗
(t)ψ
j
(t))
дляпочтивсех t∈ [t
0
,t
1
],
λ =x
0
+Φ
−1
(t
1
)(y
1
−x
1
).
Таким образом, для построения финитных управлений достаточно найти
управления до начала процесса регулирования, запомнить их точки пере-
ключения (если они существуют), а затем во время процесса управления
сформировать финитные управления. В следующем пункте рассмотрено
построениефинитныхуправленийдлялинейныхсистемсразличнымитер-
минальнымиограничениями.
2.5. Построение финитных управлений для линейных систем с
ограничениями
Рассмотрим теперь построение финитных управлений для линейных
системстерминальнымиограничениями.
1.Пустьзаданасистемалинейныхдифференциальныхуравненийвида
(2.16)сначальнымиусловиями x(t
0
) =x
0
.Рассмотриммножество
Q ={x :c
i∗
x−b
i
= 0, i = 1,m}. (2.29)
Электронныйжурнал.  88Дифференциальные уравнения и процессы управления, N. 1, 2004
Здесь c
i
— n-мерные вектора, а b
i
— вещественные константы. Требуется
построить управление u = u(t), переводящее систему (2.16) из точки x
0
в
точку x
1
множества Q,ближайшуюкначалукоординат.
Запишем (2.29)вматричнойформе
Q ={x :C
∗
x−b = 0}, (2.30)
где C = (c
1
,...,c
m
) — n×m-матрица, b−m-вектор. Пусть матрица C
∗
имеетрангr.Найдемнаилучшееприближенноерешение ˆ x (пометодунаи-
меньшихквадратов)системы:
C
∗
x−b = 0, (2.31)
тоесть
kC
∗
ˆ x−bk = min
x∈R
n
kC
∗
x−bk. (2.32)
Эторешениеопределяется [31]поформуле
ˆ x = (C
∗
)
+
b = (C
+
)
∗
b, (2.33)
где C
+
—псевдообратнаяматрицадляматрицы C.
Покажем, что вектор ˆ x имеет наименьшую длину по сравнению с дру-
гимивекторами,длякоторыхреализуетсяминимум(2.32).Действительно,
обозначим совокупность всех векторов C
∗
x, x ∈ R
n
, образующих r-мерное
подпространство пространства R
m
, через S
1
. Соотношение (2.32) означа-
ет, что C
∗
ˆ x представляет собой ортогональную проекцию вектора b на
подпространстве S
1
. В то же время совокупность всех векторов x ∈ R
n
,
удовлетворяющих условию C
∗
x = 0 образует подпространство R
2
в R
n
.
Это подпространство является ортогональным дополнением к r-мерному
подпространству R
1
из R
n
.
Пусть ¯ x(¯ x 6= ˆ x) — любой другой вектор из R
n
, для которого реализу-
етсяминимум (2.32).Тогда
C
∗
¯ x =C
∗
ˆ x.
Следовательно,
C
∗
(¯ x− ˆ x) = 0.
Тоесть
¯ x− ˆ x∈R
2
.
Нотаккак
ˆ x⊥ ¯ x− ˆ x ¯ x = ˆ x+(¯ x− ˆ x),
Электронныйжурнал.  89Дифференциальные уравнения и процессы управления, N. 1, 2004
топотеоремеПифагоранаходим:
k¯ xk
2
=kˆ xk
2
+k¯ x− ˆ xk
2
>kˆ xk
2
. (2.34)
Такимобразомвсилу(2.34)точкаx = ˆ xмножестваQявляетсяближайшей
кначалукоординат.
Теперьможнонайтифинитноеуправление,переводящеесистему (2.16)
из точки x
0
в точку множества Q, ближайшую к началу координат. Под-
ставляя в (2.20) вместо x
1
точку ˆ x, определяемую соотношением (2.33) по-
лучимискомоеуправление.Такимобразом,справедлива
Теорема 2.2. Пусть система (2.16) полностью управляема, а ее ре-
шения стесненыдополнительно линейными ограничениямиC
∗
x(t
1
)−b = 0.
Тогда финитное управление, переводящее систему (2.16) из точки x
0
в
ближайшую к началу координат точку ˆ x множества (2.30), имеет вид:
u(t) =N(t)[x
0
+Φ
−1
(t
1
)(y
1
− ˆ x)],
y
1
=
t
1
Z
t
0
Φ(t
1
)Φ
−1
(t)f(t)dt,
(2.35)
причем столбцами матрицы N(t) являются управления, переводящие си-
стему (2.18) за время t
1
−t
0
из точек e
j
в начало координат (здесь e
j
,
j = 1,n, — единичные орты).
Конкретный вид матрицы N(t) может быть определен также, как в
предыдущемпункте.
2.Пустьзаданауправляемаясистемавида (2.16)сначальнымиуслови-
ямиx(t
0
) =x
0
ипустьзадананекотораякриваяx =ξ(t),t∈ [t
0
,t
1
].Требу-
етсяпостроитьфинитноеуправление,доставляющеенаименьшеезначение
величине kx(t
1
)−ξ(t
1
)k при условиях c
i∗
x(t
1
)−b
i
= 0, i = 1,m, где c
i
—
n-мерные вектора, а b
i
— вещественные константы. Считаем, что точка
ξ =ξ(t
1
)непринадлежитмножеству Q.
Как и в предыдущем пункте найдем вначале точку ˆ x, в которую нуж-
но перевести систему (2.16). Ясно, что эта точка является ортогональной
проекцией точки ξ, на множество Q. Следовательно, нужно решить следу-
ющуюзадачу:минимизироватьфункцию
ρ(x) =kx−ξk (2.36)
приограничениях (2.30).Пусть
x =y+ξ. (2.37)
Электронныйжурнал.  90Дифференциальные уравнения и процессы управления, N. 1, 2004
Сделаемзаменупеременных(2.37)вформулах(2.36)и(2.31).Врезультате,
для нахождения проекции точки ξ на множество Q достаточно решить
относительно y (пометодунаименьшихквадратов)систему
C
∗
y+C
∗
ξ−b = 0. (2.38)
Решение ˆ y системы (2.38)имеетвид:
ˆ y =−(C
∗
)
+
(C
∗
ξ−b).
Используя свойства псевдообратной матрицы (D
∗
)
+
= (D
+
)
∗
, (DD
+
)
∗
=
DD
+
,получимокончательно:
ˆ y =−CC
+
ξ+C
+
b.
Осуществляяобратнуюзаменупеременных,получим
ˆ x =ξ−CC
+
ξ+(C
+
)
∗
b. (2.39)
Вданномслучаефинитноеуправлениеопределяетсятакже,какдлязадачи
пункта 1 по формуле (2.35) только с той разницей, что точка ˆ x находится
поформуле (2.39).
3.Рассмотримболееобщийслучай.Пустьзаданауправляемаясистема
(2.16) с начальными условиями x(t
0
) =x
0
. Требуется построить финитное
управление,доставляющеенаименьшеезначениевыпуклойдифференциру-
емойфункцииконечногосостояния g(x(t
1
))прилинейныхограничениях
C
∗
x(t
1
)−b = 0. (2.40)
Так как система (2.16) полностью управляема, то финитное управление
может переводить точку x
0
в любое конечное положение x
1
. Подставляя в
(2.20)вместоx
1
точку ˆ x,доставляющуюминимумфункцииg(x)намноже-
стве Q,найдемтребуемоефинитноеуправление.
Для нахождения оптимальной точки ˆ x может быть применен метод
проекции градиента. Идея метода состоит в следующем [43]. Для вычис-
ления очередного приближения к оптимальной точке направление s
k
=
x
k
−α
k
g
0
(x
k
), k = 0,1,2,..., проектируется на множество Q и в качестве
направленияспускаберется
ρ(s
k
)−x
k
.
Здесь g
0
(x
k
) — градиент функции g(x) в точке x
k
, α
k
> 0 — шаг спуска,
ρ(s
∗
) — проекция направления s
k
на множество Q. Так как ограничения
(2.40)линейны,методпроекцииградиентаможетбытьзаписанввиде:
x
k+1
= (E−CC
+
)(x
k
−α
k
g
0
(x
k
)), x
0
= (C
+
)
∗
b, k = 0,1,2,... . (2.41)
Электронныйжурнал.  91Дифференциальные уравнения и процессы управления, N. 1, 2004
Таким образом, финитное управление в данном случае определяется по
формуле (2.35), причем точка ˆ x является предельной точкой последова-
тельности (2.41).
2.6. Численные примеры
Приведемвкачествеиллюстрацииработысимплексногоалгоритмаре-
зультаты численных расчетов известных по литературе тестовых приме-
ров. Так как симплексный алгоритм ориентирован на линейную систему
управления,топриводимаянелинейнаясистема
˙
ξ =f(ξ)+Bu, ξ(t
0
) =x
0
, t∈T, u∈U,
традиционнымспособомлинеаризуетсяоколоопорнойтраектории:
˙ x
p
=A
p
(t)x
p
+Bu+c
p
(t),
x
p
(t
0
) =x
0
, t∈T, u∈U,
A
p
(t) =
∂f
∂ξ
(ξ
p−1
(t)),
c
p
(t) =f(ξ
p−1
(t))−
∂f
∂ξ
(ξ
p−1
(t))ξ
p−1
(t),
ξ
p
(t)≡ξ(t,u
∗p
(t)),
u
∗p
(t) — управление, доставляющее минимум функционалу
ϕ
0
(x
p
(t
1
)).
Предварительноисходнаязадача (еслинеобходимо)приводитсяквиду
(2.1)–(2.3).Критериямиокончанияпроцессалинеаризацииявляются
|ϕ
0
(ξ
p
(t
1
))−ϕ
0
(x
p
(t
1
))|<ε
0
1
, |ϕ
0
(ξ
p−1
(t
1
))−ϕ
0
(ξ
p
(t
1
))|<ε
0
2
,
гдеε
0
1
,ε
0
2
—заданныезаранеевеличины.Нижевпримерахполагалосьε
0
1
=
ε
0
2
= 0.002.Отметим,чтолинеаризацияоколоопорнойтраекториитребует
достаточнохорошегоначальногоприближениядлялинейныхсистем.
Обозначения:
p —номерлинеаризованнойзадачи;
l — номер вспомогательной задачи (2.9) метода модифицированной
функцииЛагранжаприрешении p-йлинеаризованнойзадачи;
l
p
—числозадач (2.9)прирешении p-йлинеаризованнойзадачи;
k —номеритерации;
g
k
—краевоеусловиедлясопряженнойсистемы;
Электронныйжурнал.  92Дифференциальные уравнения и процессы управления, N. 1, 2004
z
k
—крайняяточкамножествадостижимости;
y
k
—точкаминимуманасимплексе σ
k
;
ϕ(y
k
) —значениефункции ϕ(x)вточкеминимума y
k
;
μ(g
k
) —значениеопорнойфункции (g
k
,z
k
).
Пример 2.1 [76].
˙ x
1
=x
2
+u,
˙ x
2
=−u,
˙ x
3
=x
2
1
/2;
x(0) = (0.5,0,0)
∗
,
[t
0
,t
1
] = [0,1.5],
U = [−1,1];
F
0
(u) =x
3
(.(1.5)),
r
1
=x
1
, r
2
=x
2
(см. (2.2), (2.3)).
Возьмем в качестве минимизируемой функции ϕ
0
(x) =
1
2
(x,x), x =
(x
1
,x
2
,x
3
)
∗
.Начальноеприближение u
0
(t)≡ 0, t∈T.
ПриреализацииметодамодифицированнойфункцииЛагранжаисполь-
зовалисьследующиевеличины (см.формулы (2.10), (2.11)):
η = 3n, γ = 0.5, δ = 0.1, ε
0
= 10
−4
, c
1
= 10
−9
.
Результаты счета: p = 1, l
1
= 4, k = 15, b ϕ
0
= 0.044921; b g = (1.0×
10
−4
, 1.0·10
−4
, 3.0)
∗
, b x = (0.0, 0.0, 0.2997)
∗
, b u(·) = {a
i
: t ∈ (t
i−1
,t
i
], i =
1,3},где
i 0 1 2 3
t
i
0.0 0.5001 0.9997 1.5
a
i
− 1.0 −1.0·10
−4
−0.9996
Ходитерацийиллюстрируетсятаблицей 2.1.
В приведенном примере 1 отрезок [t
1
,t
2
] является участком особого
управления. Он был получен автоматически. Однако, это скорее ”счаст-
ливая”случайность, чем закономерный факт. Алгоритмы, использующие
построениепоследовательностикрайнихточек (построениепоследователь-
ностиэкстремальныхуправленийдлялинейныхзадачМайера),могутпло-
хо сходиться. Дело в том, что оптимальное управление в исходной задаче
Электронныйжурнал.  93Дифференциальные уравнения и процессы управления, N. 1, 2004
можетоказатьсяособым.Поэтомупривычислениикрайнихточек (экстре-
мальных управлений) необходимо учитывать [26] возможность появления
(обнаружения) особых участков управления. Если же этого не делать, ал-
горитм может попросту расходиться из-за неоднозначности определения
управления. Такая ситуация уже возникает в линейных задачах с терми-
нальнымиограничениями.
Электронныйжурнал.  94Дифференциальные уравнения и процессы управления, N. 1, 2004
Таблица 2.1
p,l,k g
k
z
k
y
k
μ(g
k
),ϕ(y
k
)
1 0.5 −0.1164 0.3779 −0.0415
1 0.0 0.68590000 0.1359 −0.0136000
1 0.1875 0.0891 0.168
1 0.2558 0.875 0.434 −0.1051
1 0.2718 −1.5 0.0454 −0.0099
2 0.168 0.4687 0.1827
1 0.368 −0.1094000 0.434 0.01860000
1 0.09090000 0.2506 0.0454 −0.0099
3 0.1827 0.1975 0.1827
1 0.5 −0.1249000 0.2296 −0.0597
2 0.0 0.5187 0.2245 0.04670000
4 0.0188 0.1461 0.1696
1 0.2026 0.875 0.1149 −0.1852
2 0.2469 −1.5 0.0346 0.0046
5 0.017 0.4626 0.222
1 0.07640000 0.069 0.0543 −0.0015
2 0.0381 −0.3808 0.00720000 0.0019
6 0.0222 0.3477 0.2442
1 0.0097 −0.0776 0.0543 0.0060
2 0.0079 0.0646 0.00720000 0.0019
7 0.0244 0.25520000 0.2442
1 0.50540000 −0.125 0.1947 −0.0625
3 7.0·10
−4
0.499 0.2437 0.04960000
8 0.0019 0.1816 0.18460000
1 0.1971 0.875 0.0998 −0.197
3 0.2469 −1.5 0.04960000 0.0067
9 0.00180000 0.4667 0.2457
Электронныйжурнал.  95Дифференциальные уравнения и процессы управления, N. 1, 2004
Продолжение Таблицы 2.1
1 0.1012 0.1222 6.00000000 −0.0117
3 0.05080000 −0.4944 2.0·10
−4
4.0·10
−4
10 0.0025 0.41400000 0.2977
1 0.0011 −0.084 6.00000000 9.00000000
3 9.00000000 0.09530000 2.0·10
−4
4.0·10
−4
11 0.0030 0.3004 0.2977
1 0.5006 −0.125 0.195 −0.0625
4 1.0·10
−4
0.4998 0.2439 0.0489
12 2.0·10
−4
0.17020000 0.1791
1 0.1953 0.875 0.1 −0.1954000
4 0.2442 −1.5 0.05 0.0063
13 2.0·10
−4
0.47940000 0.2398
1 0.10020000 0.12480000 0.0 −0.0124000
4 0.05010000 −0.4995 0.0 0.0
14 2.0·10
−4
0.4252 0.2977
1 1.0·10
−4
−0.0503000 0.0 1.0·10
−4
4 1.0·10
−4
−0.0465 0.0 0.0
15 3.00000000 0.3355 0.2977
Пример 2.2 [26].
˙ x
1
=x
2
,
˙ x
2
=−sin(x
1
)+u,
x(0) = (5,0)
∗
;
[t
0
,t
1
] = [0,5],
U = [−1,1].
Возьмем в качестве минимизируемой функции ϕ
0
(x) =
p
(x,x), x =
(x
1
,x
2
)
∗
.
Электронныйжурнал.  96Дифференциальные уравнения и процессы управления, N. 1, 2004
Начальноеприближение:
u
0
(t) =





1, t∈ [0,1.0],
−1, t∈ (1.0,4.5],
1, t∈ (4.5,5.0].
Результатысчета:
p = 1, k = 6, ϕ
∗
0
= 3.453019,b g = (0.9247, −0.3806)
∗
,b x = (3.1907, −1.3201)
∗
,
b u(·) ={a
i
: t∈ (t
i−1
,t
i
], i = 1,5}где:
i 0 1 2 3 4 5
t
i
0.0 0.9519 0.9698 4.5610 4.5845 5.0000
a
i
− 1.0000 −0.6079 −1.0000 0.6079 1.0000
Ходитерацийиллюстрируетсятаблицей 2.2:
Таблица 2.2
p,k g
k
z
k
y
k
μ(g
k
),ϕ(y
k
)
1 0.9305 3.16220000 3.16220000 3.4496
1 −0.3662 −1.3847 −1.3847 3.4521
1 0.916 3.2485 3.1783 3.44940000
2 −0.4011 −1.181 −1.3467 3.4518
1 0.92080000 3.21920000 3.186 3.451
3 −0.3901 −1.248 −1.3276000 3.45150000
1 0.9231 3.20530000 3.1897 3.4512
4 −0.3847000 −1.2805 −1.3182 3.45130000
1 0.9242 3.19860000 3.1915 3.4512
5 −0.3819 −1.2963 −1.3136 3.4512
1 0.92470000 3.19540000 3.1915 3.4512
6 −0.3806 −1.3039 −1.3136 3.4512
Электронныйжурнал.  97Дифференциальные уравнения и процессы управления, N. 1, 2004
3 Решение нелинейной задачи оптимального управ-
ления
Длярешениякраевойзадачи,возникающейврезультатепримененияприн-
ципа максимума Л.С. Понтрягина, предлагается алгоритм, являющийся
комбинацией метода неподвижной точки и квазиньютоновского метода.
Первый из них обладает широкой областью сходимости и применим для
достаточно широкого класса функций, а второй имеет локальную сверх-
линейнуюсходимость.Приводятсярезультатысчета.Результатыданного
разделаопубликованывработах [14], [15].
Известно,чтопринципмаксимумаЛ.С.Понтрягина [68]позволяетре-
шатьдостаточноширокийклассзадачтеорииоптимальныхпроцессов.Од-
нако,численнаяреализациятакогоподходаможетбытьзатрудненаотсут-
ствиемэффективногоспособанахожденияначальныхусловийдлярешения
сопряженной системы, с помощью которой формулируются необходимые
условияоптимальности.Отметимследующиедванаправлениядляпостро-
енияприближенныхметодоврешениязадачоптимальногоуправления:
1) одним из них является сведение решения задачи оптимального
управления к решению краевой задачи (см., например, [61], [66], [68], [70],
[84]);
2) другое направление составляют методы последовательных прибли-
жений, связанных с построением минимизирующей последовательности
управлений (в функциональных пространствах) [26], [41], [53], [58], [61],
[66], [73], [76], [84].
Предлагаемыйметодпримыкаеткпервойгруппе.Решениекраевыхза-
дач,возникающихврезультатепримененияпринципамаксимума,сводит-
ся либо к решению системы нелинейных алгебраических уравнений, либо
кмаксимизациивогнутойфункциивконечномерномпространстве.Дляре-
шения алгебраических уравнений в этом случае можно воспользоваться,
например,методамипрогонки,методомНьютонаиликвазиньютоновскими
методами[61],[66],[84],авслучаемаксимизациифункции—методамигра-
диентного типа (проекции градиента, условного градиента) [28], [29], [41].
Однакоупомянутыевышеметодывнекоторыхслучаяхлибосходятсяпло-
хо, либо вообще не сходятся. Квазиньютоновские методы могут оказаться
предпочтительнее в силу их значительно более быстрой сходимости. При
этомонитребуютвычисленийфункциинебольше,чемградиентныемето-
ды. На практике же проблема заключается в том, что обычно неизвестно
Электронныйжурнал.  98Дифференциальные уравнения и процессы управления, N. 1, 2004
достигнуталиужеобластьсходимости (например,методомНьютона)или
нет. Даже более того, неизвестно, будет ли оптимальная точка иметь та-
куюобласть.
Отметимособоалгоритмы[33],[41],которыеполучаютаппроксимацию
решенийиспользованиемсимплексов.Этиалгоритмыпозволяютнаходить
оптимальные управления и в том случае, когда множество достижимости
нестроговыпукло (например,имеетформумногогранника).Вэтихслуча-
яхметодыградиентноготипасходятсяоченьмедленно,априменениесим-
плексных алгоритмов может существенно ускорять итерационный процесс
и фактически обеспечивать вычислительную устойчивость. Это объясня-
ется тем, что в вычислительных целях непрерывная система управления
раздискречивается. Поэтому алгоритмы применяются фактически к дис-
кретнымсистемамуправления,адлядискретныхсистемуправлениямно-
жества достижимости могут оказаться многогранниками (как это имеет
место,например,вслучаезадачиминимизациитоплива).
В данном разделе предлагается [14], [15] для решения уравнений, воз-
никающих в результате применения принципа максимума, использовать
комбинированныйметод:методнеподвижнойточкидлянепрерывныхотоб-
ражений [79]иквазиньютоновскийметод [19], [99], [103].Параметрический
метод приближенного вычисления неподвижных точек непрерывных отоб-
ражений обладает достаточно широкой областью сходимости ввиду то-
го, что использует для их нахождения кусочно-линейную аппроксимацию
функции на триангуляциях. При этом за “глобальную”сходимость мето-
да приходится расплачиваться большим количеством вычислений значе-
нийфункции.Поэтому,оборвавэтотпроцессснекоторойточностью,мож-
но продолжить решение квазиньютоновским методом, который имеет при
хорошем начальном приближении локальную сверхлинейную сходимость.
Таким образом, можно построить алгоритм, который обладает как свой-
ством “глобальной”сходимости метода неподвижной точки (симплексного
метода), так и свойством локальной сверхлинейной сходимости квазинью-
тоновскихметодов.Главное,однако,состоитвтом,чтосвойство“глобаль-
ной”сходимости симплексных алгоритмов остается в силе в любом случае,
даже без какого-либо предположения о гладкости функции. Симплексный
метод часто работает лучше других методов, когда начальное приближе-
ние плохое или когда отображение имеет некоторые патологические свой-
ства.
Электронныйжурнал.  99Дифференциальные уравнения и процессы управления, N. 1, 2004
3.1. Постановка задачи
Рассмотримследующуюзадачуоптимальногоуправления:натраекто-
рияхуправляемойсистемы
˙ x =f(x,u,t), t∈T = [t
0
,t
1
],
x(t
0
) =x
0
, u(t)∈U
(3.1)
минимизироватьфункционал
Φ
0
(u)≡ϕ
0
(x(t
1
)) (3.2)
придополнительныхусловиях
Φ
i
(u)≡ϕ
i
(x(t
1
)) = 0, i = 1,q. (3.3)
Предположим, что функции ϕ
i
(x), i = 0,q, дифференцируемы на R
p
,
вектор-функцияf(x,u,t)иматрицачастныхпроизводныхf
x
(x,u,t)непре-
рывна по своим аргументам на R
p
×U ×T, множество U ⊂ R
r
компакт-
но.Допустимымиуправлениямибудемсчитатькусочно-непрерывныенаT
вектор-функции u(t)созначениямив U.
Пусть u(t) — допустимое управление, а x(t) — соответствующая ему
траектория. Положим H(x,ψ,u,t) = ψ
∗
f(x,u,t), где функция ψ(t) удовле-
творяетдифференциальномууравнению
˙
ψ =−f
∗
x
(x,u,t)ψ (3.4)
скраевымусловием
ψ(t
1
) =−ϕ
0x
(x(t
1
))−
q
X
i=1
λ
i
ϕ
ix
(x(t
1
)) (3.5)
длянекоторогопараметра λ = (λ
1
,... ,λ
q
).
Говорят,чтоуправлениеu(t)удовлетворяетпринципумаксимума,если
найдетсявектор λ6= 0такой,чтовыполняетсяусловиемаксимума
H(x(t),ψ(t),u(t),t) = max
u∈U
H(x(t),ψ(t),u,t). (3.6)
Пусть ˆ u(t) — оптимальное управление, а ˆ x(t) — соответствующая оп-
тимальная траектория. В этом случае принцип максимума [68] утвержда-
ет,чтонайдетсянепрерывнаявектор-функция
ˆ
ψ(t)6≡ 0такая,что
ˆ
ψ(t)яв-
ляетсярешениемуравнения (3.4)скраевымусловием (3.5)длянекоторого
Электронныйжурнал.  100Дифференциальные уравнения и процессы управления, N. 1, 2004
λ =
ˆ
λ и оптимального процесса {ˆ u(t),ˆ x(t)}, причем выполняется условие
максимума (3.6),т.е.
H(ˆ x(t),
ˆ
ψ(t),ˆ u(t),t) = max
u∈U
H(ˆ x(t),
ˆ
ψ(t),u,t).
Пусть u(t) можно однозначно определить из условия максимума (3.6)
как функцию x(t),ψ(t) : u(t) = γ(x(t),ψ(t)). Подставляя управление u(t) в
системы (3.1)и (3.4),получимсистему 2pуравнений
˙ x =f(x,γ(x,ψ),t),
˙
ψ =−f
∗
x
(x,γ(x,ψ),t)ψ, (3.7)
решения которой определяются заданием x(t
0
), ψ(t
0
) и λ. Поэтому, решая
систему (3.7)скраевымусловием
x(t
0
) =x
0
, ψ(t
1
) =−ϕ
0x
(x(t
1
))−ϕ
∗
x
(x(t
1
))λ, ϕ = (ϕ
1
,... ,ϕ
q
), (3.8)
получимрешениеисходнойзадачиоптимальногоуправления.Такимобра-
зом, получена краевая задача для системы обыкновенных дифференциаль-
ныхуравненийсдостаточносложнойструктуройправойчасти,множество
решенийкоторойсодержитрешениеисходнойзадачи.
Известночтовсякийметодрешениянелинейнойкраевойзадачисводит,
по существу, ее решение к решению некоторой нелинейной системы урав-
нений относительно некоторых параметров. Далее эта система решается
каким-либометодомрешениянелинейныхсистем.Выборвспомогательных
переменных (параметризация задачи) часто определяет успешность ее ре-
шения. Приведем два способа определения вектора неизвестных парамет-
ров.
1) Положим ξ = ψ(t
0
). В качестве неизвестных переменных примем
(ξ,λ). Интегрируя систему (3.7)“слева направо”от t
0
до t
1
при начальном
условии (x
0
,ξ), определим ψ(t
1
,ξ) и x(t
1
,ξ), а тем самым будет установ-
лена функциональная зависимость (p +q)-мерного вектора z = (ψ(t
1
,ξ),
ϕ(x(t
1
,ξ))) от (p +q)-мерного вектора g = (ξ,λ). Таким образом, в этом
случае решение краевой задачи (3.7),(3.8) сводится к решению системы
нелинейныхуравнений
ψ(t
1
,ξ)+ϕ
0x
(x(t
1
,ξ))+ϕ
∗
x
(x(t
1
,ξ))λ = 0, ϕ(x(t
1
,ξ)) = 0 (3.9)
относительнонеизвестныхпеременных ξ,λ.
2) Положим ξ = x(t
1
). В качестве неизвестных переменных примем
(ξ,λ). Найдем ψ(t
1
) из условия трансверсальности (3.8). Интегрируя си-
стему (3.7) “справа налево”в обратном времени, при начальном условии
Электронныйжурнал.  101Дифференциальные уравнения и процессы управления, N. 1, 2004
(ξ,ψ(t
1
,ξ,λ)),определимx(t
0
,ξ,λ).Врезультате,будетустановленафунк-
циональная зависимость (p +q)-мерного вектора z = (x(t
0
,ξ,λ),ϕ(ξ)) от
(p + q)-мерного вектора g = (ξ,λ). В этом случае система нелинейных
уравненийимеетвид
x
0
−x(t
0
,ξ,λ) = 0, ϕ(ξ) = 0 (3.10)
относительнонеизвестныхпеременныхξ,λ.Такимобразом,формальноре-
шениекраевойзадачисводитсякрешениюсистемыp+qнелинейныхурав-
нений z(g) = 0. Отметим здесь лишь, что иногда предпочтительнее выби-
рать второй способ параметризации задачи: в этом случае решение систе-
мы нелинейных уравнений (3.10) может оказаться более устойчивым, чем
решениесистемы (3.9).
3.2. Метод неподвижной точки
Началом конструктивной аппроксимации неподвижных точек непре-
рывныхотображенийпослужилалгоритмСкарфа [115].Алгоритмы,кото-
рые вырабатывают более точную аппроксимацию, основывались на гомо-
топиях[100],[101].Использоватьгомотопиивсимплексныхалгоритмахдля
получения аппроксимации неподвижных точек было предложено Ивзом.
Симплексные алгоритмы, использующие векторную разметку, включают
всебякусочно-линейнуюаппроксимациюфункциинатриангуляциях [101],
[102], [93], [94]. Более подробные и общие обзоры работ по этой тематике
можнонайти,например,в [79], [93], [94], [107].Тамжеприведенаобширная
библиографияподаннымвопросам.
Рассмотримсистемунелинейныхалгебраическихуравнений
z(g) = 0, (3.11)
где z : R
n
→R
n
—непрерывнаяфункция.Будемпредполагать,чтосуще-
ствуетрешение ˆ g системы (3.11).
Одним из способов решения уравнения (3.11) является сведение реше-
ния исходной задачи к решению более простой задачи, вводя в рассмот-
рениецелоесемейство отображений l(τ,g),зависящихотнекоторогопара-
метра τ.Приэтомдлянекоторогоконкретногозначения τ (например,при
τ = δ
0
) получается система z
1
(g) = 0, имеющая известное решение g
0
, а
при τ = 0 — исходное уравнение z(g) = 0, решение которого необходимо
найти.Такойпереходможноосуществить,например,спомощьюлинейной
Электронныйжурнал.  102Дифференциальные уравнения и процессы управления, N. 1, 2004
гомотопии [64],стр. 226]:
l(τ,g) =θ(g−g
0
)+(1−θ)z(g), (3.12)
где θ =τ/δ
0
, 0≤θ≤ 1.
Решение g
0
уравнения l(δ
0
,g) = 0 известно, а уравнение l(0,g) = 0
нужнорешить.Рассмотримуравнение
l(τ,g) = 0, τ ∈ [0,δ
0
]. (3.13)
Предположим, что уравнение (3.13) для каждого τ ∈ [0,δ
0
] имеет решение
g = g(τ), непрерывно зависящее от τ. Геометрически это означает что
точка g описываетпространственнуюкривую
C ={g∈R
n
: g =g(τ), τ ∈ [0,δ
0
]},
одним концом которой служит некоторая заданная точка g
0
,адругим
— точка, являющаяся решением ˆ g = g(0) уравнения l(0,g)≡ z(g) = 0.
Поэтомунеобходимоуметьприближенноотслеживатькривую C.
Гомотопный путь C можно отслеживать либо с помощью численно-
горешенияопределеннойзадачиКоши (алгоритмыпродолжения),которой
удовлетворяет кривая C, либо с помощью кусочно-линейной аппроксима-
ции (симплексами)вспомогательногоотображенияl(τ,g) (симплексныеал-
горитмы).Подробныеобзорыработпометодам продолжения и симплекс-
ным алгоритмам можно найти, например, в [79], [93], [94], [107].
Пусть y = (τ,g), ρ = [y
0
,y
1
,...,y
n
] есть n-мерный симплекс (n-
симплекс), а β(y) = Bg + c — аффинное отображение, совпадающее со
значениямифункции l(y)ввершинахсимплекса ρ,тоесть
Bg
i
+c =l(y
i
), i = 0,n.
Здесь n×n-матрица B и вектор c определяются из последних равенств.
ПустьL =
1 1 ... 1
l(y
0
) ... ... l(y
n
)
.МатрицаLназываетсяматрицейметок,а
самафункция l(y) —векторнойразметкой (векторнымпомечиванием).
Легко можно показать, что если точки l(y
0
),...,l(y
n
) аффинно неза-
висимы (находятся в общем положении), то нуль аффинной функции β(y)
может быть представлен в виде [64], стр. 190–192] ˜ g =
n
P
i=0
α
i
g
i
, причем
коэффициенты α
i
, i = 0,nопределяютсяврезультатерешениясистемы
Lα =e
0
. (3.14)
Электронныйжурнал.  103Дифференциальные уравнения и процессы управления, N. 1, 2004
Здесь e
0
= (1,0,...,0)
∗
— единичный орт. Так как предполагается, что
кривая C пересекает n-мерную грань (n + 1)-симплекса, то ноль должен
принадлежать n-симплексу, и в этом случае будет α ≥ 0. Поэтому гово-
рят, что n-симплекс полностью размечен в соответствии с отображением
l, если существует решение α ≥ 0 системы (3.14). Таким образом, мож-
носказать,чтосимплексныеалгоритмыявляются,посуществу,методами
приближенного отслеживания кривой C посредством (n+1)-мерных сим-
плексов, определенных на триангуляциях и имеющих две полностью раз-
меченне n-мерные грани. Одна полностью размеченная грань считается
входом для кривой C, а другая ее выходом. Так как обе грани полностью
размечены, то соответствующие им матрицы меток невырождены. Поэто-
му переход от входной грани к выходной осуществляется (как в линейном
программировании) введением в базис на некоторое место нового вектор-
столбца.Врезультате,получаембазис,соответствующийвыходнойграни.
Симплексныйалгоритмвырабатываетконечнуюилибесконечнуюпоследо-
вательностьполностьюразмеченныхn-мерныхгранейисоответствующих
(n+1)-симплексов.
Нижеописываетсяалгоритмнахождениярешениясистемы(3.11),осно-
ванный на триангуляциях [79], стр. 84–95] с непрерывным уменьшением
размерасетки(уточняемыетриангуляции).Этиуточняемыетриангуляции
становятсявсеболеемелкими,когдагомотопныйпараметрτ приближает-
ся к нулю. Описание указанных триангуляций приводится в работах [79],
[94].
Обозначим:σ
k
— (n+1)-мерныйсимплекснаk-йитерации;ρ
k−1
,ρ
k
—
его грани, причем y
i
= (τ
i
,g
i
), i = 0,n, — вершины входной грани ρ
k−1
,
а ¯ y
i
= (τ
i
,¯ g
i
), i = 0,n, — вершины выходной грани ρ
k
, Y = (¯ y
0
,...,¯ y
n
),
G = (¯ g
0
,...,¯ g
n
), L
ρ
k
=
1 ... 1
l(¯ y
0
) ... l(¯ y
n
)
— матрица меток грани ρ
k
, Q =
(q
0
,...,q
n
) =L
−1
ρ
k
, τ
s
= 2
−s
δ
0
, s = 0,1,....
Алгоритм 3.1 (гомотопный алгоритм):
Шаг 0. Задать начальную точку g
0
∈ R
n
. Задать числа δ
0
, ε
1
, ε
2
, ζ.
Положить k = 0, m = 0.
Шаг 1.Начальныйшаг:
Положить m =m+1;
a)определитьвектор η∈R
n+1
: η
m
0
=δ
m−1
, η
m
i
=g
m−1
i
, i = 1,n;
Электронныйжурнал.  104Дифференциальные уравнения и процессы управления, N. 1, 2004
b) определить точку y
−1
, являющуюся опорной (центральной) при нахо-
ждении остальных точек y
0
,...,y
n
симплекса σ
k
размерности n+1, в со-
ответствиисточкой η
m
;
c) вычислить остальные вершины y
0
,...,y
n
симплекса σ
k
размерности
n+1,т.е.вычислитьвершиныграни ρ
k
= [y
0
,...,y
n
];
d)вычислитьматрицуразметкивходнойграни ρ
k
:
L
ρ
k
=
1 ... 1
l(y
0
) ... l(y
n
)
.
Найтиобратнуюматрицу L
−1
ρ
k
;
e)принятьy
−1
вкачествевходноговектораy
+
,т.е.векторакоторыйнужно
ввестивбазис L
ρ
k
.
Шаг 2.Шаглинейногопрограммирования:
положить k =k+1;
a)вычислить l(y
+
);
b) найти номер j
0
вектора, который должен быть замещен в базисе L
ρ
k−1
:
y
−
=y
j
0
;
c) удалить столбец (1, l(y
−
))
∗
из базиса L
ρ
k−1
и ввести столбец
(1, l(y
+
))
∗
. Получаем новый базис L
ρ
k
. В результате получаем также мат-
рицу L
−1
ρ
k
.
Шаг 3.Определениенового (n+1)-симплекса σ
k
:
a)вычислитьвершины ¯ y
−1
, ¯ y
0
,... ,¯ y
n
нового (n+1)-симплекса σ
k
;
b)установитьсоответствиемеждувершинамисимплексовσ
k−1
иσ
k
.Найти
точку y
+
,противолежащуюграни ρ
k
.
Шаг 4.Переходнановыйуровень:
если (y
+
0
)
k
≥ (y
+
0
)
k−1
,топерейтинашаг 2,иначе —кследующемушагу.
Шаг 5.Вычислениеочереднойнеподвижнойточки:
a) вычислить неподвижную точку, лежащую в грани ρ
k
: y
m
=Yq
0
, g
m
=
Gq
0
;
b)определить z(g
m
)и l(y
m
);
c)еслиkl(y
m
)k≥ε
2
,топерейтинашаг 2,иначе —кследующемушагу 6.
Шаг 6.Проверкаточностирешения:
еслиkz(g
m
)k<ε
1
—остановиться,иначе —перейтикшагу 7.
Шаг 7.Рекурсивныйцикл:
а)если
 
 
 
 
kz(g
m
)k−kz(g
m−1
)k
 
 
 
 
<ζ и ε
2
> 10
−8
,положить ε
2
= 0.1ε
2
;
Электронныйжурнал.  105Дифференциальные уравнения и процессы управления, N. 1, 2004
b) вычислить μ
m
= max
i=1,n
|g
m
i
−g
m−1
i
|; если μ
m
≥ 0.5δ
m
, то положить
δ
m+1
= 0.5δ
m
,иначе δ
m+1
=μ
m
.Перейтикшагу 1.
В дальнейшем вычисления, требуемые для получения очередного при-
ближения к решению уравнения (3.11) (очередной неподвижной точки) бу-
дут называться ”этапом”,а вычисления,необходимые для интегрирования
прямой и сопряженной системы (3.7), (3.8), — ”итерацией”. Если на ша-
ге 5 гомотопного алгоритма необходимая точность вычисления решения
уравнения (3.11) не достигнута, то для ускорения итерационного процес-
санаэтомшагенеобходимопроделатьдополнительноньютоновскиешаги.
Подробное описание квазиньютоновского алгоритма дается в следующем
пункте.
3.3. Квазиньютоновский метод
Рассмотримсистемунелинейныхалгебраическихуравнений
z(g) = 0, (3.15)
где z : R
n
→R
n
, g∈R
n
.
Введем обозначения. Пусть z
k
=z(g
k
), Δg
k
=g
k
−g
k−1
, Δz
k
=
z
k
−z
k−1
. Будем обозначать через z
0
(g) матрицу Якоби, вычисленную в
точке g.
Если матрица Якоби z
0
(g) легко вычисляется, наиболее известным ме-
тодомдлярешениясистемы (3.15)являетсяметодНьютона
g
k+1
=g
k
−z
0
(g
k
)
−1
z(g
k
), k = 0,1... . (3.16)
Если же z
0
(g) недоступна для вычисления, то матрица z
0
(g
k
) (или
z
0
(g
k
)
−1
)заменяетсянекоторойееаппроксимацией.
Ниже будет рассматриваться квазиньютоновский метод в следующем
виде
g
k+1
=g
k
−D
k
z(g
k
), D
k+1
=D
k
+
(Δg
k
−D
k
Δz
k
)w
∗k
w
∗k
Δz
k
, k = 0,1... .
Предложенный в этом пункте алгоритм является незначительной мо-
дификацией алгоритмов [103], [19]. Предположим, что на k-й итера-
ции имеется множество линейно независимых векторов ΔZ
k
= {Δz
j
,
j ∈ J
k
}, где J
k
= {j
k1
,j
k2
,...,j
kn
} — множество упорядоченных по убы-
ванию целых чисел. Предположим так же, что вектор Δz
j
ks
может быть
Электронныйжурнал.  106Дифференциальные уравнения и процессы управления, N. 1, 2004
замененвматрице ΔZ
k
навектор Δz
k
,такчтоврезультатетакойзамены
получитсяновыйбазис.
Обозначим
J
0
k
=J
k
\{j
ks
}, A
k
={Δz
j
,j ∈J
0
k
}.
Тогдавкачествеw
k
длякоррекцииD
k
можновыбратьвектор,ортогональ-
ныйковсем Δz
j
, j ∈J
0
k
.Очевидно,чтовэтомслучаевекторw
k
имеетвид
w
k
= Δz
k
−Δ˜ z
k
,
где Δ˜ z
k
— ортогональная проекция вектора Δz
k
на подпространство, на-
тянутоенавектора Δz
j
,j ∈J
0
k
.ПустьA
+
k
—матрица,псевдообратная [31],
стр. 32]дляматрицы A
k
.Легкоможнопоказать,что
Δz
k
=A
k
A
+
k
Δz
k
.
Алгоритм 3.2 (квазиньютоновский алгоритм):
Шаг 0. Задать начальную точку g
0
, матрицу D
0
, число ε
1
. Вычислить
z
0
.Положить k = 0.
Шаг 1.СоставитьмножествоJ
k
={k−1,... ,k−n}.ПоложитьΔZ
k
=E
(E —единичнаяматрица).
Шаг 2.Еслиkz
k
k<ε
1
,тоостановиться.
Шаг 3. Найти Δg
k
= −D
k
z
k
. Положить g
k+1
= g
k
+ Δg
k
. Вычислить
z
k+1
и Δz
k
=z
k+1
−z
k
.
Шаг 4. Определить номер j
ks
вектора, который необходимо исключить
избазиса ΔZ
k
.Определитьмножество J
0
k
=J
k
\{j
ks
}.
Шаг 5.СоставитьматрицуA
k
={Δz
j
, j ∈J
0
k
}.Найтипсевдообратную
матрицу A
+
k
.Вычислить Δ˜ z
k
=A
k
A
+
k
Δz
k
,атакже w
k
= Δz
k
−Δ˜ z
k
.
Шаг 6.Вычислитьматрицу D
k+1
поформуле
D
k+1
=D
k
+(Δg
k
−D
k
Δz
k
)
w
∗k
w
∗k
Δz
k
.
Шаг 7.Составитьматрицу ΔZ
k+1
={Δz
k
, Δz
j
, j ∈J
0
k
}исоответству-
ющееэтойматрицемножество J
k+1
={k,J
0
k
}.
Шаг 8.Положить k =k+1иперейтикшагу 2.
Алгоритм 3.2 сходится к ˆ g [19], если точка g
0
достаточно близка к ˆ g, а
нормаkD
0
−z
0
(g
0
)
−1
kдостаточномала.
Электронныйжурнал.  107Дифференциальные уравнения и процессы управления, N. 1, 2004
На шаге 5 алгоритма 3.2 для вычисления псевдообратной матрицы и
нашаге 4припроверкеналинейнуюзависимостьвекторовможновосполь-
зоватьсяметодомГревилля [31],стр. 39–40]последовательногонахождения
псевдообратнойматрицы.
Электронныйжурнал.  108Дифференциальные уравнения и процессы управления, N. 1, 2004
3.4. Общая схема алгоритма
В предыдущих пунктах были приведены алгоритмы решения нелиней-
ныхалгебраическихуравнений:рестартовыйгомотопный (раздел 2)иква-
зиньютоновский (раздел 3). В данном пункте приводится общая схема ис-
пользования этих алгоритмов. Оба метода для получения приближения к
решениюуравненийвырабатываютпоследовательностьсмежныхсимплек-
сов (двасимплексаназываютсясмежными,еслиониимеютобщуюгрань).
При этом гомотопный метод может быть применен для убывающей после-
довательностисеточныхразмеров,еслииспользоватьвкачественачальной
точкиналюбомэтапеаппроксимацию,полученнуюнапредыдущемэтапе.
На тесную связь между этими двумя методами впервые, вероятно, указал
Сейгал [113]. Он предложил чередовать шаги симплексного алгоритма с
ньютоновскими шагами. Техника чередования PL-шагов (начальные бук-
вы слов piecewise linear) и ньютоновских шагов для ускорения гомотопных
алгоритмовобсуждаласьв [114], [117].
Вработе [15]предлагаетсяболеепростойспособ —комбинированиего-
мотопного и квазиньютоновского алгоритмов, а не чередование PL-шагов
иквазиньютоновскихшаговдляглобализацииметодаНьютона.Аименно,
после нахождения очередного приближения к решению системы уравне-
нийгомотопнымалгоритмомпроделываютсяпробныеньютоновскиешаги.
Если они не успешны (нарушается монотонное убывание невязки откло-
нения левой части системы от нуля), вновь перезапускается гомотопный
алгоритм,причемвкачественачальнойточкипринимаетсяпоследнеепри-
ближенноерешениесистемыуравнений.
Пусть задана начальная точка g
0
∈ R
n
и начальный сеточный размер
δ
0
. Предположим, что используется и перезапускается гомотопный алго-
ритм. Пусть на m-м этапе имеется приближенный нуль g
m−1
функции z
и сеточный размер δ
m−1
. Для получения очередного приближения к реше-
нию уравнений проделываются вычисления в соответствии с шагами 1–5
гомотопного алгоритма. Предположим, что после многократного выполне-
нияшагов1–5алгоритма3.1достигнутанеобходимаяточностьвычисления
решения уравнения (3.13). В результате, будут найдены (см. шаг 5 алго-
ритма 3.1) g
m
, z(g
m
), а еще — G
m
и Z
m
, соответствующие матрицам Y
m
и L
ρ
m
. Пусть N(k,¯ g) означает шаги 1–8 алгоритма 3.2 при g
k
= ¯ g. Тогда,
используяматрицыG
m
иZ
m
,определяемвкачественачальногоприближе-
ния D
k
= ΔG
m
ΔZ
−1
m
и проделываем шаги квазиньютоновского алгоритма
N(k,g
m
).Еслиалгоритм 3.2ненаходитрешенияснеобходимойточностью,
Электронныйжурнал.  109Дифференциальные уравнения и процессы управления, N. 1, 2004
сеточныйразмерδ
m
уменьшаетсяиперезапускаетсявновьгомотопныйал-
горитм.
Алгоритм 3.3 (общий алгоритм).
Шаг 0. Задать начальную точку g
0
∈ R
n
. Задать числа δ
0
,ε
1
,ε
2
,ζ.
Положить k = 0, m = 0.
Шаг 1. Проделывать шаги 1–5 гомотопного алгоритма (алгоритма 3.1)
до тех пор, пока не будет достигнута необходимая точность приближения
ε
2
длягомотопногоалгоритма.
Шаг 2.Проверкаточностирешения:
еслиkz(g
m
)k<ε
1
—остановиться,иначе —перейтикшагу 3.
Шаг 3.Проделыватьшаги N(k,g
m
)квазиньютоновскогоалгоритма.
Шаг 4.Рекурсивныйцикл:
а)если
 
 
 
 
kz(g
m
)k−kz(g
m−1
)k
 
 
 
 
<ζ и ε
2
> 10
−8
,положить ε
2
= 0.1ε
2
;
б) вычислить μ
m
= max
i=1,n
 
 
 
 
g
m
i
−g
m−1
i
 
 
 
 
; если μ
m
≥ 0.5δ
m
, то положить
δ
m+1
= 0.5δ
m
,иначе δ
m+1
=μ
m
.
Перейтикшагу 1.
Легко видеть, что алгоритм 3.3 генерирует последовательность {g
m
}
приближенных решений уравнения z(g) = 0. Последовательность {g
m
}
ограниченаи,следовательно,имеетпоменьшеймереоднуточкусгущения.
Еслижепредположить,чтоz(g)имеетизолированныенули,тополученная
алгоритмом 3.3последовательность{g
m
}сходитсяпри m→∞к ˆ g.
3.5. Численные примеры
Для проверки эффективности предложенного алгоритма 3.3 были со-
ставленыпрограммыипроведенырасчетызадач,известныхвлитературе.
Приведем здесь итоговые результаты проверки, которые демонстрируют
типичноеповедениеалгоритма.
Примеры решались при следующих данных: точность решения задачи
ε
1
= 10
−4
, точность решения задачи по методу неподвижной точки ε
2
=
0.01, ζ = 0.1.
Обозначения: m — номер этапа, k — номер итерации, τ
mk
— значения
гомотопного параметра, g
mk
— краевое условие для сопряженной системы
Электронныйжурнал.  110Дифференциальные уравнения и процессы управления, N. 1, 2004
(см. (3.7) — (3.10)), l
mk
≡ l(τ
mk
,g
mk
) — значение функции разметки в
методенеподвижнойточки (см. (3.12)).
Пример 3.1 [26]:
˙ x
1
=x
2
, ˙ x
2
=−sin x
1
+u,
x(0) = (5,0)
∗
, T = [0,5], U = [−1,1], Φ
0
=x
2
1
+x
2
2
.
Ограниченияотсутствуют.Использовалсявторойвидпараметризации(см.
пункт3.1).Начальныеприближения:δ
0
= 0.2, g
0
≡x(t
1
) = (3.1,−1)
∗
.Ход
итерацийиллюстрируетсятаблицей 1.
Результаты счета:
ˆ
Φ
0
= 11.90805, ˆ g = (3.178936, −1.342526)
∗
. Опти-
мальное управление — релейное управление с двумя точками переключе-
ния t
1
,t
2
:
ˆ u(t) =





1, t∈ [0,t
1
);
−1, t∈ [t
1
,t
2
);
1, t∈ [t
2
,5],
где t
1
= 0.982443, t
2
= 4.550369.
Пример 3.2 [76]:
˙ x
1
=x
2
, ˙ x
2
=−sin x
1
+u, ˙ x
3
=u,
x(0) = (1,0,0)
∗
, T = [0,2π], U = [0,1], Φ
0
=x
3
, Φ
1
=x
1
, Φ
2
=x
2
.
Начальныеприближения: δ
0
= 0.2, g
0
≡ψ(0) = (0,0,−1)
∗
.Ходитера-
цийиллюстрируетсятаблицей 2.
Результаты счета:
ˆ
Φ
0
= 0.999637, ˆ g = (−0.997403,0,−1)
∗
. Оптималь-
ное управление — релейное управление с двумя точками переключения
t
1
, t
2
:
ˆ u(t) =





0, t∈ [0,t
1
);
1, t∈ [t
1
,t
2
);
0, t∈ [t
2
,2π],
гдеt
1
= 1.175244,t
2
= 2.174881.Нижевтаблицахсимволом”∗”помечаются
итерации,получаемыеквазиньютоновскималгоритмом.
Электронныйжурнал.  111Дифференциальные уравнения и процессы управления, N. 1, 2004
Таблица 3.1.Результатысчетаалгоритма 3.3.
m,k,τ
mk
g
mk
z(g
mk
) Φ
0
, kz(g
mk
)k,
kl
mk
k
1 3.2608 −0.164538 12.3128
9 −1.29613 0.201425 0.260086
0.1 0.00162065
1 3.11629 0.0918759 11.5909
∗10 −1.37099 −0.143661 0.170528
− −
1 3.18719 −0.00215886 11.9549
∗11 −1.34041 0.00999895 0.0102294
− −
1 3.18129 −0.000998527 11.9212
∗12 −1.34186 0.00316346 0.00331731
− −
1 3.17897 −1.56394·10
−5
11.9082
∗13 −1.34252 5.02865·10
−5
5.26623·10
−5
− −
Электронныйжурнал.  112Дифференциальные уравнения и процессы управления, N. 1, 2004
Таблица 3.2.
m,k,τ
mk
g
mk
z(g
mk
) Φ
0
, kz(g
mk
)k,
kl
mk
k
1 −0.9006 0.9264 0
37 −0.3151 0.3476 0.9895
0.1 −1 0 0.01036
1 −0.9421 0.2905 0.6859
59 −0.06369 0.002756 0.2905
0.05 −1 1.11·10
−16
0.005619
1 −0.9608 0.05106 0.936
∗60 0.09059 0.07051 0.08706
− −1 −2.22·10
−16
−
2 −0.9805 0.01564 0.9778
69 0.05181 0.03983 0.04279
0.05 −1 4.441·10
−16
0.001046
2 −0.997 0.001503 0.9979
∗70 −0.0003432 −8.748·10
−5
0.001506
− −1 0 −
2 −0.9974 −0.0001966 0.9998
∗71 7.389·10
−5
3.307·10
−5
0.0001994
− −1 0 −
2 −0.9974 −1.005·10
−6
0.9996
∗72 −3.527·10
−7
−3.749·10
−7
1.073·10
−6
− −1 0 −
Электронныйжурнал.  113Дифференциальные уравнения и процессы управления, N. 1, 2004
Литература
[1] АввакумовС.Н.,КиселевЮ.Н.,ОрловМ.В.Методырешениязадач
оптимального управления на основе принципа максимума Понтряги-
на // Труды Математического института им. В.А. Стеклова РАН.
1995.Т. 211. C. 3–31.
[2] Александров В.М. Квазиоптимальные процессы в автоматических
системах.ИзвестияАНСССР.Техническаякибернетика.Т. 13,№ 3.
1975.
[3] АлександровВ.М.Приближенноерешениезадачилинейногобыстро-
действия //Автоматикаителемеханика. 1998.№ 12. C. 3–13.
[4] Александров В.М. Численный метод решения задачи линейного
быстродействия // Журнал вычислительной математики и матема-
тическойфизики. 1998.Т. 38.№ 6.С. 918–931.
[5] Антоник В.Г., Срочко В.А. Решение задач оптимального управле-
ния на основе методов линеаризации // Журнал вычислительной
математикииматематическойфизики. 1992.Т. 32.№ 7.С. 979–991.
[6] Атанс М., Фалб П. Оптимальное управление. М.: Машиностроение,
1968.
[7] Баничук Н.В., Петров В.М., Черноусько Ф.Л. Численное решение
вариационных и краевых задач методом локальных вариаций //
Журнал вычислительной математики и математической физики.
1966.Т. 6.№ 6. C. 947–961.
[8] Батурин В.А., Урбанович Д.Е. Методы улучшения второго порядка
для задач оптимального управления // Известия РАН. Теория и
системыуправления. 1997.№ 3.С. 99–103.
[9] Башков Е.А. Алгоритм решения задачи быстродействия по ампли-
туде и “мере”управления // Теория оптимальных процессов. Киев:
ИздательствоИнститутакибернетики. 1974.С. 15–23.
[10] Белман Р. Динамическое программирование. М.: Издательство
иностраннаялитература, 1960.
[11] Болдырев В.И. Построение финитных управлений для линейных
систем с ограничениями // Новосибирск, 1992. 17 c. (Препринт /
РАН.Сибирскоеотделение.Институтматематики;№ 8).
Электронныйжурнал.  114Дифференциальные уравнения и процессы управления, N. 1, 2004
[12] Болдырев В.И. Минимизация псевдовыпуклого функционала на
множестве конечных состояний линейной системы управления //
Известия РАН. Теория и системы управления. 2002. № 3. С. 49–52
(V.I.Boldyrev. Minimization of a Pseudo-Convex Functional on a Set of
Terminal States of a Linear Control System // Journal of Computer and
Systems Sciences International. 2002. V. 41(3). P. 382–388).
[13] Болдырев В.И. Решение линейной задачи оптимального управления
с терминальными ограничениями // Известия РАН. Теория и
системы управления. 2003. № 5. С. 41–50 (V.I.Boldyrev. Solution
of a Linear Optimal Control Problem With Terminal Constraints //
JournalofComputerandSystemsSciencesInternational.2003.V.42(3)).
[14] Болдырев В.И. Численное решение задачи линейного быстродей-
ствия // Фундаментальная и прикладная математика. 1999. Т. 5.
№ 3.С. 637–648.
[15] Болдырев В.И. Численное решение задач оптимального управления
//ИзвестияРАН.Теорияисистемыуправления. 2000.№ 3.С. 85–92.
(англ. перевод: Boldyrev, V.I. Numerical solution of optimal control
problems // Journal of Computer and Systems Sciences International.
2000. V. 39.№ 3. P. 415–422.)
[16] БолтянскийВ.Г.Математическиеметодыоптимальногоуправления.
М.:Наука, 1969.
[17] Брайсон А., Денхем В. Применение наискорейшего спуска к задачам
оптимальногоуправления //Ракетнаятехникаикосмонавтика. 1964.
№ 2.
[18] Брайсон А., Хо Ю-Ши. Прикладная теория оптимального управле-
ния.М.:Мир, 1972.
[19] Бурдаков О.П. Устойчивые варианты метода секущих для решения
систем уравнений // Журнал вычислительной математики и мате-
матическойфизики. 1983.Т. 23.№ 5.С. 1027–1040.
[20] Васильев О.В., Терлецкий В.А. Оптимальное управление краевой
задачей // Труды Математического института им. В.А. Стеклова
РАН. 1995.Т. 211.С. 121–130.
[21] Васильев О.В. Методы оптимизации в функциональных простран-
ствах.Иркутск:ИздательствоИркутскогоуниверситета, 1979.
Электронныйжурнал.  115Дифференциальные уравнения и процессы управления, N. 1, 2004
[22] Васильев О.В. К вопросу о численном решении задачи терминаль-
ного управления // Труды Иркутского университета. Иркутск:
ИздательствоИркутскогоуниверситета, 1968.
[23] Васильев Ф.П. Лекции по методам решения экстремальных задач.
М.:ИздательствоМосковскогоуниверситета, 1974.
[24] Васильев О.В., Бельтюков Н.Б., Терлецкий В.А. Алгоритмы опти-
мизации динамических систем, основанные на принципе максимума
//Вопросыкибернетики.М.:Наука, 1991. C. 17–38.
[25] Васильев О.В., Тятюшкин А.И. Опыт в решении задач оптималь-
ного управления на основе необходимых условий для оптимальности
типа принципа максимума // Вопросы устойчивости и оптимизация
динамических систем. Иркутск: Издательство Иркутского универси-
тета, 1983.С. 43–64.
[26] Васильев О.В., Тятюшкин А.И. Об одном методе решения задач
оптимального управления основанного на принципе максимума //
Журнал вычислительной математики и математической физики.
1981.Т. 21.№ 6.С. 1376–1384.
[27] Васильев О.В., Тятюшкин А.И. К численному решению задач
линейного быстродействия // Дифференциальные и интегральные
уравнения. Иркутск: Издательство Иркутского университета. 1973.
Вып. 2.С. 57–69.
[28] Габасов Р., Кириллова Ф.М. Построение последовательных прибли-
женийдлянекоторыхзадачоптимальногоуправления//Автоматика
ителемеханика. 1964.Т. 27.№ 2. C. 5–17.
[29] Габасов Р., Кириллова Ф.М. Качественная теория оптимальных
процессов.М.:Наука, 1971.
[30] Габасов Р., Кириллова Ф.М. Оптимизация линейных систем.
Минск: Издательство Беларусского государственного университета,
1973.Т. 33.№ 9. C. 31–62.
[31] ГантмахерР.Теорияматриц.М.:Наука, 1966.
[32] Гиндес В.Б. К задаче минимизации выпуклого функционала на
множестве конечных состояний линейной системы управления //
Журнал вычислительной математики и математической физики.
1966.Т. 6.№ 6.С. 962–970.
Электронныйжурнал.  116Дифференциальные уравнения и процессы управления, N. 1, 2004
[33] Гиндес В.Б. Один метод последовательных приближений для
решения линейных задач оптимального управления // Журнал
вычислительной математики и математической физики. 1970. Т. 10.
№ 1. C. 216–223.
[34] Грачев Н.И., Евтушенко Ю.Г. Библиотека программ для решения
задач оптимального управления // Журнал вычислительной мате-
матикииматематическойфизики. 1979.Т. 19.№ 2.С. 367–387.
[35] Гроссман К., Каплан А.А. Нелинейное программирование на основе
безусловнойминимизации.Новосибирск:Наука, 1981.
[36] Демьянов В.Ф. К построению оптимальной программы в линейной
системе //Автоматикаителемеханика. 1964.Т. 25.№ 1. C. 3–11.
[37] Демьянов В.Ф., Рубинов А.М. Приближенные методы решения
экстремальных задач. Л.: Издательство Ленинградского государ-
ственногоуниверситета, 1968.
[38] Евтушенко Ю.Г. Методы решения экстремальных задач и их
применениевсистемахоптимизации.М.:Наука, 1982.
[39] Ермольев Ю.М., Гуленко В.П. О численных методах решения задач
оптимальногоуправления //Кибернетика. 1966.№ 1.С. 72–78.
[40] Ермольев Ю.М., Гуленко В.П., Царенко Т.И. Конечно-разностный
метод в задачах оптимального управления. Киев: Наукова думка,
1978.
[41] Жолудев А.И., Тятюшкин А.И., Эринчек Н.М. Численные методы
оптимизации управляемых процессов // Известия АН СССР. Техни-
ческаякибернетика. 1989.№ 4. C. 14–31.
[42] Калман Р.Е. Об общей теории управления I // Международный
конгрессИФАК.М.:Физматгиз, 1960.
[43] КармановВ.Г.Математическоепрограммирование.М.:Наука, 1975.
[44] Квакернаак Х., Сиван Р. Линейные оптимальные системы управле-
ния.М.:Мир, 1977.
[45] Киселев Ю.Н. Оптимальное управление. М.: Издательство Москов-
скогогосударственногоуниверситета, 1988.
[46] Киселев Ю.Н. Быстро сходящиеся алгоритмы для линейного оп-
тимального быстродействия // Кибернетика. 1990. Т. 62. № 6.
С. 47–57.
Электронныйжурнал.  117Дифференциальные уравнения и процессы управления, N. 1, 2004
[47] КиселевЮ.Н.,ОрловМ.В.Численныеалгоритмылинейныхбыстро-
действий //Журналвычислительнойматематикииматематической
физики. 1991.Т. 31.№ 12. C. 1763–1771.
[48] Киселев Ю.Н. Построение точных решений для нелинейной
задачи оптимального быстродействия специального вида // Фун-
даментальная и прикладная математика. 1997. Т. 3. Вып. 3.
С. 847–868.
[49] Кирин Н.Е. К решению общей задачи линейного быстродействия //
Автоматикаителемеханика. 1964.Т. 25.№ 1. C. 16–22.
[50] Кирин Н.Е. Методы последовательных оценок в задачах опти-
мизации управляемых систем. Л.: издательство Ленинградского
государственногоуниверситета, 1975.
[51] Кротов В.Ф., Гурман В.И. Методы и задачи оптимального управле-
ния.М.:Наука, 1973.
[52] Крылов И.А., Черноусько Ф.Л. О методе последовательных при-
ближений для решения задач оптимального управления // Журнал
вычислительной математики и математической физики. 1962. Т. 2.
№ 6. C. 1132–1139.
[53] Крылов И.А., Черноусько Ф.Л. Алгоритм метода последовательных
приближений для задач оптимального управления // Журнал
вычислительной математики и математической физики. 1972. Т. 12.
№ 1. C. 14–34.
[54] ЛевинА.Ю.Линейныеоптимальныебыстродействияицентрирован-
ные сечения // Вестник Ярославского университета. 1975. Вып. 12.
С. 87–93.
[55] Ли Э.Б., Маркус Л. Основы теории оптимального управления. М.:
Наука, 1972.
[56] Любушин А.А. Модификации и исследование сходимости метода
последовательных приближений для задач оптимального управления
// Журнал вычислительной математики и математической физики.
1979.Т. 19.№ 6.С. 1414–1421.
[57] Любушин А.А. О применении модификации метода последователь-
ных приближений для задач оптимального управления // Журнал
вычислительной математики и математической физики. 1982. Т. 22.
№ 1.С. 30–35.
Электронныйжурнал.  118Дифференциальные уравнения и процессы управления, N. 1, 2004
[58] Любушин А.А., Черноусько Ф.Л. Метод последовательных прибли-
женийдлярасчетаоптимальногоуправления //ИзвестияАНСССР.
Техническаякибернетика. 1983.№ 2.С. 147–159.
[59] Милютин А.А., Илютович А.Е., Осмоловский Н.П., Чуканов С.В.
Оптимальноеуправлениевлинейныхсистемах.М.:Наука, 1993.
[60] Моисеев Н.Н. Численные методы теории оптимальных управлений,
использующие вариации в пространстве состояний // Кибернетика.
1966.№ 3. C. 1–29.
[61] Моисеев Н.Н. Численные методы в теории оптимальных систем. М.:
Наука, 1971.
[62] Моисеев Н.Н. Элементы теории оптимальных систем. М.: Наука,
1975.
[63] Орлов М.В. Линейная задача быстродействия: численный алгоритм
// Вестник Московского университета. Серия 15. Вычислительная
математикаикибернетика. 1986.№ 4.С. 41–46.
[64] Ортега Дж., Рейнболдт В. Итерационные методы решения нелиней-
ныхсистемсомногиминеизвестными.М.:Мир, 1975.
[65] Охоцимский Д.Е., Энеев Т.М. Некоторые вариационные задачи,
связанные с запуском искусственного спутника Земли // Успехи
физическихнаук. 1957.Т. 63.№ 1а.С. 36–51.
[66] ПолакЭ.Численныеметодыоптимизации.Единый подход.М.:Мир,
1974.
[67] Поляк Б.Т., Третьяков Н.В. Метод штрафных оценок для задач
на условный экстремум // Журнал вычислительной математики и
математическойфизики. 1973.Т. 13.№ 1.С. 34–46.
[68] Понтрягин Л.С., Болтянский В.Г., Гамкрелидзе Р.В., Мищенко
Е.Ф. Математическая теория оптимальных процессов. М.: Физмат-
гиз, 1969.
[69] Пропой А.И. Элементы теории оптимальных дискретных процессов.
М.:Наука, 1973.
[70] Розоноэр Л.И. Принцип максимума Л.С. Понтрягина в теории
оптимальных систем II // Автоматика и телемеханика. 1959. Т. 22.
№ 11.С. 1441–1457.
[71] РокафелларР.Выпуклыйанализ.М.:Мир, 1973.
Электронныйжурнал.  119Дифференциальные уравнения и процессы управления, N. 1, 2004
[72] Скоков В.А. Алгоритм метода штрафных оценок для минимизации
функций многих переменных при наличии ограничений // Програм-
мыиалгоритмы.ЦЭМИАНСССР. 1973.Вып. 55.
[73] Срочко В.А. Вариационный принцип максимума и методы линеари-
зации в задачах оптимального управления. Иркутск: Издательство
Иркутскогоуниверситета, 1989.
[74] Срочко В.А. Итерационные методы решения задач оптимального
управления.М.:Физматлит, 2000.
[75] Срочко В.А., Мамонова Н.В. Квазиградиентный метод решения
задач оптимального управления // Известия высших учебных заве-
дений.Математика. 1996.Т. 415.№ 12.С. 84–91.
[76] Срочко В.А., Хамидулин Р.Г. Метод последовательных приближе-
ний в задачах оптимального управления с краевыми условиями //
Журнал вычислительной математики и математической физики.
1986.Т. 26.№ 4.С. 508–520.
[77] Табак Д., Куо Б. Оптимальное управление и математическое про-
граммирование.М.:Наука, 1975.
[78] Тихонов А.Н., Галкин В.Я., Заикин П.Н. О прямых методах
решения задач оптимального управления // Журнал вычисли-
тельной математики и математической физики. 1967. Т. 7. № 2.
С. 416–423.
[79] Тодд М. Дж. Вычисление неподвижных точек и приложения к
экономике.М.:Наука, 1983.
[80] ТятюшкинА.И.Численноерешениезадачоптимальногоуправления
// Дифференциальные уравнения и численные методы. Новосибирск:
Наука, 1986.С. 208–217.
[81] Тятюшкин А.И. Численные методы и программные средства опти-
мизацииуправляемыхсистем.Новосибирск:Наука, 1992.
[82] ТятюшкинА.И.Алгоритмпоискаоптимальногоуправлениявзадаче
линейного быстродействия // Алгоритмы и программы решения
задач линейной алгебры и математического программирования. Ир-
кутск:ИздательствоИркутскогогос.университета. 1979.С. 115–128.
[83] Федоренко Р.П. К обоснованию метода вариаций в фазовом про-
странстве для численного решения задач оптимального управления
// Журнал вычислительной математики и математической физики.
1969.Т. 9.№ 6. C. 1396–1402.
Электронныйжурнал.  120Дифференциальные уравнения и процессы управления, N. 1, 2004
[84] Федоренко Р.П. Приближенное решение задач оптимального управ-
ления.М.:Наука, 1978.
[85] Черноусько Ф.Л., Баничук Н.В. Вариационные задачи механики и
управления.Численныеметоды.М.:Наука, 1973.
[86] Черноусько Ф.Л., Колмановский В.Б. Вычислительные и прибли-
женныеметодыоптимальногоуправления //Итогинаукиитехники.
Математическийанализ. 1977.Т. 14.С. 101–166.
[87] Шатровский Л.И. Об одном численном методе решения задачи
оптимального управления // Журнал вычислительной математики
иматематическойфизики. 1962.Т. 2.№ 3.С. 488–490.
[88] Шевченко Г.В. Алгоритмы решения некоторых задач оптимального
управления для линейных систем // Новосибирск, 1990. 29 c. (Пре-
принт /РАН.СибирскоеотделениеИнститутматематики;№ 11).
[89] ШевченкоГ.В.Численныйалгоритмрешениялинейнойзадачиопти-
мального быcтродействия и его модификация // Новосибирск, 2002.
27с. (Препринт /РАН.Сибирскоеотделение Институтматематики;
№ 93).
[90] ШевченкоГ.В.Численныйалгоритмрешениялинейнойзадачиопти-
мальногобыcтродействия //Журналвычислительнойматематикии
математическойфизики. 2002.Т. 42.№ 8.С. 1184–1196.
[91] Шевченко Г.В. Линейная задача оптимального управления с выпук-
лым однородным функционалом // Фундаментальная и прикладная
математика. 1999.Т. 5.№ 3.С. 757–763.
[92] Энеев Т.М. О применении градиентного метода в задачах опти-
мального управления // Космические исследования. 1966. Т. 4. № 5.
С. 651–669.
[93] Allgower E., Georg K. Simplicial and continuation methods for
approximating Fixed Points and Solutions to systems of equations //
SIAM Review. 1980. V. 22.ь 1. P. 28–85.
[94] Allgower E., Georg K. Numerical Continuation Methods. Introduction.
New York, Berlin: Springer Verlag, 1990.
[95] Balakrishnan A.V. On a new computing technique in optimal control //
SIAM J. Control. 1968. V. 6.№ 2. P. 149–173.
[96] R.O. Barr. An eﬃcient computational procedure for a generalized
quadratic programming problem // SIAM J. Control. 1969. V. 7. № 3.
P. 415–429.
Электронныйжурнал.  121Дифференциальные уравнения и процессы управления, N. 1, 2004
[97] Bulirsch, R. Miele, A. Stoer, J. Well, K.H. Optimal Control. Calculus
of variations, optimal control theory and numerical methods //
ISNM. International Series of Numerical Mathematics. V. III. Basel:
Birkhaeuser, 1993.
[98] Caetano M.A.L., Yoneyama T. New iterative method to solve optimal
control problems with terminal constraints // J. Guad. Control Dyn.
1996. V. 19.№ 1. P. 262–264.
[99] Dennis J.E., Mor´ e Jr. & Jorge J. Quasi-Newton Methods, Motivation
and Theory // SIAM Review. 1977. V. 19.ь 1. P. 46–89.
[100] Eaves B.C. Computing Kakutani Fixed Points // SIAM J. Appl. Math.
1971. V. 21.№ 2. P. 236–244.
[101] Eaves B.C. Homotopies for Computation of Fixed Points // Math. Prog.
1972. V. 3.№ 1. P. 1–22.
[102] Eaves B.C., Saigal R. Homotopies for Computation of Fixed Points on
Unbounded Regions // Math. Prog. 1972. V. 3.№ 2. P. 225–237.
[103] Gay D.M., Schnabel R.B. Solving Systems of Nonlinear Equations by
Broyden’s Method with Projected Updates // Nonlinear Prog. 1978.
№ 3. P. 245–281.
[104] E.G. Gilbert. An iterative procedure for computing the minimum of a
quadratic form on a convex set // SIAM J. Control. 1966. V. 4. № 1.
P. 61–80.
[105] Hestenes M. R. Multiplier and gradient methods // J. Optimization
Theory Appl. 1969. V. 4.№ 5. P. 303–320.
[106] Hohenbalken B. A ﬁnite algorithm to maximize certain pseudoconcave
functions on polytopes // Math. Prog. 1975. V. 9. P. 189–206.
[107] Laan G., Talman A.J.J. Simplicial Fixed Point Algorithms. Amsterdam:
Mathematical Centre, 1980.
[108] Mangasarian O.L. Nonlinear programming. McGraw-Hill, New York,
1969.
[109] Meyer G.L. Accelerated Frank-Wolfe Algorithms // SIAM J. Control.
1974. V. 12.№ 4. P. 655–663.
[110] Pecsvaradi T., Kumpati S. Narendra. A new iterative procedure for the
minimization of a quadratic form on a convex set // SIAM J. Control.
1970. V. 8.№ 3. P. 396–402.
Электронныйжурнал.  122Дифференциальные уравнения и процессы управления, N. 1, 2004
[111] Polak E. An historical survey of computational methods in optimal
control // SIAM Review. 1973. V. 15.№ 2. P. 553–584.
[112] Rockafellar R. T. Augmented Lagrange multiplier functions and duality
in nonconvex programming // SIAM J. Control. 1974. V. 12. № 2.
P. 268–285.
[113] Saigal R. On The Convergence Rate of Algorithms for Solving Equations
that are Based on Methods of Complementary Pivoting // Math. Oper.
Res. 1977.№ 2. P. 108–124.
[114] Saigal R., Todd M.J. Eﬃcient Acclleration Techniques for Fixed Point
Algorithms // SIAM J. Num. An. 1978.№ 15. P. 997–1007.
[115] Scarf H. The Approximation of Fixed Points of a Continuous Mapping
// SIAM J. Appl. Math. 1967. V. 15.№ 5. P. 1328–1343.
[116] Seywald H., Kumar R. R. Some recent developments in computational
optimal control // IMA Vol. Math. Appl. 1997. V. 93. P. 203–233.
[117] Todd M.J. Improving the Convergence of Fixed Point Algorithms //
Complementarity and Fixed Point problems / Balinski M.L., Cottle
R.W. Math. Prog. Study. 1978.№ 7.
[118] Yamashita, Y., Shima, M. Numerical computational method using
generalized algorithm for optimal control problem with terminal
constraints and free parameters // J. Nonlinear Anal., Theory Methods
Appl. V. 30.№ 4. 1997. P. 2285–2290.
Электронныйжурнал.  123
