    
    
6
 
-
?
ДИФФЕРЕНЦИАЛЬНЫЕ УРАВНЕНИЯ
И
ПРОЦЕССЫ УПРАВЛЕНИЯ
N. 1, 2023
Электронный журнал,
рег. Эл. N ФС77-39410 от 15.04.2010
ISSN 1817-2172
http://diffjournal.spbu.ru/
e-mail: jodiff@mail.ru
Управление в сложных системах
Сетевое управление с итеративным обучением при изменении
режима работы агентов и конфигурации информационной
структуры
Копосов А.С.
Арзамасский политехнический институт (филиал) Нижегородского
государственного технического университета им. Р.Е. Алексеева
koposov96@yandex.ru
Аннотация. Рассматривается задача синтеза управления с итеративным
обучением (УИО) сетевой системой при изменении режима работы подси-
стем (агентов) и конфигурации информационной структуры. Сетевая систе-
ма состоит из одинаковых агентов, которые представляют собой дискретные
линейные динамические объекты, работающие в повторяющемся режиме. Ре-
жимы работы агентов зависят от их параметров и желаемой траектории, ко-
торая должна воспроизводиться с требуемой точностью на выходе системы.
Конфигурацииинформационнойсетиопределяютгруппуфункционирующих
агентов и характер обмена информацией между ними. Переключения режи-
ма и конфигурации происходят в соответствии с определенными внешними
правилами. Синтез управления основан на дивергентном методе векторной
функции Ляпунова. С целью уменьшения переходной ошибки, вызываемой
изменениемрежимаиподключениемновыхагентов,предложеноспециальное
правило переключения закона УИО. Приводятся результаты моделирования
сетевой системы, состоящей из одинаковых манипуляторов с гибким звеном,
управление которой осуществляется согласно полученному закону.
Ключевые слова: сетевое управление, управление с итеративным обучени-
ем,системыспереключениями,изменяемаяжелаемаятраектория,векторнаяДифференциальные уравнения и процессы управления,N. 1, 2023
функция Ляпунова.
1 Введение
Методуправленияситеративнымобучением(УИО)привлеквниманиеиссле-
дователейразличныхобластейпослепубликацииработы[1],датируемой1984
годом, и с тех пор активно развивается, находя новые области практического
применения. Он ориентирован на системы, которые многократно повторяют
одну и ту же операцию конечной продолжительности, возвращаясь в исход-
нуюпозициюпослекаждогоповторениятак,чтоначальныеусловияостаются
одинаковыми на всех повторениях. Предполагается, что система должна вос-
производить желаемую траекторию с заданной точностью. Отличительная
особенность УИО состоит в том, что на каждом повторении учитывается ин-
формация, полученная ранее в результате выполнения операции, за счет чего
удается последовательно улучшать точность или какой-либо другой показа-
тель. Таким образом, УИО по сути реализует простейший механизм обучения
для данного класса систем, аналогичный, например, возникающему при тре-
нировках баскетболиста, который пытается выполнить точный бросок мяча
в корзину с заданной позиции. Подобные механизмы в биологии называют
выработкой мышечной памяти. В соответствии со сказанным, УИО можно
классифицировать как одно из направлений интеллектуального управления.
Подробнее с методами интеллектуального управления и УИО в частности
можно ознакомиться в обзорных статьях [2, 3, 4].
МетодУИОэффективноприменяетсякразличнымклассамсистем,одна-
ко не во всех случаях он позволяет сохранить высокую точность выполнения
операции на всем протяжении работы системы. Во время ее функционирова-
ния может возникнуть необходимость изменить целевую задачу, что порож-
дает переходную ошибку, которая часто снижает точность ниже допустимого
уровня в течение нескольких повторений.
В частности, такой эффект появляется при изменении желаемой траекто-
рии, что характерно для гибких интеллектуальных производств. В работе [5]
рассматривается задача УИО системой, работа которой может происходить
в двух режимах, которые отличаются желаемой траекторией и параметрами
системы. Кроме того, система подвержена внешним возмущениям, ее выход-
ной сигнал измеряется с шумами, а режим работы изменяется в соответствии
с заданным внешним правилом. Предложенный метод синтеза УИО основан
на дивергентном методе векторной функции Ляпунова в сочетании с филь-
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 36Дифференциальные уравнения и процессы управления,N. 1, 2023
тром Калмана. Дополнительно, с целью уменьшения величины переходной
ошибки, вводится специальное правило переключения закона УИО. Компен-
сирующий переходную ошибку закон управления находится из решения за-
дачи минимизации среднеквадратической ошибки и используется только на
повторении, на котором происходит переключение режима. В [6] данные ре-
зультаты распространяются на случай системы в виде группы одинаковых
объектов (агентов), связанных между собой информационной сетью.
В работе [7] была рассмотрена задача сетевого УИО при изменении кон-
фигурацииинформационнойструктуры,гдеростошибкивозникаетвмомент
подключения новых агентов. В этом случае новым агентам в момент их под-
ключения предлагается передавать управляющие сигналы от тех агентов, к
которым они подключаются.
В данной работе рассматривается сетевая система, в которой во время
ее функционирования может изменяться как желаемая траектория выход-
ного сигнала, так и конфигурация информационной структуры. В основу
предложенного решения был положен подход, рассмотренный в [5], который
дополнительно получил развитие на случай подключения новых агентов.
2 Постановка задачи
Рассмотрим систему из    линейных подсистем (агентов), повторяющих опе-
рацию, одинаково определенную для всех агентов, и связанных между собой
информационной сетью переменной конфигурации. Динамика агента    опи-
сывается следующей дискретной моделью в пространстве состояний:
  
  
(  ,   + 1) =  
     
(  )
  
  
(  ,  ) +  
     
(  )
  
  
(  ,  ),
  
  
(  ,  ) =    
  
(  ,  ),  ∈ℐ
   (  )
,  ≥ 0, 0≤   ≤   − 1,
(1)
где   
  
(  ,  )∈ R
  
  
– вектор состояния,   
  
(  ,  )∈ R
  
  
– вектор управления,
  
  
(  ,  )∈R
  
  
– вектор выходных переменных (профиль повторения),    <∞
–продолжительностьповторения,одинаковаядлявсех  .Граничныеусловия
  
  
(  , 0) и   
  
(0,  ) будем считать известными.
Сигнал      
(  ), переключающий режим работы агента   , представляет со-
бой кусочно-постоянную функцию, отображающую Z
+
в{1,...,  } (где   
– количество режимов), точки разрыва которой будем называть момента-
ми переключения режима. Каждый режим определяет желаемую траекто-
рию выходного сигнала   
      
     
(  )
(  ) и матрицы   
     
(  )
∈{  
1
,...,  
  
} и   
     
(  )
∈
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 37Дифференциальные уравнения и процессы управления,N. 1, 2023
{  
1
,...,  
  
} агентов, при этом тройки (  
     
(  )
,  
     
(  )
,  ) полностью управля-
емы и наблюдаемы, а матрицы     
     
(  )
невырожденные.
Сигнал    (  ), переключающий конфигурацию сети, представляет собой
кусочно-постоянную функцию, отображающуюZ
+
в{1,...,  } (где    – коли-
чество конфигураций), точки разрыва которой будем называть моментами
переключения конфигурации. Каждая конфигурация определяет множество
функционирующих агентов, которое представляется в виде набора их номе-
ровℐ
   (  )
={  
  
}
  
   (  )
  =1
, где   
   (  )
– количество агентов в конфигурации    (  ),
  
  
∈{1,...,  }, а также связи между ними, которые представляются в виде
направленного графа  
   (  )
= (ℐ
   (  )
,ℰ
   (  )
), гдеℰ
   (  )
⊆ℐ
   (  )
×ℐ
   (  )
– ребра гра-
фа. Возможность доступа агента    к выходным данным агента    (  ,  ∈ℐ
   (  )
)
задается ребром, направленным от вершины    к вершине    и обозначается
упорядоченной парой (  ,  )∈ℰ
   (  )
. Элементы матрицы смежности
  
   (  
   ) =
⎡
⎢
⎢
⎢
⎢
⎣
  
  
1
  
1
  
  
1
  
2
...   
  
1
  
       
  
2
  
1
  
  
2
  
2
...   
  
2
  
     .
.
.
.
.
.
.
.
.
.
.
.
  
  
       
1
  
  
       
2
...   
  
       
     ⎤
⎥
⎥
⎥
⎥
⎦
, (2)
где    =   (  ), задаются следующим образом:   
    
> 0, если (  ,  )∈ℰ
   (  )
,   
    
= 0
в противном случае,   
    
= 0. Матрица Лапласа графа  
   (  )
задается выраже-
нием
ℒ
   (  
   ) =
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
∑︀
  ∈ℐ
     
  
1
  
−   
  
1
  
2
... −   
  
1
  
     −   
  
2
  
1
∑︀
  ∈ℐ
     
  
2
  
... −   
  
2
  
     .
.
.
.
.
.
.
.
.
.
.
.
−   
  
       
1
−   
  
       
2
...
∑︀
  ∈ℐ
     
  
       
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, (3)
где    =   (  ).
Введем ошибку обучения
  
  
(  ,  ) =  
      
     
(  )
(  )−   
  
(  ,  ). (4)
Задача заключается в поиске такого управления (протокола)   
  
(  ,  ), при
котором норма ошибки убывает не медленнее некоторой геометрической про-
грессии, т. е. с увеличением числа повторений
|  
  
(  ,  )|≤        
,  ≥ 0, 0≤   ≤   − 1,  > 0, 0<  < 1, (5)
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 38Дифференциальные уравнения и процессы управления,N. 1, 2023
при этом
lim
  →∞
|  
  
(  ,  )| = 0, lim
  →∞
|  
  
(  ,  )| =|  
  
(∞,  )|,  ≥ 0, (6)
где   
  
(∞,  ) ограничено по норме и обычно называется обученным управле-
нием.
Будем учитывать, что непосредственный доступ к   
      
     
(  )
(  ) могут иметь
только некоторые агенты, которых далее будем называть глобальными лиде-
рами.Возможностьполученияагентамиинформацииожелаемойтраектории
выходного сигнала задается матрицейℛ
   (  )
= diag[  
  
  
]
  
   (  )
  =1
, где   
  
= 1, если
агент    имеет доступ к   
      
     
(  )
(  ), и   
  
= 0 в противном случае.
Агент,которыйнеявляетсяглобальнымлидером,можетполучитьинфор-
мацию либо от глобального лидера, либо от любого другого агента, которого
будем называть локальным лидером. Принимающий информацию агент яв-
ляется ведомой системой, и предполагается, что он не может передать свои
данные своему локальному лидеру.
3 Решение задачи
3.1 Управление при заданном режиме работы агентов и конфи-
гурации сети
В начале рассмотрим случай, когда режим работы агентов и конфигурация
сети установлены, т. е. рассмотрим интервал вдоль повторений, на котором
сигналы      
(  ) и    (  ) не имеют точек разрыва и их значения равны для всех
   и   . В связи с этим в рамках данного подраздела для краткости обозначим
     
(  ) и    (  ) как    и    соответственно.
В данном случае для закона УИО
  
  
(   + 1,  − 1) =  
  
(  ,  − 1) + Δ  
  
(   + 1,  − 1) (7)
корректирующую добавку Δ  
  
(   + 1,  − 1) будем формировать в виде
Δ  
  
(   + 1,  − 1) =  
1     (  
  
(   + 1,  − 1)−   
  
(  ,  − 1))
+  
2     ⎛
⎝
∑︁
  ∈  
    
  
    
(  
  
(  ,  )−   
  
(  ,  )) +  
  
  
  
(  ,  )
⎞
⎠
, (8)
где   
1     и   
2     – матрицы протокола в режиме    и конфигурации    ,
  
    
={  ∈ℐ
  |(  ,  )∈ℰ
  } – множество агентов, информация о которых до-
ступна агенту    в конфигурации    .
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 39Дифференциальные уравнения и процессы управления,N. 1, 2023
Введем вектор приращения состояния
     
(   + 1,   + 1) =  
  
(   + 1,  )−   
  
(  ,  ) (9)
и запишем систему (1) в терминах приращения (9) и ошибки обучения (4):
     
(   + 1,   + 1) =  
        
(   + 1,  ) +  
   Δ  
  
(   + 1,  − 1),
  
  
(   + 1,  ) =−     
        
(   + 1,  ) +  
  
(  ,  )−     
   Δ  
  
(   + 1,  − 1).
(10)
Введем расширенные векторы приращения состояния и ошибки обучения
     
(  ,  ) =
⎡
⎢
⎣
   1
(  ,  )
.
.
.
     
   (  ,  )
⎤
⎥
⎦
,  (  ,  ) =
⎡
⎢
⎣
  
1
(  ,  )
.
.
.
  
  
   (  ,  )
⎤
⎥
⎦
,
и запишем расширенную систему относительно (10) с учетом (8):
   (   + 1,   + 1) =
(︀ ¯
  
11     +
¯
  
1     ¯
  
1     ¯
ℋ
1   )︀    (   + 1,  )
+
(︀ ¯
  
12     +
¯
  
1     ¯
  
2     ¯
ℋ
2   )︀   (  ,  ),
  (   + 1,  ) =
(︀ ¯
  
21     +
¯
  
2     ¯
  
1     ¯
ℋ
1   )︀    (   + 1,  )
+
(︀ ¯
  
22     +
¯
  
2     ¯
  
2     ¯
ℋ
2   )︀   (  ,  ),
(11)
где
¯
  
11     =  
  
   ⊗   
   ,
¯
  
12     = 0,
¯
  
21     =  
  
   ⊗ (−     
   ),
¯
  
22     =  
  
   ⊗   
  
  
,
¯
  
1     =  
  
   ⊗   
   ,
¯
  
2     =  
  
   ⊗ (−     
   ),
¯
  
1     =  
  
   ⊗   
1     ,
¯
  
2     =  
  
   ⊗   
2     ,
¯
ℋ
1   =  
  
   ⊗ℋ
1
,
ℋ
1
=  
  
  
,
¯
ℋ
2   = (ℒ
   +ℛ
   )⊗ℋ
2
,ℋ
2
=  
  
  
.
Система (11) записана в стандартной форме повторяющегося процесса и
дальнейший анализ будет основываться на теории устойчивости повторяю-
щихся процессов с переключениями [8].
Введем векторную функцию Ляпунова
  
     (   (   + 1,  ),  (  ,  )) =
[︃
  
1     (   (   + 1,  ))
  
2     (  (  ,  ))
]︃
, (12)
где  
1     (   (  +1,  ))> 0,   (  +1,  )̸= 0,  
2     (  (  ,  ))> 0,  (  ,  )̸= 0,  
1     (0) =
0,   
2     (0) = 0, и дискретный аналог ее дивергенции
    
     (   (   + 1,  ),  (  ,  )) =  
1     (   (   + 1,   + 1))−   
1     (   (   + 1,  ))
+  
2     (  (   + 1,  ))−   
2     (  (  ,  )).
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 40Дифференциальные уравнения и процессы управления,N. 1, 2023
Теорема 1. Пусть существует векторная функция Ляпунова (12) и поло-
жительные скаляры   
1
,   
2
,   
3
и    такие, что
  
1
|   (   + 1,  )|
2
≤   
1     (   (   + 1,  ))≤   
2
|   (   + 1,  )|
2
,
  
1
|  (  ,  )|
2
≤   
2     (  (  ,  ))≤   
2
|  (  ,  )|
2
,
    
     (   (   + 1,  ),  (  ,  ))≤    −   
3
(|   (   + 1,  )|
2
+|  (  ,  )|
2
).
Тогда закон управления (7) с корректирующей добавкой (8) обеспечивает
условия сходимости (5)-(6).
Доказательство с незначительными изменениями повторяет доказатель-
ство теоремы 1 из [8] и поэтому не приводится.
ВыберемкомпонентывекторнойфункцииЛяпуноваввидеквадратичных
форм:
  
1     (   (   + 1,  )) =   ⊤
(   + 1,  )
¯
  
1        (   + 1,  ),
  
2     (  (  ,  )) =  
⊤
(  ,  )
¯
  
2       (  ,  ),
где
¯
  
1     =  
  
   ⊗   
1     и
¯
  
2     =  
  
   ⊗   
2     .
Вычисляя аналог дивергенции векторной функции Ляпунова, получим
    
     (   (   + 1,  ),  (  ,  ))
=
[︃
   (   + 1,  )
  (  ,  )
]︃
⊤
((
¯
  
     +
¯
  
     ¯
  
     ¯
ℋ
   )
⊤
¯
  
     (
¯
  
     +
¯
  
     ¯
  
     ¯
ℋ
   )
− ¯
  
     )
[︃
   (   + 1,  )
  (  ,  )
]︃
,
где
¯
  
     =
[︃
¯
  
11     ¯
  
12     ¯
  
21     ¯
  
22     ]︃
,
¯
  
     =
[︃
¯
  
1     ¯
  
2     ]︃
,
¯
  
     =
[︁
¯
  
1     ¯
  
2     ]︁
,
¯
ℋ
   =
[︃
¯
ℋ
1   0
0
¯
ℋ
2   ]︃
,
¯
  
     =
[︃
¯
  
1     0
0
¯
  
2     ]︃
.
Потребуем выполнение следующих матричных неравенств:
(
¯
  
     +
¯
  
     ¯
  
     ¯
ℋ
   )
⊤
¯
  
     (
¯
  
     +
¯
  
     ¯
  
     ¯
ℋ
   )− ¯
  
     +
¯
  
   + (
¯
  
     ¯
ℋ
   )
⊤
¯
  
   ¯
  
     ¯
ℋ
   4 0,
¯
  
     ≻ 0, (13)
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 41Дифференциальные уравнения и процессы управления,N. 1, 2023
где
¯
  
   и
¯
  
   – весовые матрицы, которые имеют вид
¯
  
   = diag
[︁
¯
  
1   ¯
  
2   ]︁
,
¯
  
1   =  
  
   ⊗   
1   ,
¯
  
2   =  
  
   ⊗   
2   ,
¯
  
   =  
  
   ⊗   
   .
Используя лемму Шура о дополнении, сведем неравенства (13) к следу-
ющей системе матричных уравнений и неравенств:
⎡
⎢
⎢
⎢
⎢
⎣
¯
  
     (
¯
  
     ¯
  
     +
¯
  
     ¯
  
     ¯
ℋ
   )
⊤
¯
  
     (
¯
  
     ¯
ℋ
   )
⊤
¯
  
     ¯
  
     +
¯
  
     ¯
  
     ¯
ℋ
   ¯
  
     0 0
¯
  
     0
¯
  
− 1
   0
¯
  
     ¯
ℋ
   0 0
¯
  
− 1
   ⎤
⎥
⎥
⎥
⎥
⎦
< 0,
¯
  
  
¯
ℋ
   =
¯
ℋ
   ¯
  
  
,
¯
  
  
≻ 0,
(14)
где
¯
  
     = diag
[︁
¯
  
1     ¯
  
2     ]︁
=
¯
  
− 1
     ,
¯
  
1     =  
  
   ⊗   
1     ,
¯
  
2     =  
  
   ⊗   
2     ,
¯
  
     = diag
[︁
¯
  
1     ¯
  
2     ]︁
,
¯
  
1     =  
  
   ⊗   
1     ,
¯
  
2     =  
  
   ⊗   
2     ,
¯
  
     =
[︁
¯
  
1     ¯
  
2     ]︁
=
¯
  
     ¯
  
     ,
¯
  
1     =  
  
   ⊗   
1     ,
¯
  
2     =  
  
   ⊗   
2     .
Таким образом, в рассмотренном случае закон УИО (7) с корректирую-
щей добавкой (8) и матрицами протокола   
1     =  
1       
− 1
1     и   
2     =  
2       
− 1
2     ,
где   
1     ,   
2     ,   
1     и   
2     находятся из решения системы (14), обеспечивает
выполнение условий сходимости (5)-(6) и, следовательно, сходимость выход-
ного сигнала к желаемой траектории.
3.2 Управление в момент переключения режима работы агентов
Рассмотрим случай, когда происходит переключение режима работы аген-
тов. В этот момент ошибка обучения может выйти за допустимый предел,
поэтому закон управления должен быть разработан таким образом, чтобы
исключить этот нежелательный эффект в максимально возможной степени.
В рамках данного подраздела сигнал, переключающий конфигурацию сети,
для краткости обозначим за    подразумевая, что он одинаков на всех рас-
сматриваемых повторениях.
В данном случае закон управления можно найти, решая задачу миними-
зации отклонения выходного сигнала агента от доступного ему образа же-
лаемой траектории. Для глобального лидера эта задача сводится к задаче
минимизации ошибки обучения, поскольку таким агентам непосредственно
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 42Дифференциальные уравнения и процессы управления,N. 1, 2023
доступна информация о желаемой траектории. Как и в разделе 3.1, в ка-
честве образа желаемой траектории для ведомой системы будет выступать
взвешенная сумма выходных сигналов ее локальных лидеров. Поскольку ло-
кальные лидеры передают данные с предыдущего повторения, переключение
ведомой системы должно происходить с некоторой задержкой после пере-
ключения ее локальных лидеров, чтобы информация о желаемой траектории
соответствовала новому режиму.
По аналогии с сигналом      
(  ), который теперь будем именовать локаль-
ным сигналом, переключающим режим, введем глобальный сигнал    (  ), ко-
торый запускает процесс переключения режимов агентов. Моменты пере-
ключения      
(  ) глобальных лидеров совпадают с моментами переключения
   (  ), т. е.      
(  ) =    (  )∀   :   
  
= 1. Для ведомых систем локальный сигнал
     
(  ) =     
(  − 1)∀  ∈  
    
.
Найдем закон управления для глобальных лидеров. Пусть    + 1 – один
из моментов переключения глобального лидера   . Записав ошибку обучения
в виде
  
  
(   + 1,  ) =  
      
     
(  +1)
(  )
−   
  
(  ,  )−   (  
     
(  +1)
  
  
(   + 1,  − 1)−   
     
(  )
  
  
(  ,  − 1))
−   (  
     
(  +1)
−   
     
(  )
)  
  
(  ,  − 1)−     
     
(  +1)
Δ  
  
(   + 1,  − 1),
и решая задачу ее минимизации, получим следующую корректирующую до-
бавку для закона (7):
Δ  
  
(   + 1,  − 1) = (    
     
(  +1)
)
− 1
(  
      
     
(  +1)
(  )−   
  
(  ,  ))
− (    
     
(  +1)
)
− 1
  (  
     
(  +1)
  
  
(   + 1,  − 1)−   
     
(  )
  
  
(  ,  − 1))
− (    
     
(  +1)
)
− 1
  (  
     
(  +1)
−   
     
(  )
)  
  
(  ,  − 1). (15)
Теперь найдем закон управления для ведомых систем. Пусть    +1 – один
из моментов переключения ведомой системы   . Введем отклонение ее выход-
ного сигнала от выходных сигналов ее локальных лидеров
  
  
(   + 1,  ) =
∑︁
  ∈  
    
  
    
(  
  
(  ,  )−   
  
(   + 1,  )), (16)
где   
    
– элемент матрицы (2).
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 43Дифференциальные уравнения и процессы управления,N. 1, 2023
Переписав (16) в виде
  
  
(   + 1,  ) =
∑︁
  ∈  
    
  
    
(  
  
(  ,  )−   
  
(  ,  ))
−   
    
  (  
     
(  +1)
  
  
(   + 1,  − 1)−   
     
(  )
  
  
(  ,  − 1))
−   
    
  (  
     
(  +1)
−   
     
(  )
)  
  
(  ,  − 1)
−   
    
    
     
(  +1)
Δ  
  
(   + 1,  − 1),
где   
    
– элемент матрицы (3), и решая задачу ее минимизации, получим сле-
дующую корректирующую добавку для закона (7):
Δ  
  
(   + 1,  − 1) =  
− 1
    
(    
     
(  +1)
)
− 1
∑︁
  ∈  
    
  
    
(  
  
(  ,  )−   
  
(  ,  ))
− (    
     
(  +1)
)
− 1
  (  
     
(  +1)
  
  
(   + 1,  − 1)−   
     
(  )
  
  
(  ,  − 1))
− (    
     
(  +1)
)
− 1
  (  
     
(  +1)
−   
     
(  )
)  
  
(  ,  − 1). (17)
Таким образом, в момент переключения режима будем применять закон
УИО (7) с корректирующей добавкой (15) для глобального лидера, и с кор-
ректирующей добавкой (17) для ведомой системы.
3.3 Управление в момент переключения конфигурации сети
Последний случай, который необходимо рассмотреть, это случай, когда про-
исходит переключение конфигурации. Допустим, что все агенты работают
в одном и том же режиме на всех рассматриваемых в данном случае по-
вторениях, поэтому в рамках данного подраздела для краткости сигналы,
переключающие режимы, обозначим за    .
В момент переключения конфигурации агент может выполнить одно из
следующих действий: подключение к сети, отключение от сети и смена ло-
кальных лидеров (для ведомых систем). Во втором и третьем случаях управ-
ление всеми агентами производится согласно закону УИО (7) с корректиру-
ющей добавкой (8) с матрицами протокола, соответствующими новой кон-
фигурации. В первом случае ошибка подключаемого агента при использо-
вании этого закона может превышать допустимый предел первые несколько
повторений после подключения. Для предотвращения этого эффекта найдем
управление для подключаемого к сети агента, решая задачу минимизации от-
клонения выходного сигнала от выходных сигналов его локальных лидеров.
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 44Дифференциальные уравнения и процессы управления,N. 1, 2023
Пусть  +1–моментпереключенияконфигурациисподключениемагента
  . Переписав (16) в виде
  
  
(   + 1,  ) =
∑︁
  ∈  
   (  +1)  
  
    
  
  
(  ,  )
−   
    
    
     
  
(   + 1,  − 1)−   
    
    
     
  
(   + 1,  − 1),
где   
    
– элемент матрицы  
   (  +1)
, а   
    
– элемент матрицыℒ
   (  +1)
, решени-
ем задачи минимизации отклонения будет следующий закон управления для
подключаемой системы:
  
  
(   + 1,  − 1) =  
− 1
    
(    
   )
− 1
∑︁
  ∈  
   (  +1)  
  
    
  
  
(  ,  )
− (    
   )
− 1
    
     
  
(   + 1,  − 1). (18)
3.4 Общий закон управления
Объединим полученные результаты в виде следующих правил переключения
режима работы агентов, конфигурации сети и закона управления.
Переключения инициируются сигналами    (  ) и    (  ). Сигнал    (  ), име-
нуемый глобальным сигналом, переключающим режим, запускает процесс
переключения режимов агентов. Переключение режима глобальных лидеров
происходит в момент запуска процесса переключения глобальным сигналом,
т. е.      
(  ) =    (  )∀   :   
  
= 1. Переключение остальных агентов происхо-
дит с запаздыванием в одно повторение после переключения их локальных
лидеров, т. е.      
(  ) =      
(  − 1)∀  ∈   
   (  )  
. Сигнал    (  ) переключает конфи-
гурацию сети.
Управляющий сигнал на повторении    + 1 формируется в виде (7) с кор-
ректирующей добавкой (8), матрицы протокола которой находятся из реше-
ния системы (14), если      
(   + 1) =     
(  ) и   ∈ℐ
   (  )
, с корректирующей добав-
кой (15), если   
  
= 1,      
(   + 1)̸=     
(  ) и   ∈ℐ
   (  )
, и добавкой (17) если   
  
= 0,
     
(   + 1)̸=     
(  ) и   ∈ℐ
   (  )
, где   
  
– элемент матрицыℛ
   (  +1)
. Если    / ∈ℐ
   (  )
,
то управляющий сигнал на повторении    +1 формируется в виде (18). Таким
образом, поскольку условия (5) и (6) выполняются на фиксированных желае-
мых траекториях, параметрах и конфигурациях сети, а в моменты изменения
режима и конфигурации переменные в силу уравнений (11) ограничены, эти
условия будут выполняться всюду.
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 45Дифференциальные уравнения и процессы управления,N. 1, 2023
Такой подход позволит значительно снизить величину ошибки в момен-
ты переключения режима и подключения новых агентов, однако он накла-
дывает некоторые ограничения на конфигурацию сети. В данном случае ло-
кальные лидеры ведомой системы должны переключаться одновременно, что
исключает возможность взаимного обмена информацией между агентами и
реализации замкнутой информационной сети. В случае применения данного
алгоритмаксетиспоследовательнымсоединениемагентов,процесспереклю-
чения может занять недопустимо длительное время.
4 Пример
Было проведено моделирование сетевой системы, состоящей из одинаковых
манипуляторов с поворотным гибким звеном, управление которой происхо-
дит согласно полученному закону. Каждый манипулятор представляет собой
гибкое звено, закрепленное одним концом на двигателе постоянного тока, ко-
торый вращает звено из одного конца в другой в горизонтальной плоскости.
Отклонение другого конца звена определяется тензодатчиком и выводится в
виде аналогового сигнала, пропорционального отклонению. Динамика дви-
жения каждого манипулятора описывается следующими уравнениями:
¨
   (  ) =−   
    
  
    
˙
   (  ) +
  
  
  
    
   (  ) +
1
  
    
   (  ),
¨    (  ) =
  
    
  
    
˙
   (  )−   
  
(︂   
  
+  
    
  
    
  
  
)︂    (  )− 1
  
    
   (  ),
где    (  ) – угол поворота сервопривода,    (  ) – угол отклонения звена,    (  ) –
крутящий момент на силовом редукторе сервопривода, приводящем звено в
движение,   
  
– жесткость звена,   
    
– момент инерции сервопривода,   
    
–
коэффициент вязкого трения сервопривода,   
  
– момент инерции звена отно-
сительно центра масс.
Определив векторы состояния, управления и выходных переменных как
   = [      ˙
   ˙    ]
⊤
,   =   и   =   соответственно,перепишемданныеуравнения
в виде модели в пространстве состояний с непрерывным временем:
˙   
  
(  ,  ) =  
        
     
(  )
  
  
(  ,  ) +  
        
  
  
(  ,  ),
  
  
(  ,  ) =    
  
(  ,  ),
(19)
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 46Дифференциальные уравнения и процессы управления,N. 1, 2023
где
  
        
     
(  )
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0 0 1 0
0 0 0 1
0
  
  
  
    
−   
    
  
    
0
0 −   
  
(︂   
  
(     
(  )) +  
    
  
    
  
  
(     
(  ))
)︂   
    
  
    
0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
,  
        
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0
0
1
  
    
− 1
  
    
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
,
   =
[︁
1 0 0 0
]︁
.
Были приняты следующие параметры манипуляторов с гибким звеном
[9]:   
  
= 1, 3 Н· м/рад,   
    
= 2, 08× 10
− 3
кг· м
2
,   
    
= 0, 004 Н· м/(рад/с). Ди-
намика агентов определяется двумя режимами, в каждом из которых задана
своя желаемая траектория:
  
      
     
(  )
(  ) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
   (︂   
2
6
−   
3
27
)︂ ,      
(  ) = 1,
   2
sin
    
6
,      
(  ) = 2.
Приизменениижелаемойтраекторииодновременноизменяетсямоментинер-
ции звена:
  
  
(     
(  )) =
{︃
0, 0038 кг· м
2
,      
(  ) = 1,
0, 008 кг· м
2
,      
(  ) = 2.
Продолжительность повторения составляет 3 с.
Дискретизация по времени динамики (19) дает модель в пространстве
состояний (1) для проектирования управления с   
     
(  )
= exp(  
        
     
(  )
  
  
) и
  
     
(  )
=
∫︀
  
  
0
exp (  
        
     
(  )
   )  
        
     , где   
  
– период дискретизации, который в
данном случае выберем равным 0,01 c.
Рассмотрим сетевую систему из трех манипуляторов данного типа, среди
которых выделен один глобальный лидер. На первой конфигурации работает
только глобальный лидер, на второй к глобальному лидеру подключаются
первая ведомая система, и на третьей к первой ведомой системе подключает-
ся вторая. Данные конфигурации определяются следующими множествами
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 47Дифференциальные уравнения и процессы управления,N. 1, 2023
функционирующих агентов и матрицами связей:
ℐ
1
={1},ℒ
1
= 0,ℛ
1
= 1,
ℐ
2
={1, 2},ℒ
2
=
[︃
0 0
− 1 1
]︃
,ℛ
2
=
[︃
1 0
0 0
]︃
,
ℐ
3
={1, 2, 3},ℒ
3
=
⎡
⎢
⎣
0 0 0
− 1 1 0
0 − 1 1
⎤
⎥
⎦
,ℛ
3
=
⎡
⎢
⎣
1 0 0
0 0 0
0 0 0
⎤
⎥
⎦
.
(20)
Решая (14) с весовыми матрицами
  
1   (  )
=
{︃
10  
  
  
,    (  ) = 1,
10
− 4
  
  
  
,    (  )̸= 1,
  
2   (  )
= 10
5
,  
   (  )
= 10
− 3
,
получим следующие матрицы протокола для (8):
  
111
=
[︁
− 25, 3429 − 1, 2471 − 0, 3469 − 0, 0181
]︁
,  
211
= 9, 2965,
  
112
=
[︁
− 41, 8954 − 1, 2959 − 0, 416 − 0, 0044
]︁
,  
212
= 16, 2678,
  
113
=
[︁
− 41, 9283 − 1, 296 − 0, 4161 − 0, 0044
]︁
,  
213
= 14, 3248,
  
121
=
[︁
− 25, 3841 − 1, 2813 − 0, 3428 − 0, 0139
]︁
,  
221
= 9, 2971,
  
122
=
[︁
− 41, 889 − 1, 2981 − 0, 4159 − 0, 0044
]︁
,  
222
= 16, 4272,
  
123
=
[︁
− 41, 9326 − 1, 2982 − 0, 4161 − 0, 0044
]︁
,  
223
= 14, 2538.
Зададим переключающие сигналы в виде
   (  ) =
⎧
⎪
⎨
⎪
⎩
1,    < 40,
2, 40≤    < 80,
1,   ≥ 80,
   (  ) =
⎧
⎪
⎨
⎪
⎩
1,    < 20,
2, 20≤    < 60,
3,   ≥ 60.
Для оценки эффективности алгоритма введем среднеквадратическую
ошибку обучения
  
  
(  ) =
⎯
⎸
⎸
⎷
1
  
  − 1
∑︁
  =0
|  
  
(  ,  )|
2
.
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 48Дифференциальные уравнения и процессы управления,N. 1, 2023
На рисунке 1 представлены графики среднеквадратических ошибок обу-
чения агентов без учета переключения управления при изменении режима
работы и конфигурации сети, т. е. управление происходит согласно закону
(7) с корректирующей добавкой (8) на всем протяжении функционирования
системы, а на рисунке 2 – с учетом переключения управления. Данные ре-
зультаты демонстрируют, что разработанный закон управления действитель-
нопозволяетснизитьвеличинупереходнойошибкивмоментыпереключения.
0 10 20 30 40 50 60 70 80 90 100
k
0
0.2
0.4
0.6
0.8
1
1.2
E(k
Рис. 1: Среднеквадратические ошибки обучения агентов без учета переключения закона
управления
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 49Дифференциальные уравнения и процессы управления,N. 1, 2023
0 10 20 30 40 50 60 70 80 90 100
k
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
E(k
Рис. 2: Среднеквадратические ошибки обучения агентов с учетом переключения закона
управления
5 Заключение
ВданнойработеполученорешениезадачиУИОсетевойсистемойприизмене-
ниижелаемойтраекториивыходногосигнала,параметровагентовиконфигу-
рацииинформационнойструктурывовремяработысистемы.Предложенный
алгоритм переключения управления позволяет компенсировать переходные
ошибки, однако он накладывает некоторые ограничения на конфигурацию
информационной сети. При взаимном обмене информацией между агента-
ми произвести переключение режима невозможно, а при последовательном
соединении длительность процесса переключения режима зависит от коли-
чества агентов в сети, в связи с чем в некоторых случаях он может занять
недопустимо длительное время. В дальнейшем планируется распространить
полученные результаты на случай, когда агенты сетевой системы подверже-
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 50Дифференциальные уравнения и процессы управления,N. 1, 2023
ны воздействию внешних возмущений, а их выходные сигналы измеряются с
шумами.
6 Благодарности
Работа выполнена при поддержке Российского научного фонда, грант № 21-
71-00091, https://rscf.ru/project/21-71-00091/.
Список литературы
[1] Arimoto S., Kawamura S., Miyazaki F. Bettering operation of robots by
learning // J. Robot. Syst. 1984. V. 1. P. 123-140.
[2] Zaitceva I., Andrievsky B. Methods of Intelligent Control in Mechatronics
and Robotic Engineering: A Survey // Electronics. 2022. V. 11, No. 15. P.
2443.
[3] Ahn H.-S., Chen Y. Q., Moore K. L. Iterative learning control: brief survey
and categorization // IEEE Transactions on Systems, Man, and Cybernetics
Part C: Applications and Reviews. 2007. V. 37, No. 6. P. 1099-1121.
[4] Bristow D.A., Tharayil M., Alleyne A.G. A survey of iterative learning //
IEEE Control Systems Magazine. 2006. V. 26. No. 3. P. 96-114.
[5] Pakshin P., Emelianova J., Emelianov M. Iterative learning control of
stochastic linear systems under switching of the reference trajectory
and parameters // 2021 29th Mediterranean Conference on Control and
Automation (MED). 2021. P. 1311-1316.
[6] Koposov A., Emelianova J., Pakshin P. Iterative Learning Control of
Multi-Agent Systems under Changing Reference Trajectory // IFAC-
PapersOnLine. 2022. V. 55. No. 12. P. 759-764.
[7] Копосов, А. С. Робастное сетевое управление с итеративным обучени-
ем системой переменной конфигурации при случайных возмущениях //
Управление большими системами: сборник трудов. 2021. № 94. С. 50-65.
DOI 10.25728/ubs.2021.94.3. EDN DFWYYG.
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 51Дифференциальные уравнения и процессы управления,N. 1, 2023
[8] Pakshin P., Emelianova J., Emelianov M., Galkowski K., Rogers E.
Dissipativity and Stabilization of Nonlinear Repetitive Processes // Systems
& Control Letters. 2016. V. 91. P. 14-20.
[9] Apkarian J., Karam P., Levis M. Workbook on Flexible Link Experiment for
Matlab/Simulink Users. Quanser, 2011.
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 52Дифференциальные уравнения и процессы управления,N. 1, 2023
Networked iterative learning control under changing operating mode
of agents and configuration of information structure
Koposov A.S.
Arzamas Polytechnic Institute of R.E. Alekseev Nizhny Novgorod State
Technical University
koposov96@yandex.ru
Abstract. The paper considers the iterative learning control (ILC) design
problem of a network system under changing operating mode of subsystems
(agents) and configuration of information structure. The network system consists
of identical agents, which are discrete linear dynamic plants operating in a
repetitive mode. The operating modes of agents depend on their parameters
and the reference trajectory, which must be tracked with required accuracy at
output of system. The configurations of information network define the group
of functioning agents and the type of information exchange between them. The
modeandtheconfigurationchangetakesplaceinaccordancewithcertainexternal
rules. The control design is based on the divergent method of the vector Lyapunov
function. For reducing the transient error caused by the mode change and the
connection of new agents, a special rule for switching the ILC law is proposed.
Theresultsofmodelinganetworksystemconsistingofidenticalmanipulatorswith
flexible link, which is controlled according to the obtained law, are presented.
Keywords: networked control, iterative learning control, systems with switches,
changing reference trajectory, vector Lyapunov function.
Acknowledgements. The work was supported by the Russian Science
Foundation under grant 21-71-00091, https://rscf.ru/project/21-71-00091/.
https://doi.org/10.21638/11701/spbu35.2023.104Электронныйжурнал: http://diffjournal.spbu.ru/ 53
