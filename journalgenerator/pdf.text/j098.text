dx
dt
6
 
-
?
DIFFERENTIAL EQUATIONS
AND
CONTROL PROCESSES
N 4, 2002
Electronic Journal,
reg. N P23275 at 07.03.97

e-mail: diff@osipenko.stu.neva.ru
Group analysis of differential equations
CONNECTION BETWEEN PAINLEV
´
E ANALYSIS
AND OPTIMAL SYSTEMS
J¨ org VOLKMANN, Gerd BAUMANN
Department of Mathematical Physics
University of Ulm, Albert-Einstein-Alle 11
D-89069 Ulm, Germany
E-mail: joerg.volkmann@volkswagen.de
Abstract
In this article we discuss two methods of solving systems of partial differen-
tial equations. First we describe the Painlev´ e test. In a second step a similarity
analysis is carried out to motivate optimal systems. We present procedures of
solvingpartialdifferentialequations,whichconnectbothmethods.Theconnec-
tion between the methods is exampliﬁed by the KdV equation. Special points
are the applications of the theorem of Strampp and the calculation of nonclas-
sical symmetries via the algorithm of Clarkson.
Introduction
A large number of physical phenomena is described by systems of partial or
ordinary differential equations. During the last years it became more and more
important to characterise biological, chemical and physical phenomenons withDifferential Equations and Control Processes, N 4, 2002
nonlinearpartialdifferentialequations(PDEs).Sothedevelopmentofanalytical
methodsofsolvingsuchPDEsbecomesmoresigniﬁcant.Todaythereexistthree
algorithms which are powerful and appropriate to solve such equations:
- the inverse scattering transform
- the calculation of similarity solutions by Lie’s theory, and
- the calculation of solutions with the Painlev´ e Ansatz.
The aim of this paper is to connect the method of Lie [1] and the Painlev´ e
Ansatz [2] to construct solutions with the aid of optimal systems. The ﬁrst
section contains the main facts about the Painlev´ e test. In section 2 we discuss
theconnectionbetweenthePainlev´ etestsdevelopedbyWeiss,Tabor,Carnevale
(WTC-Test)[3]andbyAblowitz,Ramani,Segur[2].Weapplytheseteststothe
Boussinesq equation to solve it. The third section connects the WTC-test and
Lie’s similarity analysis. We demonstrate the joint methods by applying it to
the KdV equation. The fourth section introduces optimal systems. We discuss
the preliminary method by Olver [1] for the KdV and nonlinear Schr¨ odinger
equation. The last section makes some concluding remarks.
1 Facts about Painlev´ e Property and the Painlev´ e Test
The generation of the Painlev´ e test is traced back to S. Kovalevskaya’s conjec-
ture in the years 1889, 1890 [4, 5]. She demonstrated a connection between the
complete solvability of a ﬁnite dimensional Hamilton system and the analytical
structure of the equations of motions on a complex surface. Her discussion was
based on the problem that a rigid body moves around a ﬁx point. She tried
to ﬁnd parameters in such a way that the solutions should not have movable
branch points (essential singularities in the complex surface) depending on ini-
tial conditions. For these cases she solved the equations of motion explicitly
[6]. Kovalevskaya was motivated by papers written by Painlev´ e (1888) [7] and
Fuchs (1884) [8].
The main idea behind this investigation was the question if singularities
appearing in the solutions are ﬁxed or movable. Painlev´ e showed in 1888 that
the singularities in the solution of a ﬁrst-order differential equation
y
 
x,f,
df
dx
 
= 0 (1)
are poles and/or algebraic branch points [9]. In (1) y is an analytical polynom
in f and
df
dx
. The power expansion found by Kovalevskaya is based on a method
Electronic Journal.  18Differential Equations and Control Processes, N 4, 2002
introduced by Frobenius in the year 1873. After this Painlev´ e and Gambier
[10] catalogued all ordinary differential equations of order one and two due to
the fact that they allow poles as moveable singularities in the complex surface.
Out of these attributes there emerged the Painlev´ e property. All solutions of
the known ordinary differential equations except for six allow convergent series.
These six exceptions are called the ”Painlev´ e transcendents”.
The interest in this fact was recovered by Ablowitz [2, 11]. He found that the
Painlev´ e transcendents result from ordinary differential equations which are
generated by the reduction of partial differential equations solvable via inverse
scattering transformation .
Let us ﬁrst look at the ordinary differential equations
y
 
x,f,
df
dx
,
d
2
f
dx
2
,··· ,
d
n
f
dx
n
 
= 0 (2)
of order n ∈ IN in the complex surface. Equation (2) depends on dependent
variables f and the independent variables x. Equation (2) contains a meromor-
phic functionf [12] which is one of the basics for the Painlev´ e property [6]. The
practical calculation of the Painlev´ e property is bases on the following theorem
by Steeb [6]:
Theorem 1.1 An ordinary differential equation of order n allows the Pain-
lev´ e property. Then the general solution of the differential equation has the
generalised Laurent expansion at any point z
1
∈C
f(z) =
∞
X
j=0
a
j
(z−z
1
)
j+m
, m∈IR, (3)
furthermore there exist n−1 free constants.
ThistheoremallowstodeﬁneatesttoverifythePainlev´ eproperty[6].However
we note that condition (3) in Theorem 1.1 is not suﬃcient, because moveable
essential singularities are not excluded.
In the following we describe how to transfer this Painlev´ e test to partial
differential equations. We examine a system of partial differential equations of
higher order with n independent and m dependent variables. We denote the
independent variables by x = (x
1
,x
2
,...,x
n
) and the dependent variables by
u =
 
u
1
,u
2
,...,u
m
 
. Let F
1
,...,F
l
be functions deﬁned on the manifold M:X×
Electronic Journal.  19Differential Equations and Control Processes, N 4, 2002
U×U
(r)
→IR,
 
x,u,u
(r)
 
7→ F
ν
 
x,u,u
(r)
 
, ν = 1,...,l, and
u
(r)
=


u
1
x
1
,u
2
x
2
,··· ,u
1
x
n
,u
2
x
1
,··· ,u
m
x,n
,u
1
x
1
x
1
,··· ,u
m
x
n
···x
n
| {z }
r times


. (4)
are the derivatives in M. The system of differential equations under considera-
tion now is
F
 
x,u,u
(r)
 
:=
 
F
1
 
x,u,u
(r)
 
,··· ,F
l
 
x,u,u
(r)
  
= 0. (5)
We call a solution of (5) a function that satisﬁes F
 
x,f(x),f
(r)
(x)
 
≡ 0 if
f : X → U,x7→ f(x) is given by (3).
We assume that all functions we are dealing with are analytic and therefore
can be differentiated as often as necessary. In the case of partial differential
equations we deal with functions with more than one variable. This extended
manifoldisknownasananalyticalhypersurface[13].ThePainlev´ epropertyona
analytic hypersurface is deﬁned in [13]. To calculate solutions for F
ν
 
x,u,u
(r)
 
,
we need the deﬁnition giving by Weiss [3]
Deﬁnition 1.1 A partial differential equation of order r passes the Painlev´ e
test from Weiss-Tabor-Carnevale (WTC-Test), if the solution can be expressed
in the Form
u =
∞
X
j=0
u
j
(x
1
,··· ,x
n
)Φ
j+α
(6)
where α∈Z Z, u
j
is holomorph and k of these u
j
are not determined.
We note:
1. Some authors don’t distinguish between the Painlev´ e property and the
Painlev´ e test.
The ansatz from deﬁnition 1.1 is called weak Painlev´ e property. So we
can deﬁne that a partial differential equation possesses the weak Painlev´ e
property if equation (5) passes the Painlev´ e test.
2. Condition written in deﬁnition 1.1 is not suﬃcient because essential sin-
gularities are not pointed out (see for example [14]).
In the course of the analysis we must differentiate series. So we have to apply
the theorem of Osgood [15]. This allows us to differentiate an inﬁnite series of
Electronic Journal.  20Differential Equations and Control Processes, N 4, 2002
functions in n complex variables z
1
,...,z
n
which are holomorph
1
on a 2n di-
mensional surface T. You can conceive the product u
j
Φ
j+α
in (6) as a function
of ˜ u
j
. Applying the series ansatz by Weierstrass to (6), we need the condition
that ˜ u
j
is holomorph. A holomorphic function is the product of two holomor-
phic functions. This fact is the reason that u
j
and Φ must have this property.
Furthermore we take the elements of this series and differentiate them one by
one.
There exists another Painlev´ e test given by [16] who is distinguished from
the WTC-test by assumptions and practicability:
Deﬁnition 1.2 A partial differential equation (5) passes the Painlev´ e test from
Ablowitz, Ramani, Segur (ARS-test), if the classical and the nonclassical sym-
metry reductions pass the Painlev´ e test, perhaps after transformations.
This procedure is very diﬃcult because you need all symmetry reductions
of the original equation . The solution of this problem was the development
of the WTC-test which can be easily applied to partial differential equations.
However, it was shown [17] that if an equation passes the WTC-test it also
pasess the ARS-test, but not vice versa. In the following part we describe how
to apply the Painlev´ e test to partial differential equations. We look at a system
of differential equations (5) with x = (x
1
,x
2
,...,x
n
) and u =
 
u
1
,u
2
,...,u
m
 
.
We assume that the number of equations coincide with the number of de-
pendent variables (but it can happen that n 6= m). We make the following
ansatz to expand the functions u
k
; k = 1,...,m about an analytic manifold Φ:
u
k
(x,t) = Φ
α
k
∞
X
j
k
=0
u
k
j
k
Φ
j
k
(x,t);k = 1,...,m; α
k
∈Z Z (7)
α
k
; k = 1,...,m form a m-tuple in short α := (α
1
,α
2
,...,α
m
). The following
stepsdiscussthenecessarycalculationstocometothestatementifthediscussed
equation passes the Painlev´ e-test:
Step 1: To determine α, we have to look at the system of equations
F
 
x,u
(0)
,u
(r)
(0)
 
= 0 (8)
where
u
(0)
=
 
u
1
0
Φ
α
1
,··· ,u
m
0
Φ
α
m
 
. (9)
1
Osgood is using the word analytic but he means the complex differentiation relating to z
1
,...,z
n
at every
point inside of this surface.
Electronic Journal.  21Differential Equations and Control Processes, N 4, 2002
In each equation from (5) we determine for each nonvanishing term of the sum
the exponent of the power of Φ. We get determining equations for the tuple α
out of thefactthat welook forthe smallestexponents appearing in atleasttwo
terms of the sum of each equation. The complete set of determining equations
for α depends on n,m and r. They are parameters in system (5).
Deﬁnition 1.3 Terms leading to the smallest exponents of Φ for the ν-th equa-
tion in (5) are called the leading terms of the equation
F
ν
 
x,u,u
(r)
 
= 0; ν = 1,...,m.
IfoneofthecoeﬃcientsofαisnotinZ Z,thesystemdoesn’tpossessthePainlev´ e
property. If you cannot calculate all α
k
,k = 1,...,n meaning, that some can
be chosen arbitrary, we continue with the Painlev´ e test under the assumption
α∈Z Z
m
and restrict this arbitrary α in a later step.
Step 2: All known coeﬃcients α
k
∈ Z Z
m
will be inserted in (5). We neglect
all terms with the exception of the leading ones. If the equation can be reduced
to the form
u
k
0
u
l
0
∂
|J|
Φ
∂x
j
1
···∂x
j
|J|
= 0,
the cases u
k
0
= 0 and u
l
0
= 0 are inconsistent with the ansatz, because the series
starts with powers of Φ
α
k
. The partial derivatives are written with a multi-
index. In the cases that the assumption α∈Z Z
m
isn’t valid or the last case has
happened you can try to transform equation (5) into a form which passes step
1 and step 2 of the Painlev´ e test
Step 3: After doing these examinations we insert the generalised Laurent-
series (6) into equation (5) and take into account the values of α
k
. We assume
that these series are convergent or absolutely convergent without making ex-
aminations about this question. We now factor out Φ
σ
ν
in the ν-th equation
where σ
ν
is the leading power of this equation. The gained result is
∞
X
j=0
G
ν
j
 
u
j
,u
(r)
j−1
,··· ,u
(r)
0
,Φ
(r)
 
Φ
j
= 0. (10)
Now we make a comparison of coeﬃcients in powers of Φ leading to
^
j∈IN
0
G
ν
j
 
u
j
,··· ,Φ
(r)
 
= 0.
Electronic Journal.  22Differential Equations and Control Processes, N 4, 2002
These equations lead to a recursion equation for arbitrary but ﬁxed j,
P
ν
 
j,u
0
,Φ
(r)
 
u
T
j,ν
=
˜
G
ν
 
u
j−1
,...,u
0
,Φ
(r)
 
,
whereP
ν
 
j,u
0
,Φ
(r)
 
:=
 
P
ν
1
 
j,u
0
,Φ
(r)
 
,...,P
ν
m
 
j,u
0
,Φ
(r)
  
.T denotesatrans-
position and P
ν
k
,k = 1,...,m are the coeﬃcients in front of u
k
. All ν equations
can be put together to a matrix equation
Mu = V (u
j−1
,u
j−2
,··· ,Φ,Φ
x
1
,···).
To solve this matrix equation in a deﬁnite manner it is necessary that det M
doesn’t vanish. So we deﬁne
Deﬁnition 1.4 The spots a
j
, j = 1,...,r, where the determinant of M is van-
ishing are called resonance spots. At these spots the functions u
k
a
j
are arbitrary.
This arbitrary function is necessary for solving problems including initial-
and boundary condition problems. We must adapt the solutions to these prob-
lems.
The gain of this procedure is:
1. One resonance spot is a
1
=−1. This corresponds with the arbitrariness of
Φ.
2. If u
0
is arbitrary we ﬁnd the resonance spot a
2
= 0.
3. If all resonance spots are a ∈ Z Z and have the rows of the vector V the
same factor as the belonged rows of the matrix M, so the system posses
the Painlev´ e property. Further more we ﬁnd that all coeﬃcients u
k
with
the index j = a
i
are arbitrary functions.
4. Some resonance spots may be not an element of Z Z. For this case we ﬁnd
integrable as well as non-integrable equations. An example for this is the
Harry-Dym equation. The case of rational resonance spots is called weak
Painlev´ e property.
5. If all resonance spots are inZ Z but the rows of the vector on the right hand
aren’t linear dependent like described in 3) then we distinguish between
two cases:
Electronic Journal.  23Differential Equations and Control Processes, N 4, 2002
(a) We can generate the linear dependence if one introduces logarithm
Psi-series
2
or:
(b) We get conditions of compatibility out of the assumption that the ma-
trixequationissolvable.Thesolutionshadtoperformtheseadditional
equations. In the last two cases the Painlev´ e test is violated.
To check whether the resonance spots are valid or not you form the matrix
equation for the special j and examine the linear dependence of the rows. It
must be accomplish
Rang M = Rang M
erw
. (11)
For constructing solutions we make a cut of the several series u
k
at the power
Φ
0
andputthistermsinsystem(5).AcomparisonofcoeﬃcientsofpowersofΦ
leads to an overdetermined system of equations which we have to solve. There
are several varieties for solving:
1. You can simplify the system by inserting an equation into other equations
of the system and making a very strong assumption. In this case a solution
will be found.
2. We can add and subtract terms to remove interfering terms. You have
to pay attention to the fact that the Painlev´ e property respectively the
passing of the Painlev´ e test wouldn’t be disturbed. This means, that the
resonancespotscanbedisplacedandthecondition(11)canlooseitsvalid-
ity because of adding and subtracting terms. A procedure to ﬁnd special
terms which don’t change the Painlev´ e property is given in a paper by
Newell. [21]
1.1 The Boussinesq Equation and Painlev´ e tests
InthissubsectionwewillexaminetheBoussinesqequation.Thisequationintro-
duced by Boussinesq in 1871 describes the expansion of long waves in shallow
water. However, this type of equation is applied to a wide range of physical
problems containing one-dimensional nonlinear lattice wave, vibrations in a
nonlinear chains, and sound waves of ions in a plasma.
2
series of the form
u
k
=
∞
X
j=0
∞
X
n=0
u
k
j,n
Φ
j−α
k
(Φ
ai
lnΦ)
n
(vgl. Clarkson [18], Tabor [19], Levine [20])
Electronic Journal.  24Differential Equations and Control Processes, N 4, 2002
Here we examine the Boussinesq equation in the form
u
tt
+au
xx
+b
 
u
2
 
xx
+cu
xxxx
= 0 (12)
⇒ u
tt
+au
xx
+2bu
2
x
+2buu
xx
+cu
xxxx
= 0 (13)
and make for the WTC-Test the ansatz.
u =
∞
X
j=0
u
j
Φ
j+α
. (14)
First, as mentioned in step 1, we introduce the terms of order zero in the
equation to determine u
0
and α. We get the solution
α =−2; u
0
=−6
c
b
 
∂Φ
∂x
 
2
.
Thelastthreetermsofequation(13)aretheleadingones.Weputtheseriesand
their derivatives into the differential equation and make an index - transforma-
tion. Since the derived equation is valid for all j we get the following recursion
equation:
u
j−2
(j−4)(j−5)
 
∂Φ
∂t
 
2
+2(j−5)
∂u
j−3
∂t
∂Φ
∂t
+u
j−3
(j−5)
∂
2
Φ
∂t
2
+
∂
2
u
j−4
∂t
2
+au
j−2
(j−4)(j−5)
 
∂Φ
∂x
 
2
+2a
∂u
j−3
∂x
(j−5)
∂Φ
∂x
+
au
j−3
(j−5)
∂
2
Φ
∂x
2
+a
∂
2
u
j−4
∂x
2
+2b
j
X
k=0
∂u
k
∂x
∂u
j−k−2
∂x
+
2b
j
X
k=0
∂u
k
∂u j−k−1
(j−k−3)
∂Φ
∂x
+2b
j
X
k=0
u
k
(k−2)
∂u
j−k−1
∂x
∂Φ
∂x
+
2b
j
X
K=0
u
k
(k−2)u
j−k
(j−k−2)
 
∂Φ
∂x
 
2
+
2b
j
X
k=0
u
k
∂
2
u
j−k−2
∂x
2
+4b
j
X
k=0
u
k
∂u
j−k−1
∂x
(j−k−3)
∂Φ
∂x
+
2b
j
X
k=0
u
k
u
j−k
(j−k−2)(j−k−3)
 
∂Φ
∂x
 
2
+
Electronic Journal.  25Differential Equations and Control Processes, N 4, 2002
2b
j
X
k=0
u
k
u
j−k−1
(j−k−3)
∂
2
Φ
∂x
2
+
c(j−5)(j−4)(j−3)(j−2)u
j
 
∂Φ
∂x
 
4
+
4c(j−5)(j−4)(j−3)
∂u
j−1
∂x
 
∂Φ
∂x
 
3
+ (15)
6c(j−5)(j−4)(j−3)u
j−1
 
∂Φ
∂x
 
2
∂
2
Φ
∂x
2
+
12c(j−5)(j−4)
∂Φ
∂x
∂u
j−2
∂x
∂
2
Φ
∂x
2
+
3c(j−5)(j−4)u
j−2
 
∂
2
Φ
∂x
2
 
2
+6c(j−5)(j−4)
 
∂Φ
∂x
 
2
∂
2
u
j−2
∂x
2
+
6c(j−5)
∂
2
Φ
∂x
2
∂
2
u
j−3
∂x
2
+3c(j−5)(j−4)u
j−2
∂Φ
∂x
∂
3
Φ
∂x
3
+
4c(j−5)
∂u
j−3
∂x
∂
3
Φ
∂x
3
+4c(j−5)
∂Φ
∂x
∂
3
u
j−3
∂x
3
+
c(j−5)u
j−3
∂
4
Φ
∂x
4
+c
∂
4
u
j−4
∂x
4
= 0
We solve this equation for the leading terms and calculate the resonance
spots. One ﬁnds j =−1,4,5,6.
Now we insert numbers of IN for j in (15) and get the u
j
’s:
j = 0 : u
0
=−6
c
b
 
∂Φ
∂x
 
2
,
j = 1 : u
1
= 6
c
b
∂
2
Φ
∂x
2
,
j = 2 : u
2
=−
 
∂Φ
∂t
 
2
+a
 
∂Φ
∂x
 
2
−3c
 
∂
2
Φ
∂x
2
 
2
+4c
∂Φ
∂x
∂
3
Φ
∂x
3
2b
 
∂Φ
∂x
 
2
,
j = 3 : u
3
=−
−
∂
2
Φ
∂x
2
 
∂Φ
∂x
 
2
+
 
∂Φ
∂t
 
2
∂
2
Φ
∂x
2
−3c
 
∂
2
Φ
∂x
2
 
3
2b
 
∂Φ
∂x
 
4
+
4c
∂Φ
∂x
∂
2
Φ
∂x
2
∂
3
Φ
∂x
3
−c
 
∂φ
∂x
 
2
∂
4
Φ
∂x
4
2b
 
∂Φ
∂x
 
4
.
Electronic Journal.  26Differential Equations and Control Processes, N 4, 2002
For j = 4,j = 5 and j = 6 the equation (15) is fulﬁlled identically. So the
Boussinesq equation passes the WTC-Test.
In the following part of this section we deal with the symmetry analysis.
Applying Lie’s theory by using the functions of MathLie [22], we get the in-
ﬁnitesimal symmetries of equation (13):
ξ
1
= c
1
+
c
3
2
x, ξ
2
= c
2
+c
3
t, η
1
=−
c
3
(a+2bu)
2b
,
which are connected with the generators
v
1
=
∂
∂x
, v
2
=
∂
∂t
, and v
3
=
1
2
x
∂
∂x
+t
∂
∂t
−
a+2bu
2b
∂
∂u
The commutator table is
v
1
v
2
v
3
v
1
0 0 −
1
2
v
1
v
2
0 0 −v
2
v
3
1
2
v
1
v
2
0
In the next step we reduce the Boussinesq equation with these generators:
1. v
1
: The corresponding similarity variable is λ = t,u = F(λ), and the
reduced equation is
F
00
(λ) = 0.
We ﬁnd the solution u = aλ +b. This function hasn’t any singularities.
It follows that this equation posses the Painlev´ e property for ordinary
differential equations.
2. v
2
: The similarity solution for this generator is λ = x,u = F(λ). We ﬁnd
the following reduced equation:
2b(F
0
(λ))
2
+aF
00
(λ)+2bF(λ)F
00
(λ)+cF
(iv)
(λ) = 0.
3. v
1
+v
2
: We get the following similarity solution for this generator:
λ =
k
1
t−k
2
x
k
1
; u = F(λ).
The reduction is
2bk
2
1
k
2
2
(F
0
(λ))
2
+k
4
1
F
00
(λ)+ak
2
1
k
2
2
F
00
(λ)+2bk
2
1
k
2
2
F(λ)F
00
(λ)+
ck
4
2
F
(iv)
(λ) = 0.
After two integrations we ﬁnd
bk
2
1
k
2
2
(F(λ))
2
+k
4
1
F(λ)+ak
2
1
k
2
2
F(λ)+ck
4
2
F
00
(λ) = Aλ+B.
Electronic Journal.  27Differential Equations and Control Processes, N 4, 2002
4. v
3
: The similarity representation is
λ =
x
2
t
, F = x
2
(a+2bu).
This leads to the reduction
10
λ
4
(F(λ))
2
+
120c
λ
4
F(λ)−
14
λ
2
F(λ)F
0
(λ)+
4
λ
2
F(λ)F
00
(λ)−
120c
λ
3
F
0
(λ)+
2
λ
F
0
(λ)+
4
λ
2
(F
00
(λ))+
60c
λ
2
F
00
(λ)+
F
00
(λ)−
16c
λ
F
000
(λ)+16cF
(iv)
(λ) = 0
On the other hand, we can examine (13) by means of the non-classical symme-
try reduction. The main topics about this procedure are collected in [23, 24].
Following Clarkson [23] we make the following ansatz to calculate the symme-
tries:
u(x,t) = α(x,t)+β(x,t)w(z(x,t))
where α,β and z(x,t) are unknown functions. This ansatz is inserted into the
differential equation (13) and order by w, powers of w and derivatives of w. We
ﬁnd:
cβ
 
∂z
∂x
 
4
d
4
w
dz
4
+
 
4c
∂β
∂x
 
∂z
∂x
 
3
+6cβ
 
∂z
∂x
 
2
∂
2
z
∂x
2
!
d
3
w
dz
3
+
 
β
 
∂z
∂t
 
2
+aβ
 
∂z
∂x
 
2
+2bαβ
 
∂z
∂x
 
2
+6c
 
∂z
∂x
 
2
∂
2
β
∂x
2
+
12c
∂β
∂x
∂z
∂x
∂
2
z
∂x
2
+3cβ
 
∂
2
z
∂x
2
 
2
+4cβ
∂z
∂x
∂
3
z
∂x
3
!
d
2
z
dz
2
+
 
2
∂β
∂t
∂z
∂t
+β
∂
2
z
∂t
2
+2a
∂β
∂x
∂z
∂x
+aβ
∂
2
z
∂x
2
+4bβ
∂α
∂x
∂z
∂x
+2bαβ
∂
2
z
∂x
2
+
6c
∂
2
β
∂x
2
∂
2
z
∂x
2
+4c
∂z
∂x
∂
3
β
∂x
3
+4c
∂β
∂x
∂
3
z
∂x
3
+cβ
∂
4
z
∂x
4
 
dw
dz
+
Electronic Journal.  28Differential Equations and Control Processes, N 4, 2002
 
8bβ
∂β
∂x
∂z
∂x
+2bβ
2
∂
2
z
∂x
2
 
w
dw
dz
+
 
∂
2
β
∂t
2
+a
∂
2
β
∂x
2
+4b
∂α
∂x
∂β
∂x
+2bβ
∂
2
α
∂x
2
+2bα
∂
2
α
2
∂x
2
+c
∂
4
β
∂x
4
 
w+
2bβ
2
 
∂z
∂x
 
2
w
d
2
w
dz
2
+2bβ
2
 
∂z
∂x
 
2
 
dw
dz
 
2
+
 
2b
 
∂β
∂x
 
2
+2bβ
∂
2
α
2
∂x
2
!
w
2
+ (16)
∂
2
α
1
∂t
2
+a
∂
2
α
∂x
2
+2bα
∂
2
α
∂x
2
+c
∂
4
α
∂x
4
+2b
 
∂α
∂x
 
2
= 0.
We now have to derive an ordinary differential equation for w(z) from (16).
Thereforethefactorsinfrontofseveralderivativesandpowersofw(z)havetobe
only functions of z. So we get conditions for α(x,t),β(x,t) and z(x,t). So each
solutionof(16)willleadtoasimilaritysolution.Wereferthereadertothecited
paper of Clarkson [23] and references included therein to get more information.
During the following calculations we have the following arbitrariness:
1. The factor in front of the highest derivative has to be normalized. So it
follows that they are of the type
βΓ(z)
∂
4
z
∂x
4
with the arbitrary function Γ(z) remaining to be determined.
2. We name the unknown functions of z with a Greek letter so that we can
denote the result after transformations like derivation, integration, expo-
nentiation, scaling etc. with the same letter. (So we denote for example
the derivative Γ
0
(z) with Γ(z))
3. Without loosing any generality we make the following statements about
α(x,t),β(x,t),z(x,t)and w(z(x,t)):
(a) Is α(x,t) given by
α = α(x,t)+β(x,t)Ω(z),
we can set Ω≡ 0 after the transformation
w(z)→ w(z)−Ω(z).
Electronic Journal.  29Differential Equations and Control Processes, N 4, 2002
(b) If α
2
(x,t) has the form
β = β
0
(x,t)Ω(z),
we can set Ω(z)≡ 1 via the transformation w(z)→
w(z)
Ω(z)
.
(c) We determine z(x,t) with the equation
Ω(z) = z
0
(x,t)
where Ω(z) is invertible. We put Ω(z) = z via the substitution z →
Ω
−1
(z).
If we look at equation (16) we ﬁnd that the coeﬃcients of w
d
2
w
dz
2
and
 
dw
dz
 
2
are
equal. So we make the ansatz
cβz
4
x
Γ(z) = 2bβ
2
z
2
x
.
It follows
β =
c
2b
z
2
x
Γ(z).
Now we are looking at the coeﬃcient of w
000
. For this the equation
cβz
4
x
Γ(z) = 4cβ
x
z
3
x
+6cz
2
x
z
xx
is valid where Γ(z) is to be determined. We put in β and β
x
and divide by z
5
x
.
After rescaling of Γ(z) we get
z
x
Γ(z)−
z
xx
z
x
= 0.
This equation will be integrated over x. During this calculation we partially
integrate the ﬁrst term and apply remark 2. After exponentiating the result
undercondition2)wegetΓ(z) = xΘ(t)+Σ(t),using3),wehavez = xθ(t)+σ(t).
and β =
c
2b
θ
2
(t). The next step considers coeﬃcients of w
00
. The corresponding
equation is
cβz
4
x
Γ(z) = β(z
t
)
2
+aβz
xx
+2bαβz
2
x
+6cβ
xx
(z
x
)
2
+12cα
x
z
x
z
xx
+
3cβ(z
xx
)
2
+4βcz
x
z
xxx
.
After inserting all results, we solve this equation with resprect to α and use
remark 1). It follows
α =−
1
2bθ
2
 
x
dθ
dt
+
dσ
dt
 
2
.
Electronic Journal.  30Differential Equations and Control Processes, N 4, 2002
Putting this into the differential equation (16) we get
θ
6
 
w
iv
+ww
00
+(w
0
)
2
 
+
c
2b
θ
2
 
x
d
2
θ
dt
2
+
d
2
σ
dt
2
 
w
0
+
c
b
θ
d
2
θ
dt
2
w+
α
tt
+aα
xx
+2bαα
xx
+cα
xxxx
+2b(α
x
)
2
= 0.
Taking the coeﬃcients of the derivatives and powers of w and determine
them as functions of z, we end up with
θ
6
γ
1
(z) =
c
2b
θ
2
 
x
d
2
θ
dt
2
+
d
2
σ
dt
2
 
(17)
θ
6
γ
2
(z) =
c
b
θ
d
2
θ
dt
2
(18)
θ
6
γ
3
(z) = −
a
bθ
2
 
∂θ
∂t
 
2
+
1
bθ
3
 
dσ
dt
+x
dθ
dt
 
2
d
2
θ
dt
2
+ (19)
4
bθ
3
dθ
dt
 
dσ
dt
+x
dθ
dt
  
d
2
σ
dt
2
+x
d
2
θ
dt
2
 
−
1
bθ
2
 
d
2
σ
dt
2
+x
d
2
θ
dt
2
 
2
−
1
bθ
2
 
dσ
dt
+x
dθ
dt
  
d
3
σ
dt
3
+x
d
3
θ
dt
3
 
Since x in (17) is linear, we make the following ansatz for γ
1
: γ
1
(z) = Az +B.
From the comparison of coeﬃcients it follows
d
2
θ
dt
2
=
2b
c
θ
5
A (20)
d
2
σ
dt
2
=
2b
c
(Aσ+B)θ
4
. (21)
We put this into equation (18) and get γ
2
(z) = 2A. Finally let us examine (20).
We insertα and its derivatives and compare the coeﬃcients. Forγ
3
(z) me make
the ansatz γ
3
(z) = ˜ αx
2
+
˜
βx+˜ γ With (20) and (21) we ﬁnd
˜ α = −
4b
c
2
θ
8
A
2
,
˜
β = −
8b
c
2
θ
7
A
2
σ−
8b
c
2
ABθ
7
,
˜ γ = −
a
bθ
2
−
4b
c
2
θ
6
A
2
σ
2
−
8b
c
2
θ
6
ABσ−
4b
c
2
θ
6
B
2
.
Electronic Journal.  31Differential Equations and Control Processes, N 4, 2002
The ﬁnal result is
u(x,t) =
c
2b
θ
2
w(z)−
1
2bθ
2
 
x
∂θ
∂t
+
∂σ
∂t
 
2
, (22)
z(x,t) = xθ(t)+σ(t);
d
2
θ
dt
2
=
2b
c
θ
5
A;
d
2
σ
dt
2
=
2b
c
(Aσ+B)θ
4
, (23)
w
(iv)
+ ww
00
+(w
0
)
2
+(Az+B)w
0
+2Aw =
4b
c
2
(Az+B)
2
+
a
bθ
8
 
dθ
dt
 
2
. (24)
We can show [23] that the general form of all differential equations of the form
w
(iv)
+ww
00
+(w
0
)
2
+f(z)w
0
+g(z)w = h(z)
wheref(z),g(z),h(z)areanalyticfunctionswhichpossessthePainlev´ eproperty
is of the type
w
(iv)
+ww
00
+(w
0
)
2
+(Az+B)w
0
+2Aw = 2(Az+B)
2
(25)
For equation (25) it is possible to distinguish several cases for the constants A
and B. We put in (24) a = 0.
For example if we choose A = 0 and B = 0, it follows from (20) and (21)
that
θ(t) = a
1
t+a
0
; σ(t) = b
1
t+b
0
and
u(x,t) =
c
2b
(a
1
t+a
0
)
2
w(z)−
1
2b
 
a
1
x+b1
a
1
t+a
0
 
2
,
z = x(a
1
t+a
0
)+b
1
t+b
0
,
w
00
+
1
2
w
2
= c
1
z+c
0
.
The last differential equation is equivalent to the ﬁrst Painlev´ e transcendent.
With this procedure, we can determine similarity reductions which possess the
Painlev´ eproperty.ItfollowsthattheBoussinesqequationpassestheARS-Test.
We observe that it is very diﬃcult to show if a partial differential equation
passes the ARS-Test because we have to ﬁnd all symmetry reductions.
2 The Theorem of Strampp and Symmetry analysis
FirstofallwewillexaminehowaLaurent-series(6)ofthePainlev´ etestchanges
under a similarity reduction. We look at an equation of the form
u
t
= K(u,u
x
,··· ,u
rx
) (26)
Electronic Journal.  32Differential Equations and Control Processes, N 4, 2002
where K is a polynomial in u and the spatial derivatives up to order r, x∈IR
2
.
The independent variables are x
1
= x and x
2
= t. Furthermore, we assume that
equation (26) possesses the Painlev´ e property and the series (6). The generator
of u in (26) is assumed to allow the ansatz
v = ξ
x
(x,t)
∂
∂x
+ξ
t
(x,t)
∂
∂t
+η
u
(x,t,u)
∂
∂u
resultingintospeciﬁcinﬁnitesimals.Knowingtheinﬁnitesimals,weapplyFuchs’s
procedure [25] to reduce equation (26) to
η
u
(x,c,v)−ξ
x
(s,c)
d
dλ
v = ξ
t
(s,c)K
 
v,v
0
,...,v
(n)
 
. (27)
It can be shown that the related Laurent-series are of the form [26]
u(x,t) =
 
x−
 
s
0
−h(t)
g(t)
  
α ∞
X
j=0
u
j
 
x−
 
s
0
−h(t)
g(t)
  
j
, (28)
where u
j
= c
j
G(t) g(t)
j−a
for j 6= a and u
a
= c
a
G(t)+H(t). If we compare
(28) with (6) we ﬁnd, that (28) does not allow other resonance spots than we
found in (11).
For example, we consider the Burgers equation [26]
u
t
+uu
x
+u
xx
= 0. (29)
The Laurent-series is given by
u = Φ
−1
∞
X
j=0
u
j
Φ
j
.
The generators for (29) are
v
1
= γ
∂
∂x
+
∂
∂t
; γ = const, (30)
v
2
= x
∂
∂x
+2t
∂
∂t
−u
∂
∂u
, (31)
v
3
= xt
∂
∂x
+t
2
∂
∂t
+(x−tu)
∂
∂u
, (32)
v
4
= t
∂
∂x
+
∂
∂u
. (33)
From generator (30) it follows that u(x,t) = v(λ); λ = x−γt. We ﬁnd
v
00
+(v+γ)v
0
= 0. (34)
Electronic Journal.  33Differential Equations and Control Processes, N 4, 2002
With (31), we get u(x,t) =
1
√
t
v(λ), λ =
x
√
t
and
v
00
+vv
0
−
1
2
λv
0
= 0. (35)
If we consider(32),wecalculateu(x,t) = λ+
1
t
(v−λ),λ =
x
t
. Thecorrespond-
ing reduced differential equation is
v
00
+vv
0
−(λv)
0
+λ = 0. (36)
Generator (33) leads to u(x,t) = v+
x
λ
, λ = t and
λv
0
+v = 0. (37)
If we inspect equations (34), (35) and (36) we ﬁnd that they allow the following
Laurent expansion over a movable pole:
v(λ) = (λ−λ
0
)
−1
∞
X
j=0
c
j
(λ−λ
0
)
j
(38)
where c
2
is an arbitrary constant. Using this equation for (34), (35) and (36),
we get the following series for similarity solutions.
In case of (34):
u(x,t) = (x−γt−λ
0
)
−1
∞
X
j=0
c
j
(x−γt−λ
0
)
j
,
for relation (35):
u(x,t) =
 
x−λ
0
√
t
 
−1
∞
X
j=0
c
j
t
−
j
2
 
x−λ
0
√
t
 
j
,
and for the reduction (36):
u(x,t) = c
0
(x−λ
0
t)
−1
+λ
0
+(c
1
−λ
0
)t
−1
+
 
c
2
t
−2
+t−1
 
(x−λ
0
t)
+
∞
X
j=3
c
j
t
−j
(x−λ
0
t)
j−1
.
Another possibility to construct solutions when making a similarity analysis is
the following procedure:
Let x
1
= x and x
2
= t be the independent variables. Let us use a linearized
form of equation (26) for the solution u, given by
v
t
= K
0
(u)v =
∂
∂ε
K(u+εv)
 
 
ε=0
. (39)
Electronic Journal.  34Differential Equations and Control Processes, N 4, 2002
Eachsolutionvofthisequationisasymmetryoraninﬁnitesimaltransformation
of u, meaning that (26) is invariant under u + εv which is motivated by the
following theorem by Strampp [27]:
Theorem 2.1 Let
u
t
= K
 
u,u
(r)
 
, (40)
be a given partial differential equation where K is a polynomial in u and in the
spatial derivatives up to order r. Furthermore, we know the expansion of u in
the form
u =
∞
X
j=0
u
j
Φ
j+α
. (41)
Equation (40) passes the Painlev´ e test.
If we stop the series at a spot a > 0 then u
a−1
is an inﬁnitesimal transfor-
mation of u
a
.
The prove of the theorem can be found in [27].
Let us apply this theorem to the KdV equation to calculate solutions con-
necting the WTC-test and inﬁnitesimal transformations. The KdV-equation ist
u
t
+uu
x
+u
xxx
= 0 (42)
The system of the broken series reads
Φ
−5
: −2u
2
0
∂Φ
∂x
−24u
0
 
∂Φ
∂x
 
3
= 0, (43)
Φ
−4
: −3u
1
u
0
∂Φ
∂x
−6u
1
 
∂Φ
∂x
 
3
+18
∂u
0
∂x
 
∂Φ
∂x
 
2
+
18u
0
∂
2
Φ
∂x
2
∂Φ
∂x
+u
0
∂u
0
∂x
= 0, (44)
Φ
−3
: −2u
2
u
0
∂Φ
∂x
−u
2
1
∂Φ
∂x
+u
1
∂u
0
∂x
+6u
1
∂
2
Φ
∂x
2
∂Φ
∂x
+u
0
∂u
1
∂x
−2u
0
∂
3
Φ
∂x
3
−
2u
0
∂Φ
∂t
+6
∂u
1
∂x
 
∂Φ
∂x
 
2
−6
∂
2
u
0
∂x
2
−6
∂u
0
∂x
∂
2
Φ
∂x
2
= 0, (45)
Electronic Journal.  35Differential Equations and Control Processes, N 4, 2002
Φ
−2
: −u
2
u
1
∂Φ
∂x
+u
2
∂u
0
∂x
+u
1
∂u
1
∂x
−u
1
∂
3
Φ
∂x
3
−u
1
∂Φ
∂t
+u
0
∂u
2
∂x
−
3
∂
2
u
1
∂x
2
∂Φ
∂x
−3
∂u
1
∂x
∂
2
Φ
∂x
2
+
∂
3
u
0
∂x
3
+
∂u
0
∂t
= 0, (46)
Φ
−1
: u
2
∂u
1
∂x
+u
1
∂u
2
∂x
+
∂
3
u
1
∂x
3
∂u
1
∂t
= 0, (47)
Φ
0
: u
2
∂u
2
∂x
+
∂
3
u
2
∂x
3
+
∂u
2
∂t
= 0. (48)
The generators are:
v
1
=
∂
∂x
, v
2
=
∂
∂t
, v
3
= t
∂
∂x
+
∂
∂u
, v
4
= x
∂
∂x
+3t
∂
∂t
−2u
∂
∂u
.
Let us make a linear combination of all the generators as an ansatz
v = α
∂
∂x
+β
∂
∂t
+γ
 
t
∂
∂x
+
∂
∂u
 
+δ
 
x
∂
∂x
+3t
∂
∂t
−2u
∂
∂u
 
and transform it to the form
v =
 
(γ−2δu)+
∂u
∂x
(α+γt−δx)−
∂u
∂t
(β +3δt)
 
∂
∂u
, (49)
using
v =
"
η
α
−
X
i
∂u
α
∂x
i
ξ
i
#
∂
∂u
α
.
(see [28] p. 261 theorem 5.2.3-1). After setting u = u
2
in 49 we apply this equa-
tion to u
2
. Therefore we can represent u
1
with the help of Strampp’s theorem
as
u
1
= (γ−2δu
2
)−
∂u
2
∂x
(α+γt+δx)−
∂u
2
∂t
(β +3δt) (50)
If we insert the solution u
2
= 0 into (50), it follows that u
1
= γ and with (44)
we ﬁnd
∂
2
Φ
∂x
2
=
1
12
γ. An integration of the last relation leads to
∂Φ
∂x
=
1
12
γx+g(t).
If we integrate once more, we get Φ =
1
24
γx
2
+g(t)x+h(t). Using this equation
we ﬁnd:
u
0
=−12
 
1
12
γx+g(t)
 
2
.
Insertingthisresultintosystem(41)-(47)weﬁndthatγ = 0, g(t) = c
1
, h(t) =
c
2
, c
1
,c
2
= const. Thus the ﬁnal result is
u
1
= 0, (51)
u
2
= 0, (52)
u
0
= −12c
2
1
, (53)
Φ = c
1
x+c
2
. (54)
Electronic Journal.  36Differential Equations and Control Processes, N 4, 2002
The solution in original coordinates for u reads
u =
−12c
2
1
(c
1
x+c
2
)
2
=
−12
(x+ ˜ c
1
)
2
.
If we check the conditions from [13], we get
grad Φ = c
1
6= 0
for c
1
6= 0 at every arbitrary spot x
0
. Furthermore we see that the solution u is
meromorph. Now we can use this solution as a new solution u
2
and apply the
transformaation [1] u
3
= f(x−εt)+ε to gain another solution
u
2
=
−12
(x+c
1
t+c
2
)
2
−c
1
We can repeat the last two steps again and again to create solutions.
3 Deﬁnition of Optimal Systems
We regard a system of differential equations (5) for which we have calculated
the r-parametric maximal symmetry group. For every s-parametric subgroup
H one is able to ﬁnd a family of similarity solutions. The assumption is that
s≥ min{r,n
0
},s,r,n
0
∈IN. n
0
is the number of independent variables of F and
r is the order of derivatives. Since in many cases there exists an inﬁnite number
of such subgroups it is impossible to calculate all similarity solutions relative to
s-parametric subgroups. In this set there are similarity solutions which result
from other similarity solutions of the same set applying a transformation of
the symmetry group. It would be proﬁtable to have a minimal list of similarity
solutions such that with these elements one can get all other similarity solu-
tions via transformation. Such a minimal list is called an optimal system and
their elements are essentially different similarity solutions. The related inner-
authomorphism can be deﬁned by conjugation [29] and leads to a comparison
of two elements g
1
,g
2
of the Lie-group G.
Since two equivalence classes are either identical or disjunct, the set of all
s-parametric subgroups is split into two disjunct equivalence classes.
WedeﬁneanoptimalsystemfollowingOlver[1].Thisdeﬁnitionreducesthe
task to classify subgroups of the maximal symmetry group S. Furthermore, we
treat the problem to classify the subalgebras contained in the subgroups of the
maximal symmetry group S. This is possible because there is a connection via
Electronic Journal.  37Differential Equations and Control Processes, N 4, 2002
the adjoint representation of the Lie group and the adjoint representation of
the Lie algebra:
ad(v)(w) :=
d
dε
Ad(exp(εv))(w) = [w,v]
with
Ad(exp(εv)) = e
ε ad(v)
(w
0
) =
∞
X
j=0
ε
j
j!
(ad(v))
j
(w
0
)
= w
0
+ε[w
0
,v]+
ε
2
2
[[w
0
,v],v]+··· (55)
It can be also shown [1]:
H
s
and
˜
H
s
are two connected s-parametric subgroups of the Lie group
G with the corresponding s-dimensional Lie algebras H
s
and
˜
H
s
, which are
subalgebras of the Lie algebra G of G. H
s
and
˜
H
s
are conjugated subgroups
of G, H
s
G
∼
˜
H
s
, if and only if there exists an inner automorphism Ad(g) ∈
Int(G)(g∈ G) for the related subalgebras
H
s
= Ad(g)
 
˜
H
s
 
.
This directly leads to the deﬁnition of conjugated subalgebras and optimal
systems [1].
To apply the calculation of optimal systems let us consider the KdV equa-
tion. Contrary to the presentation of Olver [1] we don’t use invariants in our
calculation.
The Lie algebra’s basis corresponding to the KdV equation is given by
v
1
=
∂
∂x
, v
2
=
∂
∂t
, v
3
= t
∂
∂x
+
∂
∂u
, v
4
= x
∂
∂x
+3t
∂
∂t
−2u
∂
∂u
. (56)
The commutator table reads
v
1
v
2
v
3
v
4
v
1
0 0 0 −v
1
v
2
0 0 −v
1
−3v
2
v
3
0 v
1
0 2v
3
v
4
v
1
3v
2
−2v
3
0
Electronic Journal.  38Differential Equations and Control Processes, N 4, 2002
First we determine the adjoint representation Ad of the symmetry group by
(55) and get
Ad(e
ε
1
v
1
) =






1 0 0 −ε
1
0 1 0 0
0 0 1 0
0 0 0 1






, Ad(e
ε
2
v
2
) =






1 0 −ε2 0
0 1 0 −2ε
2
0 0 1 0
0 0 0 1






,
Ad(e
ε
3
v
3
) =






1 ε
3
0 0
0 1 0 0
0 0 1 2ε
3
0 0 0 1






, Ad(e
ε
4
v
4
) =






e
ε
4
0 0 0
0 e
3ε
4
0 0
0 0 e
−2ε
4
0
0 0 0 1






.
Theadjointrepresentationofanarbitraryelementg ofthegroupisgainedfrom
the product of the matrices above.
Ad
g
=






e
ε
4
ε
3
e
3ε
4
−2ε
2
e
−2ε
4
−ε
1
−2ε
2
ε
3
0 e
3ε
4
0 −3ε
2
0 0 2e
−2ε
4
2ε
3
0 0 0 1






.
For the following calculations let us make the ansatz
1
a
Ad
g






α
1
α
2
α
3
α
4






=






β
1
β
2
β
3
β
4






, (57)
1
a






e
ε
4
α
1
+ε
3
e
2ε
4
α
2
−2ε
2
e
−2ε
4
α
3
−ε
1
α
4
−2ε
1
2ε
3
α
4
e
3ε
4
α
2
−3ε
2
α
4
2e
2ε
4
α
3
+2ε
3
α
4
α
4






=






β
1
β
2
β
3
β
4






.
We are trying to simplify the right hand side by determining ε
i
. We have to
distinguish several cases referring to α
4
1. α
4
6= 0 :
We begin with the third component and set it to zero and solve it for ε
3
.
Electronic Journal.  39Differential Equations and Control Processes, N 4, 2002
The result is
ε
3
=−
e
−2ε
4
α
3
α
4
It follows β
3
= 0. After having set the second component to zero the
solution for ε
2
is
ε
2
=
e
3ε
4
α
2
3α
4
and β
2
= 0. Now we set the ﬁrst component zero and solve it for ε
1
. We
get
ε
1
=
e
ε
4
α
1
+ε
3
e
3ε
4
α
2
−2ε
2
e
−2ε
4
α
3
−2ε
2
ε
3
α
4
α
4
and β
1
= 0. For the vector β in equation (57), we ﬁnd
β = (0,0,0,1)
with
α
4
a
= 1.
2. α
4
= 0:
The appropriate equation is
1
a






e
ε
4
α
1
+ε
3
e
3ε
4
α
2
−2ε
2
e
−2ε
4
α
3
e
3ε
4
α
1
2e
−2ε
4
α
3
0






=






β
1
β
2
β
3
β
4






.
In this case we have to distinguish some subcases too:
(a) α
2
6= 0,α
3
6= 0
You take the second component and put
e
3ε
4
α
2
=
(
+1 for α
2
> 0
−1 for α
2
< 0
This ansatz is necessary because we have to take into account log-
arithms of this equation to get a solution for ε
4
. This operation is
deﬁned only for positive values. We ﬁnd
e
3ε
4
=
1
|α
2
|
and β
2
=±1.
Electronic Journal.  40Differential Equations and Control Processes, N 4, 2002
From the same reasons, we choose the same ansatz for the third com-
ponent and get β
3
= ±1. Then the ﬁrst component will be set zero
yields
ε
3
=
−e
ε
4
α
1
+2ε
2
e
−2ε
4
α
3
α
2
e
3ε
4
It follows β
1
= 0. We obtain two different linear independent results:
β = (0,1,1,0) for α
2
> 0;α
3
> 0
β = (0,1,−1,0) for α
2
> 0;α
3
< 0.
All other possibilities of combination are linear dependent.
(b) α
2
= 0;α
3
6= 0:
The equation which corresponds to this case is
1
a






e
ε
4
α
1
−2ε
2
e
−2ε
4
α
3
0
2e
−2ε
4
α
3
0






=






β
1
β
2
β
3
β
4






.
From the third component it follows that
2e
−2ε
4
α
3
=±1
and β
3
= 1. Putting the ﬁrst component to zero this leads to
ε
2
=
e
ε
4
α
1
2e
−2ε
4
α
3
,
and β
1
= 0. We get
β = (0,0,1,0).
(c) α
2
= 0;α
3
= 0;α
1
6= 0
The equation for this case can be written as
1
a






e
ε
4
α
1
0
0
0






=






β
1
β
2
β
3
β
4






.
Electronic Journal.  41Differential Equations and Control Processes, N 4, 2002
We put the ﬁrst component to zero and get
e
ε
4
=
1
α
1
and β
1
= 1 and come to
β = (1,0,0,0).
(d) α
3
= 0;α
2
6= 0;α
1
6= 0:
The appropriate equation is
1
a






e
ε
4
α
1
+ε
3
e
3ε
4
α
2
e
3ε
4
α
2
0
0






=






β
1
β
2
β
3
β
4






.
If we set the second component equal to one, we get β
2
= 1. If we
require the vanishing of the ﬁrst component, we obtain
ε
3
=−
e
ε
4
α
1
e
3ε
4
α
2
and the result for β is
β = (0,1,0,0).
All other possible cases and settings lead to linear dependent vectors
β
As a result we ﬁnd the following optimal system Θ
G
1
:
H ={v
4
},H ={v
2
+v
3
},H ={v
2
−v
3
},H ={v
3
},H ={v
2
},H ={v
1
}.
Knowing this system, we can derive solutions of the KdV-equation via reduc-
tions, and the methods discussed in section 3.
Similar calculations were carried out by us for the non-linear Schr¨ odinger
equation. The results will be published elsewhere.
4 Conclusions
These calculations demonstrated that there are two different possibilities to
calculate solutions for non-linear partial differential equations. With the help
Electronic Journal.  42Differential Equations and Control Processes, N 4, 2002
of the Painlev´ e test, we gain solutions by Laurent- series. With the similarity
analysis, we can determine the Lie algebra related to the equation and the clas-
siﬁcation of the Lie algebra allows to derive self-similar solutions. However, we
demonstrated that both solution procedures are connected. With the Painlev´ e
ansatz, we determined a system of partial differential equations resulting from
the broken series. The similarity analyse leads directly to the generators of the
equation. If we make an ansatz of the linearcombination of these generators
we get recursively solutions. Putting this into the system of partial differential
equations we can calculate all unknown functions.
References
[1] Peter J. Olver. 1986, Applications of Lie Groups to Differential Equations,
volume 107 of GTM. Springer.
[2] M. J. Ablowitz. 1980, A connection between nonlinear evolution equations
and ordinary differential equations of P-type I. J.Math.Phys., 21(4):715 –
721.
[3] J. Weiss, M. Tabor, and Carnevale G. 1983, The Painlev´ e property for
partial differential equations. J. Math. Phys., 24(3):522 – 526.
[4] S. Kovalewski. 1889, Sur le probl` eme de la rotation d’un corps solide
autour d’un point ﬁx` e. Acta Mathematica, pages 177 – 232.
[5] S. Kovalewski. 1890, Sur une propri´ et´ e du syst` eme d’´ equations
diff´ erentielles qui deﬁnit la rotation d’un cops solide authour d’un point
ﬁx` e. Acta Mathematica, pages 81 – 93.
[6] A.SteebandH.Euler. 1988, Nonlinear Evolution Equations and Painlev´ e–
Test. World Scientiﬁc Singapore.
[7] P. Painlev´ e. 1888, Sur le ´ equations diff´ erentielles du premier ordre. C. R.
Acad. Sci. Paris, pages 221 – 224, 320 – 323, 724 – 726.
[8] L. Fuchs. 1884,
¨
Uber differentialgleichungen deren int´ egrale feste verzwei-
gungspunkte besitzen. Sitz. Akad. Wiss. Berlin, pages 669 – 720.
[9] E. L. Ince. 1956, Ordinary Differential Equations. Dover Pblications New
York.
Electronic Journal.  43Differential Equations and Control Processes, N 4, 2002
[10] P. Painlev´ e. 1900, Sur le ´ equations diff´ erentielles du second ordre et d’
ordre sup´ erieur dont l´nt grale g´ en´ erale est uniforme. Acta mathematica,
pages 1 – 85.
[11] M. J. Ablowitz, A. Ramani, and H. Segur. 1980, A connection between
nonlinearevolutionequationsandordinary,differentialequationsofP-type
II. J. Math. Phys., 21(5):1006 – 1015.
[12] W. I. Smirnow. 1987, Lehrgang der h¨ oheren Mathematik Band III/2. VEB
Deutscher Verlag der Wissenschaften Berlin.
[13] R.S. Ward. 1984, The Painlev´ e property for the self-dual gauge-ﬁeld equa-
tions. Physics Letters A, 102(7): 279 – 282.
[14] P. A. Clarkson. 1985, The Painlev´ e property and a partial differential
equation with essential singularity. Physics Letters A, 109(5):205 – 208.
[15] W. F. Osgood. 1965, Lehrbuch der Funktionentheorie, volume 2, New
York.
[16] M. J. Ablowitz and P. A. Clarkson. 1991, Solitons, Nonlinear Evolution
Equations and Inverse Scattering. Cambridge Univ. Press.
[17] Roland Schmitz. 1992, Einige exakte Resultate betreffend Painlev´ e-tests,
April.
[18] P. A. Clarkson and Chr. M. Cosgrove. 1987, Painlev´ e analysis of the
nonlinearSchr¨ odingerfamilyofequations. J. Phys. A: Math. Gen.,20:2003
– 2024.
[19] M. Tabor and J. Weiss. 1981, Analytic structure of the Lorenz system.
Physical Review A, 24:2157 – 2167.
[20] G. Levine and M. Tabor. 1988, Integrating the nonintegrable: Analytic
structure of the Lorenz system revisited. Physica D, 33: 189 – 210.
[21] A.C. Newell, M. Tabor, and Y.B. Zeng. 1987, A uniﬁed approach to
Painlev´ e expansions. Physica D, pages 1 – 68.
[22] Gerd Baumann. 1999, Symmetry Analysis of Differential Equations Using
Mathematica. TELOS/Springer.
[23] P. A. Clarkson and M. D. Kruskal. 1989, New similarity reductions of the
Boussinesq equation. J. Math. Phys., 30(10):2201 – 2213.
Electronic Journal.  44Differential Equations and Control Processes, N 4, 2002
[24] G.W.Bluman,G.J.Reid,andS.Kumei. 1988, Newclassesofsymmetries
for partial differential equations. J. Math. Phys. 29 (4), pages 806 – 811.
[25] Chr. Fuchs. 1990,
¨
Ahnlichkeitsanalyse der mehrdimensionalen nichtsta-
tion¨ aren MHD-Gleichungen f¨ ur kompressible Str¨ omungen. PhD thesis, TU
Braunschweig.
[26] P. G. L. Leach and W. H. Steeb. 1988 Finite dimensional integrable
dynamical systems. In World Scientiﬁc, Singapore.
[27] W. Strampp. 1986, Symmetries and the Painlev´ e Property. Progress of
Theoretical Phys., 76(4):802 – 809.
[28] G.W.BlumanandS.Kumai. 1989 Symmetries and Differential Equations,
volume 81 of Appl. Math. Sciences. Springer.
[29] Helmut K¨ otz. 1993, Zur
¨
Ahnlichkeitsanalyse des Vlassov-Poisson-Systems
und des Vlassov- Maxwell-Systems. PhD thesis, TU Braunschweig.
[30] N. H. Ibragimov. 1994, CRC Handbook of Lie Group Analysis of Differen-
tial equations, Volume 1. CRC Press.
[31] N. H. Ibragimov. 1995, CRC Handbook of Lie Group Analysis of Differen-
tial equations, Volume 2. CRC Press.
[32] N. H. Ibragimov. 1996, CRC Handbook of Lie Group Analysis of Differen-
tial equations, Volume 3. CRC Press.
[33] J¨ org Volkmann. 1993, Die Painlev´ e-Eigenschaft partieller Differentialgle-
ichungen. Diploma, TU Braunschweig.
[34] J¨ org Volkmann. 1998, Die Painlev´ e-Eigenschaft partieller Differential-
gleichungen und die Problematik der Berechnung von Optimalsystemen.
August.
Electronic Journal.  45
